# GitHub Actions Workflow Logs
# Generated on Sat Jun  7 20:26:08 -03 2025


### 0_test

ï»¿2025-06-07T23:23:32.7077679Z Current runner version: '2.325.0'
2025-06-07T23:23:32.7102017Z ##[group]Operating System
2025-06-07T23:23:32.7102835Z Ubuntu
2025-06-07T23:23:32.7103436Z 24.04.2
2025-06-07T23:23:32.7103995Z LTS
2025-06-07T23:23:32.7104598Z ##[endgroup]
2025-06-07T23:23:32.7105199Z ##[group]Runner Image
2025-06-07T23:23:32.7105750Z Image: ubuntu-24.04
2025-06-07T23:23:32.7106259Z Version: 20250602.3.0
2025-06-07T23:23:32.7107331Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20250602.3/images/ubuntu/Ubuntu2404-Readme.md
2025-06-07T23:23:32.7109035Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20250602.3
2025-06-07T23:23:32.7109981Z ##[endgroup]
2025-06-07T23:23:32.7110487Z ##[group]Runner Image Provisioner
2025-06-07T23:23:32.7111071Z 2.0.437.1
2025-06-07T23:23:32.7111929Z ##[endgroup]
2025-06-07T23:23:32.7113021Z ##[group]GITHUB_TOKEN Permissions
2025-06-07T23:23:32.7114904Z Contents: read
2025-06-07T23:23:32.7115476Z Metadata: read
2025-06-07T23:23:32.7116132Z Packages: read
2025-06-07T23:23:32.7116761Z ##[endgroup]
2025-06-07T23:23:32.7118915Z Secret source: Actions
2025-06-07T23:23:32.7119698Z Prepare workflow directory
2025-06-07T23:23:32.7497865Z Prepare all required actions
2025-06-07T23:23:32.7534952Z Getting action download info
2025-06-07T23:23:33.0522436Z ##[group]Download immutable action package 'actions/checkout@v4'
2025-06-07T23:23:33.0523523Z Version: 4.2.2
2025-06-07T23:23:33.0524434Z Digest: sha256:ccb2698953eaebd21c7bf6268a94f9c26518a7e38e27e0b83c1fe1ad049819b1
2025-06-07T23:23:33.0525640Z Source commit SHA: 11bd71901bbe5b1630ceea73d27597364c9af683
2025-06-07T23:23:33.0526387Z ##[endgroup]
2025-06-07T23:23:33.1465071Z ##[group]Download immutable action package 'actions/setup-python@v5'
2025-06-07T23:23:33.1465896Z Version: 5.6.0
2025-06-07T23:23:33.1466646Z Digest: sha256:0b35a0c11c97499e4e0576589036d450b9f5f9da74b7774225b3614b57324404
2025-06-07T23:23:33.1467696Z Source commit SHA: a26af69be951a213d495a4c3e4e4022e16d87065
2025-06-07T23:23:33.1468652Z ##[endgroup]
2025-06-07T23:23:33.3441881Z Download action repository 'codecov/codecov-action@v4' (SHA:b9fd7d16f6d7d1b5d2bec1a2887e65ceed900238)
2025-06-07T23:23:33.5123875Z ##[group]Download immutable action package 'actions/upload-artifact@v4'
2025-06-07T23:23:33.5124712Z Version: 4.6.2
2025-06-07T23:23:33.5125455Z Digest: sha256:290722aa3281d5caf23d0acdc3dbeb3424786a1a01a9cc97e72f147225e37c38
2025-06-07T23:23:33.5126475Z Source commit SHA: ea165f8d65b6e75b540449e92b4886f43607fa02
2025-06-07T23:23:33.5127184Z ##[endgroup]
2025-06-07T23:23:33.7263073Z Complete job name: test
2025-06-07T23:23:33.7981464Z ##[group]Run actions/checkout@v4
2025-06-07T23:23:33.7982359Z with:
2025-06-07T23:23:33.7982815Z   repository: leolech14/Evolve
2025-06-07T23:23:33.7983508Z   token: ***
2025-06-07T23:23:33.7983933Z   ssh-strict: true
2025-06-07T23:23:33.7984374Z   ssh-user: git
2025-06-07T23:23:33.7984813Z   persist-credentials: true
2025-06-07T23:23:33.7985294Z   clean: true
2025-06-07T23:23:33.7985743Z   sparse-checkout-cone-mode: true
2025-06-07T23:23:33.7986306Z   fetch-depth: 1
2025-06-07T23:23:33.7986736Z   fetch-tags: false
2025-06-07T23:23:33.7987170Z   show-progress: true
2025-06-07T23:23:33.7987609Z   lfs: false
2025-06-07T23:23:33.7988025Z   submodules: false
2025-06-07T23:23:33.7988707Z   set-safe-directory: true
2025-06-07T23:23:33.7989471Z env:
2025-06-07T23:23:33.7989886Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:33.7990340Z   MAX_TOKENS: 5000000
2025-06-07T23:23:33.7990773Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:33.7991199Z   FORCE_EVOLVE: 0
2025-06-07T23:23:33.7991826Z ##[endgroup]
2025-06-07T23:23:33.9873658Z Syncing repository: leolech14/Evolve
2025-06-07T23:23:33.9875860Z ##[group]Getting Git version info
2025-06-07T23:23:33.9876762Z Working directory is '/home/runner/work/Evolve/Evolve'
2025-06-07T23:23:33.9877908Z [command]/usr/bin/git version
2025-06-07T23:23:33.9942555Z git version 2.49.0
2025-06-07T23:23:33.9970975Z ##[endgroup]
2025-06-07T23:23:33.9990987Z Temporarily overriding HOME='/home/runner/work/_temp/97f172a7-3410-4d24-95b8-6914c7db4862' before making global git config changes
2025-06-07T23:23:33.9993409Z Adding repository directory to the temporary git global config as a safe directory
2025-06-07T23:23:33.9995621Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:23:34.0029470Z Deleting the contents of '/home/runner/work/Evolve/Evolve'
2025-06-07T23:23:34.0033106Z ##[group]Initializing the repository
2025-06-07T23:23:34.0036837Z [command]/usr/bin/git init /home/runner/work/Evolve/Evolve
2025-06-07T23:23:34.0114846Z hint: Using 'master' as the name for the initial branch. This default branch name
2025-06-07T23:23:34.0116203Z hint: is subject to change. To configure the initial branch name to use in all
2025-06-07T23:23:34.0117204Z hint: of your new repositories, which will suppress this warning, call:
2025-06-07T23:23:34.0117950Z hint:
2025-06-07T23:23:34.0118713Z hint: 	git config --global init.defaultBranch <name>
2025-06-07T23:23:34.0119372Z hint:
2025-06-07T23:23:34.0120148Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2025-06-07T23:23:34.0121620Z hint: 'development'. The just-created branch can be renamed via this command:
2025-06-07T23:23:34.0122699Z hint:
2025-06-07T23:23:34.0123484Z hint: 	git branch -m <name>
2025-06-07T23:23:34.0124755Z Initialized empty Git repository in /home/runner/work/Evolve/Evolve/.git/
2025-06-07T23:23:34.0134316Z [command]/usr/bin/git remote add origin https://github.com/leolech14/Evolve
2025-06-07T23:23:34.0166248Z ##[endgroup]
2025-06-07T23:23:34.0167565Z ##[group]Disabling automatic garbage collection
2025-06-07T23:23:34.0171493Z [command]/usr/bin/git config --local gc.auto 0
2025-06-07T23:23:34.0200623Z ##[endgroup]
2025-06-07T23:23:34.0201433Z ##[group]Setting up auth
2025-06-07T23:23:34.0207792Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2025-06-07T23:23:34.0238243Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2025-06-07T23:23:34.0531059Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2025-06-07T23:23:34.0561860Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2025-06-07T23:23:34.0782289Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2025-06-07T23:23:34.0824350Z ##[endgroup]
2025-06-07T23:23:34.0825463Z ##[group]Fetching the repository
2025-06-07T23:23:34.0833941Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +63224c07a7ba4fd3150d60b6f60c79fd94cff7a2:refs/remotes/origin/main
2025-06-07T23:23:34.6201761Z From https://github.com/leolech14/Evolve
2025-06-07T23:23:34.6203543Z  * [new ref]         63224c07a7ba4fd3150d60b6f60c79fd94cff7a2 -> origin/main
2025-06-07T23:23:34.6232110Z ##[endgroup]
2025-06-07T23:23:34.6233991Z ##[group]Determining the checkout info
2025-06-07T23:23:34.6236022Z ##[endgroup]
2025-06-07T23:23:34.6240728Z [command]/usr/bin/git sparse-checkout disable
2025-06-07T23:23:34.6282840Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2025-06-07T23:23:34.6311263Z ##[group]Checking out the ref
2025-06-07T23:23:34.6315242Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2025-06-07T23:23:34.6762280Z Switched to a new branch 'main'
2025-06-07T23:23:34.6764453Z branch 'main' set up to track 'origin/main'.
2025-06-07T23:23:34.6772753Z ##[endgroup]
2025-06-07T23:23:34.6814574Z [command]/usr/bin/git log -1 --format=%H
2025-06-07T23:23:34.6837971Z 63224c07a7ba4fd3150d60b6f60c79fd94cff7a2
2025-06-07T23:23:34.7212248Z ##[group]Run actions/setup-python@v5
2025-06-07T23:23:34.7213478Z with:
2025-06-07T23:23:34.7214348Z   python-version: 3.12
2025-06-07T23:23:34.7215573Z   cache: pip
2025-06-07T23:23:34.7216467Z   check-latest: false
2025-06-07T23:23:34.7217733Z   token: ***
2025-06-07T23:23:34.7218921Z   update-environment: true
2025-06-07T23:23:34.7220047Z   allow-prereleases: false
2025-06-07T23:23:34.7221119Z   freethreaded: false
2025-06-07T23:23:34.7222073Z env:
2025-06-07T23:23:34.7222911Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:34.7223879Z   MAX_TOKENS: 5000000
2025-06-07T23:23:34.7224845Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:34.7225775Z   FORCE_EVOLVE: 0
2025-06-07T23:23:34.7226696Z ##[endgroup]
2025-06-07T23:23:34.8903795Z ##[group]Installed versions
2025-06-07T23:23:34.8965598Z Successfully set up CPython (3.12.10)
2025-06-07T23:23:34.8968929Z ##[endgroup]
2025-06-07T23:23:34.9929544Z [command]/opt/hostedtoolcache/Python/3.12.10/x64/bin/pip cache dir
2025-06-07T23:23:35.6058801Z /home/runner/.cache/pip
2025-06-07T23:23:35.6973608Z Cache hit for: setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9
2025-06-07T23:23:36.2577835Z Received 88748529 of 88748529 (100.0%), 168.9 MBs/sec
2025-06-07T23:23:36.2579172Z Cache Size: ~85 MB (88748529 B)
2025-06-07T23:23:36.2609037Z [command]/usr/bin/tar -xf /home/runner/work/_temp/93b5cc72-95b4-4e43-8847-db820a536dda/cache.tzst -P -C /home/runner/work/Evolve/Evolve --use-compress-program unzstd
2025-06-07T23:23:36.4129949Z Cache restored successfully
2025-06-07T23:23:36.4306357Z Cache restored from key: setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9
2025-06-07T23:23:36.4458968Z ##[group]Run mkdir -p diagnostics csv_output
2025-06-07T23:23:36.4459389Z [36;1mmkdir -p diagnostics csv_output[0m
2025-06-07T23:23:36.4529494Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:36.4529746Z env:
2025-06-07T23:23:36.4529930Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:36.4530136Z   MAX_TOKENS: 5000000
2025-06-07T23:23:36.4530333Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:36.4530565Z   FORCE_EVOLVE: 0
2025-06-07T23:23:36.4530840Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4531265Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:36.4531680Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532039Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532418Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532780Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:36.4533079Z ##[endgroup]
2025-06-07T23:23:36.4666893Z ##[group]Run pip install -e '.[dev]'
2025-06-07T23:23:36.4667223Z [36;1mpip install -e '.[dev]'[0m
2025-06-07T23:23:36.4716239Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:36.4716487Z env:
2025-06-07T23:23:36.4716662Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:36.4716880Z   MAX_TOKENS: 5000000
2025-06-07T23:23:36.4717087Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:36.4717298Z   FORCE_EVOLVE: 0
2025-06-07T23:23:36.4717603Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4718017Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:36.4718660Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719037Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719398Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719768Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:36.4720072Z ##[endgroup]
2025-06-07T23:23:37.2693612Z Obtaining file:///home/runner/work/Evolve/Evolve
2025-06-07T23:23:37.2712037Z   Installing build dependencies: started
2025-06-07T23:23:37.9908793Z   Installing build dependencies: finished with status 'done'
2025-06-07T23:23:37.9915044Z   Checking if build backend supports build_editable: started
2025-06-07T23:23:38.2904886Z   Checking if build backend supports build_editable: finished with status 'done'
2025-06-07T23:23:38.2915849Z   Getting requirements to build editable: started
2025-06-07T23:23:38.6181864Z   Getting requirements to build editable: finished with status 'done'
2025-06-07T23:23:38.6191717Z   Preparing editable metadata (pyproject.toml): started
2025-06-07T23:23:38.8057517Z   Preparing editable metadata (pyproject.toml): finished with status 'done'
2025-06-07T23:23:38.8603097Z Collecting pdfplumber (from statement_refinery==0.1.0)
2025-06-07T23:23:38.8616538Z   Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)
2025-06-07T23:23:39.2028186Z Collecting ruff (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2042025Z   Using cached ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2025-06-07T23:23:39.2477484Z Collecting black (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2489804Z   Using cached black-25.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)
2025-06-07T23:23:39.2906105Z Collecting pytest (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2917577Z   Using cached pytest-8.4.0-py3-none-any.whl.metadata (7.7 kB)
2025-06-07T23:23:39.3085627Z Collecting pytest-cov (from statement_refinery==0.1.0)
2025-06-07T23:23:39.3096692Z   Using cached pytest_cov-6.1.1-py3-none-any.whl.metadata (28 kB)
2025-06-07T23:23:39.3284932Z Collecting pytest-xdist (from statement_refinery==0.1.0)
2025-06-07T23:23:39.3296463Z   Using cached pytest_xdist-3.7.0-py3-none-any.whl.metadata (3.0 kB)
2025-06-07T23:23:39.4176501Z Collecting mypy (from statement_refinery==0.1.0)
2025-06-07T23:23:39.4189327Z   Using cached mypy-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)
2025-06-07T23:23:39.4756594Z Collecting openai>=0 (from statement_refinery==0.1.0)
2025-06-07T23:23:39.4768830Z   Using cached openai-1.84.0-py3-none-any.whl.metadata (25 kB)
2025-06-07T23:23:39.5163553Z Collecting pre-commit (from statement_refinery==0.1.0)
2025-06-07T23:23:39.5175704Z   Using cached pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)
2025-06-07T23:23:39.5370796Z Collecting anyio<5,>=3.5.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5383458Z   Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)
2025-06-07T23:23:39.5516933Z Collecting distro<2,>=1.7.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5529033Z   Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
2025-06-07T23:23:39.5722288Z Collecting httpx<1,>=0.23.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5733855Z   Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2025-06-07T23:23:39.6317885Z Collecting jiter<1,>=0.4.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.6329791Z   Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
2025-06-07T23:23:39.7437056Z Collecting pydantic<3,>=1.9.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.7450091Z   Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)
2025-06-07T23:23:39.7560701Z Collecting sniffio (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.7572067Z   Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
2025-06-07T23:23:39.8105485Z Collecting tqdm>4 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8118094Z   Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2025-06-07T23:23:39.8319379Z Collecting typing-extensions<5,>=4.11 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8331364Z   Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)
2025-06-07T23:23:39.8453058Z Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8464830Z   Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
2025-06-07T23:23:39.8713665Z Collecting certifi (from httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8725347Z   Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:39.8903684Z Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8915593Z   Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:39.9033410Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.9045209Z   Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2025-06-07T23:23:39.9144886Z Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.9156707Z   Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
2025-06-07T23:23:40.4743951Z Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:40.4757462Z   Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
2025-06-07T23:23:40.4885859Z Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:40.4897394Z   Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)
2025-06-07T23:23:40.5496240Z Collecting click>=8.0.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5508725Z   Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:40.5598471Z Collecting mypy-extensions>=0.4.3 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5609672Z   Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)
2025-06-07T23:23:40.5774059Z Collecting packaging>=22.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5785501Z   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2025-06-07T23:23:40.5889549Z Collecting pathspec>=0.9.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5901242Z   Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:40.6077504Z Collecting platformdirs>=2 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.6089579Z   Using cached platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)
2025-06-07T23:23:40.6375249Z Collecting pdfminer.six==20250327 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.6387007Z   Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)
2025-06-07T23:23:40.8039926Z Collecting Pillow>=9.1 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.8052586Z   Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)
2025-06-07T23:23:40.8853089Z Collecting pypdfium2>=4.18.0 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.8864554Z   Using cached pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)
2025-06-07T23:23:40.9635649Z Collecting charset-normalizer>=2.0.0 (from pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.9648595Z   Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
2025-06-07T23:23:41.1272404Z Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.1285793Z   Using cached cryptography-45.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)
2025-06-07T23:23:41.2317090Z Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.2330309Z   Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)
2025-06-07T23:23:41.2437511Z Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.2451860Z   Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)
2025-06-07T23:23:41.2583535Z Collecting cfgv>=2.0.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.2594540Z   Using cached cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)
2025-06-07T23:23:41.3009600Z Collecting identify>=1.0.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3021147Z   Using cached identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)
2025-06-07T23:23:41.3596162Z Collecting nodeenv>=0.11.1 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3609129Z   Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:41.3939276Z Collecting pyyaml>=5.1 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3951357Z   Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
2025-06-07T23:23:41.4359166Z Collecting virtualenv>=20.10.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4370583Z   Using cached virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)
2025-06-07T23:23:41.4601274Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4612966Z   Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)
2025-06-07T23:23:41.4797419Z Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4809412Z   Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)
2025-06-07T23:23:41.5004107Z Collecting iniconfig>=1 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5015930Z   Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)
2025-06-07T23:23:41.5155545Z Collecting pluggy<2,>=1.5 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5167189Z   Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2025-06-07T23:23:41.5350784Z Collecting pygments>=2.7.2 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5362597Z   Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:41.8295320Z Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov->statement_refinery==0.1.0)
2025-06-07T23:23:41.8309136Z   Using cached coverage-7.8.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)
2025-06-07T23:23:41.8465971Z Collecting execnet>=2.1 (from pytest-xdist->statement_refinery==0.1.0)
2025-06-07T23:23:41.8477367Z   Using cached execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)
2025-06-07T23:23:41.8678878Z Using cached openai-1.84.0-py3-none-any.whl (725 kB)
2025-06-07T23:23:41.8694938Z Using cached anyio-4.9.0-py3-none-any.whl (100 kB)
2025-06-07T23:23:41.8706503Z Using cached distro-1.9.0-py3-none-any.whl (20 kB)
2025-06-07T23:23:41.8717392Z Using cached httpx-0.28.1-py3-none-any.whl (73 kB)
2025-06-07T23:23:41.8729132Z Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)
2025-06-07T23:23:41.8740553Z Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)
2025-06-07T23:23:41.8753628Z Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)
2025-06-07T23:23:41.8767756Z Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
2025-06-07T23:23:41.8792715Z Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)
2025-06-07T23:23:41.8803796Z Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
2025-06-07T23:23:41.8814433Z Using cached h11-0.16.0-py3-none-any.whl (37 kB)
2025-06-07T23:23:41.8825286Z Using cached idna-3.10-py3-none-any.whl (70 kB)
2025-06-07T23:23:41.8836497Z Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
2025-06-07T23:23:41.8847187Z Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
2025-06-07T23:23:41.8858560Z Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)
2025-06-07T23:23:41.8869951Z Using cached black-25.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)
2025-06-07T23:23:41.8893267Z Using cached click-8.2.1-py3-none-any.whl (102 kB)
2025-06-07T23:23:41.8904691Z Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)
2025-06-07T23:23:41.8915405Z Using cached packaging-25.0-py3-none-any.whl (66 kB)
2025-06-07T23:23:41.8926877Z Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)
2025-06-07T23:23:41.8937859Z Using cached platformdirs-4.3.8-py3-none-any.whl (18 kB)
2025-06-07T23:23:41.8948884Z Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)
2025-06-07T23:23:41.8961153Z Using cached mypy-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.7 MB)
2025-06-07T23:23:41.9061634Z Using cached pdfplumber-0.11.6-py3-none-any.whl (60 kB)
2025-06-07T23:23:41.9073365Z Using cached pdfminer_six-20250327-py3-none-any.whl (5.6 MB)
2025-06-07T23:23:41.9124964Z Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)
2025-06-07T23:23:41.9136643Z Using cached cryptography-45.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)
2025-06-07T23:23:41.9178839Z Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)
2025-06-07T23:23:41.9193076Z Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)
2025-06-07T23:23:41.9236154Z Using cached pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)
2025-06-07T23:23:41.9266336Z Using cached pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)
2025-06-07T23:23:41.9278511Z Using cached cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)
2025-06-07T23:23:41.9289693Z Using cached identify-2.6.12-py2.py3-none-any.whl (99 kB)
2025-06-07T23:23:41.9301221Z Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)
2025-06-07T23:23:41.9312452Z Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)
2025-06-07T23:23:41.9328211Z Using cached virtualenv-20.31.2-py3-none-any.whl (6.1 MB)
2025-06-07T23:23:41.9381438Z Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)
2025-06-07T23:23:41.9395375Z Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
2025-06-07T23:23:41.9406542Z Using cached pycparser-2.22-py3-none-any.whl (117 kB)
2025-06-07T23:23:41.9418761Z Using cached pytest-8.4.0-py3-none-any.whl (363 kB)
2025-06-07T23:23:41.9432223Z Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)
2025-06-07T23:23:41.9443278Z Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)
2025-06-07T23:23:41.9454170Z Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)
2025-06-07T23:23:41.9473703Z Using cached pytest_cov-6.1.1-py3-none-any.whl (23 kB)
2025-06-07T23:23:41.9485415Z Using cached coverage-7.8.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)
2025-06-07T23:23:41.9497385Z Using cached pytest_xdist-3.7.0-py3-none-any.whl (46 kB)
2025-06-07T23:23:41.9508626Z Using cached execnet-2.1.1-py3-none-any.whl (40 kB)
2025-06-07T23:23:41.9520264Z Using cached ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
2025-06-07T23:23:42.0493206Z Building wheels for collected packages: statement_refinery
2025-06-07T23:23:42.0501752Z   Building editable for statement_refinery (pyproject.toml): started
2025-06-07T23:23:42.2626889Z   Building editable for statement_refinery (pyproject.toml): finished with status 'done'
2025-06-07T23:23:42.2633291Z   Created wheel for statement_refinery: filename=statement_refinery-0.1.0-0.editable-py3-none-any.whl size=6066 sha256=2cd94dca6b5aa3e58787c9f86473642409a6143d2b7435e65108c513e99fb1a0
2025-06-07T23:23:42.2635168Z   Stored in directory: /tmp/pip-ephem-wheel-cache-9tzq7rmc/wheels/28/ef/08/2643d2d3176a016c9998941a41d908b9230622f970a4566ebe
2025-06-07T23:23:42.2657630Z Successfully built statement_refinery
2025-06-07T23:23:42.3584411Z Installing collected packages: distlib, typing-extensions, tqdm, sniffio, ruff, pyyaml, pypdfium2, pygments, pycparser, pluggy, platformdirs, Pillow, pathspec, packaging, nodeenv, mypy-extensions, jiter, iniconfig, idna, identify, h11, filelock, execnet, distro, coverage, click, charset-normalizer, cfgv, certifi, annotated-types, virtualenv, typing-inspection, pytest, pydantic-core, mypy, httpcore, cffi, black, anyio, pytest-xdist, pytest-cov, pydantic, pre-commit, httpx, cryptography, pdfminer.six, openai, pdfplumber, statement_refinery
2025-06-07T23:23:47.9024008Z 
2025-06-07T23:23:47.9074075Z Successfully installed Pillow-11.2.1 annotated-types-0.7.0 anyio-4.9.0 black-25.1.0 certifi-2025.4.26 cffi-1.17.1 cfgv-3.4.0 charset-normalizer-3.4.2 click-8.2.1 coverage-7.8.2 cryptography-45.0.3 distlib-0.3.9 distro-1.9.0 execnet-2.1.1 filelock-3.18.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 identify-2.6.12 idna-3.10 iniconfig-2.1.0 jiter-0.10.0 mypy-1.16.0 mypy-extensions-1.1.0 nodeenv-1.9.1 openai-1.84.0 packaging-25.0 pathspec-0.12.1 pdfminer.six-20250327 pdfplumber-0.11.6 platformdirs-4.3.8 pluggy-1.6.0 pre-commit-4.2.0 pycparser-2.22 pydantic-2.11.5 pydantic-core-2.33.2 pygments-2.19.1 pypdfium2-4.30.1 pytest-8.4.0 pytest-cov-6.1.1 pytest-xdist-3.7.0 pyyaml-6.0.2 ruff-0.11.13 sniffio-1.3.1 statement_refinery-0.1.0 tqdm-4.67.1 typing-extensions-4.14.0 typing-inspection-0.4.1 virtualenv-20.31.2
2025-06-07T23:23:48.3317180Z ##[group]Run pre-commit run --all-files --show-diff-on-failure || echo "::warning::lint failed (ignored)"
2025-06-07T23:23:48.3317910Z [36;1mpre-commit run --all-files --show-diff-on-failure || echo "::warning::lint failed (ignored)"[0m
2025-06-07T23:23:48.3370360Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:48.3370614Z env:
2025-06-07T23:23:48.3370792Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:48.3371003Z   MAX_TOKENS: 5000000
2025-06-07T23:23:48.3371196Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:48.3371381Z   FORCE_EVOLVE: 0
2025-06-07T23:23:48.3371643Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3372061Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:48.3372463Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3372818Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3373179Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3373576Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:48.3373887Z   GIT_ASKPASS: true
2025-06-07T23:23:48.3374081Z ##[endgroup]
2025-06-07T23:23:48.5051798Z [INFO] Initializing environment for https://github.com/astral-sh/ruff-pre-commit.
2025-06-07T23:23:48.6939634Z [INFO] Initializing environment for https://github.com/psf/black.
2025-06-07T23:23:48.9732082Z [INFO] Installing environment for https://github.com/astral-sh/ruff-pre-commit.
2025-06-07T23:23:48.9732881Z [INFO] Once installed this environment will be reused.
2025-06-07T23:23:48.9733383Z [INFO] This may take a few minutes...
2025-06-07T23:23:52.5257087Z [INFO] Installing environment for https://github.com/psf/black.
2025-06-07T23:23:52.5257659Z [INFO] Once installed this environment will be reused.
2025-06-07T23:23:52.5257999Z [INFO] This may take a few minutes...
2025-06-07T23:23:55.7315449Z ruff (auto-fix)..........................................................Failed
2025-06-07T23:23:55.7316070Z - hook id: ruff
2025-06-07T23:23:55.7316438Z - files were modified by this hook
2025-06-07T23:23:55.7316676Z 
2025-06-07T23:23:55.7317013Z scripts/comprehensive_analysis.py:21:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7317619Z    |
2025-06-07T23:23:55.7317892Z 19 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7318255Z 20 |
2025-06-07T23:23:55.7318784Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7319203Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7319716Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7320272Z    |
2025-06-07T23:23:55.7320423Z 
2025-06-07T23:23:55.7320783Z scripts/comprehensive_analysis.py:22:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7321428Z    |
2025-06-07T23:23:55.7321747Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7322334Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7322929Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7323341Z 23 |
2025-06-07T23:23:55.7323637Z 24 | logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:55.7324246Z    |
2025-06-07T23:23:55.7324362Z 
2025-06-07T23:23:55.7324722Z scripts/generate_golden_csvs.py:15:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7325350Z    |
2025-06-07T23:23:55.7325666Z 13 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7326147Z 14 |
2025-06-07T23:23:55.7326485Z 15 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7326958Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7327365Z 16 |
2025-06-07T23:23:55.7327832Z 17 | def generate_golden_csv(pdf_path: Path, output_dir: Path) -> Path:
2025-06-07T23:23:55.7328608Z    |
2025-06-07T23:23:55.7328771Z 
2025-06-07T23:23:55.7329198Z scripts/pattern_enhancer.py:35:13: F841 Local variable `count` is assigned to but never used
2025-06-07T23:23:55.7329881Z    |
2025-06-07T23:23:55.7330475Z 33 |         for pattern in discovered:
2025-06-07T23:23:55.7330968Z 34 |             structure = pattern["structure"]
2025-06-07T23:23:55.7331423Z 35 |             count = pattern["count"]
2025-06-07T23:23:55.7331835Z    |             ^^^^^ F841
2025-06-07T23:23:55.7332232Z 36 |             examples = pattern["examples"]
2025-06-07T23:23:55.7332664Z    |
2025-06-07T23:23:55.7333024Z    = help: Remove assignment to unused variable `count`
2025-06-07T23:23:55.7333380Z 
2025-06-07T23:23:55.7333744Z scripts/semantic_validator.py:19:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7334366Z    |
2025-06-07T23:23:55.7334685Z 17 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7335099Z 18 |
2025-06-07T23:23:55.7335434Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7335901Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7336500Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7337077Z    |
2025-06-07T23:23:55.7337241Z 
2025-06-07T23:23:55.7337590Z scripts/semantic_validator.py:20:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7338205Z    |
2025-06-07T23:23:55.7338778Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7339389Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7339939Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7340355Z 21 |
2025-06-07T23:23:55.7340665Z 22 | class SemanticValidator:
2025-06-07T23:23:55.7341038Z    |
2025-06-07T23:23:55.7341187Z 
2025-06-07T23:23:55.7341474Z scripts/semantic_validator.py:63:9: E722 Do not use bare `except`
2025-06-07T23:23:55.7342005Z    |
2025-06-07T23:23:55.7342286Z 61 |         try:
2025-06-07T23:23:55.7342715Z 62 |             pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:55.7343225Z 63 |         except:
2025-06-07T23:23:55.7343580Z    |         ^^^^^^ E722
2025-06-07T23:23:55.7343975Z 64 |             pass
2025-06-07T23:23:55.7344291Z    |
2025-06-07T23:23:55.7344450Z 
2025-06-07T23:23:55.7344831Z scripts/validate_real_accuracy.py:17:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7345474Z    |
2025-06-07T23:23:55.7345841Z 15 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7346289Z 16 |
2025-06-07T23:23:55.7346735Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7347287Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7347962Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7348712Z    |
2025-06-07T23:23:55.7348863Z 
2025-06-07T23:23:55.7349229Z scripts/validate_real_accuracy.py:18:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7349864Z    |
2025-06-07T23:23:55.7350188Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7350799Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7351403Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7351848Z 19 |
2025-06-07T23:23:55.7352240Z 20 | def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:55.7352919Z    |
2025-06-07T23:23:55.7353063Z 
2025-06-07T23:23:55.7353222Z Found 12 errors (3 fixed, 9 remaining).
2025-06-07T23:23:55.7353845Z No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
2025-06-07T23:23:55.7354360Z 
2025-06-07T23:23:55.7790879Z ruff (format)............................................................Failed
2025-06-07T23:23:55.7791550Z - hook id: ruff-format
2025-06-07T23:23:55.7791929Z - files were modified by this hook
2025-06-07T23:23:55.7792183Z 
2025-06-07T23:23:55.7792344Z 9 files reformatted, 15 files left unchanged
2025-06-07T23:23:55.7792628Z 
2025-06-07T23:23:56.8457712Z black check..............................................................Failed
2025-06-07T23:23:56.8458505Z - hook id: black
2025-06-07T23:23:56.8458888Z - exit code: 1
2025-06-07T23:23:56.8459472Z 
2025-06-07T23:23:56.8459688Z would reformat scripts/pattern_enhancer.py
2025-06-07T23:23:56.8460232Z would reformat scripts/validate_real_accuracy.py
2025-06-07T23:23:56.8460796Z would reformat scripts/incremental_learner.py
2025-06-07T23:23:56.8461358Z would reformat tests/test_pre_commit_config.py
2025-06-07T23:23:56.8461885Z would reformat scripts/semantic_validator.py
2025-06-07T23:23:56.8462227Z 
2025-06-07T23:23:56.8462774Z Oh no! ðŸ’¥ ðŸ’” ðŸ’¥
2025-06-07T23:23:56.8463261Z 5 files would be reformatted, 19 files would be left unchanged.
2025-06-07T23:23:56.8463633Z 
2025-06-07T23:23:56.8823316Z Export AI Patch..........................................................Passed
2025-06-07T23:23:56.8823877Z - hook id: export-ai-patch
2025-06-07T23:23:56.8824119Z - duration: 0s
2025-06-07T23:23:56.8824243Z 
2025-06-07T23:23:56.8824482Z cp: cannot stat 'diagnostics/ai-patch-unapplied.patch': No such file or directory
2025-06-07T23:23:56.8824822Z 
2025-06-07T23:23:56.8824940Z pre-commit hook(s) made changes.
2025-06-07T23:23:56.8825484Z If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
2025-06-07T23:23:56.8826035Z To run `pre-commit` as part of git workflow, use `pre-commit install`.
2025-06-07T23:23:56.8826499Z All changes made by hooks:
2025-06-07T23:23:56.9120736Z diff --git a/scripts/comprehensive_analysis.py b/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9121662Z index 2fb747f..5d85ede 100644
2025-06-07T23:23:56.9122151Z --- a/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9122666Z +++ b/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9123175Z @@ -24,9 +24,10 @@ from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9123694Z  logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:56.9124179Z  logger = logging.getLogger(__name__)
2025-06-07T23:23:56.9175240Z  
2025-06-07T23:23:56.9175511Z +
2025-06-07T23:23:56.9175798Z  class PatternAnalyzer:
2025-06-07T23:23:56.9176342Z      """Analyzes parsing patterns and failures across multiple PDFs."""
2025-06-07T23:23:56.9176896Z -    
2025-06-07T23:23:56.9177158Z +
2025-06-07T23:23:56.9177423Z      def __init__(self):
2025-06-07T23:23:56.9178094Z          self.parsed_lines = []
2025-06-07T23:23:56.9178642Z          self.failed_lines = []
2025-06-07T23:23:56.9179049Z @@ -36,15 +37,15 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9179468Z          self.merchant_patterns = set()
2025-06-07T23:23:56.9179858Z          self.totals_found = {}
2025-06-07T23:23:56.9180254Z          self.parsing_stats = defaultdict(int)
2025-06-07T23:23:56.9180680Z -        
2025-06-07T23:23:56.9180936Z +
2025-06-07T23:23:56.9181271Z      def analyze_pdf(self, pdf_path: Path) -> Dict:
2025-06-07T23:23:56.9181845Z          """Analyze a single PDF and extract parsing insights."""
2025-06-07T23:23:56.9182400Z          logger.info(f"Analyzing {pdf_path.name}")
2025-06-07T23:23:56.9182831Z -        
2025-06-07T23:23:56.9183087Z +
2025-06-07T23:23:56.9183331Z          try:
2025-06-07T23:23:56.9183644Z              # Extract lines from PDF
2025-06-07T23:23:56.9184112Z              lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9184558Z -            
2025-06-07T23:23:56.9185107Z +
2025-06-07T23:23:56.9185279Z              # Try to extract total
2025-06-07T23:23:56.9185524Z              pdf_total = None
2025-06-07T23:23:56.9185737Z              try:
2025-06-07T23:23:56.9185950Z @@ -52,15 +53,15 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9186251Z                  self.totals_found[pdf_path.name] = pdf_total
2025-06-07T23:23:56.9186544Z              except Exception as e:
2025-06-07T23:23:56.9186880Z                  logger.warning(f"Could not extract total from {pdf_path.name}: {e}")
2025-06-07T23:23:56.9187217Z -            
2025-06-07T23:23:56.9187386Z +
2025-06-07T23:23:56.9187560Z              # Parse lines and categorize
2025-06-07T23:23:56.9187817Z              parsed_transactions = []
2025-06-07T23:23:56.9188060Z              failed_lines = []
2025-06-07T23:23:56.9188698Z -            
2025-06-07T23:23:56.9188888Z +
2025-06-07T23:23:56.9189083Z              for line_num, line in enumerate(lines, 1):
2025-06-07T23:23:56.9189357Z                  if not line.strip():
2025-06-07T23:23:56.9189589Z                      continue
2025-06-07T23:23:56.9189791Z -                    
2025-06-07T23:23:56.9189970Z +
2025-06-07T23:23:56.9190184Z                  result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9190463Z                  if result:
2025-06-07T23:23:56.9190695Z                      parsed_transactions.append(result)
2025-06-07T23:23:56.9190978Z @@ -71,10 +72,12 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9191251Z                      if self._looks_like_transaction(line):
2025-06-07T23:23:56.9191542Z                          failed_lines.append((line_num, line))
2025-06-07T23:23:56.9191883Z                          self.failed_lines.append((pdf_path.name, line_num, line))
2025-06-07T23:23:56.9192184Z -            
2025-06-07T23:23:56.9192346Z +
2025-06-07T23:23:56.9192514Z              # Calculate CSV total
2025-06-07T23:23:56.9192858Z -            csv_total = sum(t.get("amount_brl", Decimal("0")) for t in parsed_transactions)
2025-06-07T23:23:56.9193194Z -            
2025-06-07T23:23:56.9193376Z +            csv_total = sum(
2025-06-07T23:23:56.9193689Z +                t.get("amount_brl", Decimal("0")) for t in parsed_transactions
2025-06-07T23:23:56.9193987Z +            )
2025-06-07T23:23:56.9194168Z +
2025-06-07T23:23:56.9194344Z              analysis = {
2025-06-07T23:23:56.9194564Z                  "pdf_name": pdf_path.name,
2025-06-07T23:23:56.9194812Z                  "total_lines": len(lines),
2025-06-07T23:23:56.9195069Z @@ -84,80 +87,89 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9195359Z                  "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9195745Z                  "total_delta": float(abs(csv_total - pdf_total)) if pdf_total else None,
2025-06-07T23:23:56.9196134Z                  "failed_lines": failed_lines[:10],  # First 10 for review
2025-06-07T23:23:56.9196604Z -                "success_rate": len(parsed_transactions) / max(1, len(parsed_transactions) + len(failed_lines))
2025-06-07T23:23:56.9197042Z +                "success_rate": len(parsed_transactions)
2025-06-07T23:23:56.9197363Z +                / max(1, len(parsed_transactions) + len(failed_lines)),
2025-06-07T23:23:56.9197639Z              }
2025-06-07T23:23:56.9197805Z -            
2025-06-07T23:23:56.9197964Z +
2025-06-07T23:23:56.9198140Z              self.parsing_stats["total_pdfs"] += 1
2025-06-07T23:23:56.9198596Z              self.parsing_stats["total_parsed"] += len(parsed_transactions)
2025-06-07T23:23:56.9198971Z              self.parsing_stats["total_failed"] += len(failed_lines)
2025-06-07T23:23:56.9199252Z -            
2025-06-07T23:23:56.9199409Z +
2025-06-07T23:23:56.9199569Z              return analysis
2025-06-07T23:23:56.9199766Z -            
2025-06-07T23:23:56.9199924Z +
2025-06-07T23:23:56.9200084Z          except Exception as e:
2025-06-07T23:23:56.9200377Z              logger.error(f"Error analyzing {pdf_path.name}: {e}")
2025-06-07T23:23:56.9200722Z              return {"pdf_name": pdf_path.name, "error": str(e)}
2025-06-07T23:23:56.9201117Z -    
2025-06-07T23:23:56.9201266Z +
2025-06-07T23:23:56.9201493Z      def _analyze_successful_parse(self, line: str, result: Dict):
2025-06-07T23:23:56.9201849Z          """Analyze successful parsing to understand patterns."""
2025-06-07T23:23:56.9202137Z          # Track amount formats
2025-06-07T23:23:56.9202424Z -        amount_match = re.search(r'-?\d{1,3}(?:\.\d{3})*,\d{2}', line)
2025-06-07T23:23:56.9202809Z +        amount_match = re.search(r"-?\d{1,3}(?:\.\d{3})*,\d{2}", line)
2025-06-07T23:23:56.9203107Z          if amount_match:
2025-06-07T23:23:56.9203354Z              self.amount_formats.add(amount_match.group())
2025-06-07T23:23:56.9203618Z -        
2025-06-07T23:23:56.9203789Z -        # Track date formats  
2025-06-07T23:23:56.9204147Z -        date_match = re.search(r'\d{1,2}/\d{1,2}', line)
2025-06-07T23:23:56.9204415Z +
2025-06-07T23:23:56.9204576Z +        # Track date formats
2025-06-07T23:23:56.9204820Z +        date_match = re.search(r"\d{1,2}/\d{1,2}", line)
2025-06-07T23:23:56.9205076Z          if date_match:
2025-06-07T23:23:56.9205311Z              self.date_formats.add(date_match.group())
2025-06-07T23:23:56.9205562Z -        
2025-06-07T23:23:56.9205718Z +
2025-06-07T23:23:56.9205883Z          # Track merchant patterns
2025-06-07T23:23:56.9206139Z          if result.get("desc_raw"):
2025-06-07T23:23:56.9206419Z              merchant = result["desc_raw"][:30]  # First 30 chars
2025-06-07T23:23:56.9206722Z              self.merchant_patterns.add(merchant)
2025-06-07T23:23:56.9206964Z -    
2025-06-07T23:23:56.9207113Z +
2025-06-07T23:23:56.9207319Z      def _looks_like_transaction(self, line: str) -> bool:
2025-06-07T23:23:56.9207679Z          """Heuristic to determine if a line might be a transaction."""
2025-06-07T23:23:56.9207994Z          line_upper = line.upper()
2025-06-07T23:23:56.9208211Z -        
2025-06-07T23:23:56.9208583Z +
2025-06-07T23:23:56.9208753Z          # Has amount pattern
2025-06-07T23:23:56.9209051Z -        has_amount = bool(re.search(r'\d{1,3}(?:\.\d{3})*,\d{2}', line))
2025-06-07T23:23:56.9209350Z -        
2025-06-07T23:23:56.9209579Z +        has_amount = bool(re.search(r"\d{1,3}(?:\.\d{3})*,\d{2}", line))
2025-06-07T23:23:56.9209862Z +
2025-06-07T23:23:56.9210015Z          # Has date pattern
2025-06-07T23:23:56.9210266Z -        has_date = bool(re.search(r'\d{1,2}/\d{1,2}', line))
2025-06-07T23:23:56.9210528Z -        
2025-06-07T23:23:56.9210738Z +        has_date = bool(re.search(r"\d{1,2}/\d{1,2}", line))
2025-06-07T23:23:56.9210998Z +
2025-06-07T23:23:56.9211166Z          # Skip obvious headers/footers
2025-06-07T23:23:56.9211406Z          skip_keywords = [
2025-06-07T23:23:56.9211688Z -            "FATURA", "VENCIMENTO", "LIMITE", "TOTAL", "PAGINA", "CARTAO",
2025-06-07T23:23:56.9212074Z -            "MASTERCARD", "VISA", "SAC", "OUVIDORIA", "TELEFONE", "EMAIL"
2025-06-07T23:23:56.9212372Z +            "FATURA",
2025-06-07T23:23:56.9212569Z +            "VENCIMENTO",
2025-06-07T23:23:56.9212766Z +            "LIMITE",
2025-06-07T23:23:56.9212951Z +            "TOTAL",
2025-06-07T23:23:56.9213135Z +            "PAGINA",
2025-06-07T23:23:56.9213320Z +            "CARTAO",
2025-06-07T23:23:56.9213504Z +            "MASTERCARD",
2025-06-07T23:23:56.9213699Z +            "VISA",
2025-06-07T23:23:56.9213873Z +            "SAC",
2025-06-07T23:23:56.9214053Z +            "OUVIDORIA",
2025-06-07T23:23:56.9214253Z +            "TELEFONE",
2025-06-07T23:23:56.9214440Z +            "EMAIL",
2025-06-07T23:23:56.9214614Z          ]
2025-06-07T23:23:56.9214773Z -        
2025-06-07T23:23:56.9214927Z +
2025-06-07T23:23:56.9215162Z          has_skip_keyword = any(kw in line_upper for kw in skip_keywords)
2025-06-07T23:23:56.9215464Z -        
2025-06-07T23:23:56.9215620Z +
2025-06-07T23:23:56.9215850Z          return (has_amount or has_date) and not has_skip_keyword
2025-06-07T23:23:56.9216134Z -    
2025-06-07T23:23:56.9216285Z +
2025-06-07T23:23:56.9216474Z      def discover_new_patterns(self) -> List[str]:
2025-06-07T23:23:56.9216787Z          """Analyze failed lines to discover new patterns."""
2025-06-07T23:23:56.9217200Z          patterns = []
2025-06-07T23:23:56.9217380Z -        
2025-06-07T23:23:56.9217531Z +
2025-06-07T23:23:56.9217707Z          # Group failed lines by similarity
2025-06-07T23:23:56.9217978Z          failed_by_structure = defaultdict(list)
2025-06-07T23:23:56.9218222Z -        
2025-06-07T23:23:56.9218484Z +
2025-06-07T23:23:56.9218687Z          for pdf_name, line_num, line in self.failed_lines:
2025-06-07T23:23:56.9218977Z              # Create structural signature
2025-06-07T23:23:56.9219296Z -            structure = re.sub(r'\d+', 'N', line)  # Replace numbers with N
2025-06-07T23:23:56.9219703Z -            structure = re.sub(r'[A-Za-z]+', 'W', structure)  # Replace words with W
2025-06-07T23:23:56.9220214Z +            structure = re.sub(r"\d+", "N", line)  # Replace numbers with N
2025-06-07T23:23:56.9220602Z +            structure = re.sub(r"[A-Za-z]+", "W", structure)  # Replace words with W
2025-06-07T23:23:56.9220961Z              failed_by_structure[structure].append(line)
2025-06-07T23:23:56.9221221Z -        
2025-06-07T23:23:56.9221377Z +
2025-06-07T23:23:56.9221534Z          # Find common structures
2025-06-07T23:23:56.9221813Z          for structure, lines in failed_by_structure.items():
2025-06-07T23:23:56.9222149Z              if len(lines) >= 2:  # Pattern appears in multiple lines
2025-06-07T23:23:56.9222452Z -                patterns.append({
2025-06-07T23:23:56.9222705Z -                    "structure": structure,
2025-06-07T23:23:56.9222954Z -                    "count": len(lines),
2025-06-07T23:23:56.9223195Z -                    "examples": lines[:3]
2025-06-07T23:23:56.9223427Z -                })
2025-06-07T23:23:56.9223601Z -        
2025-06-07T23:23:56.9223773Z +                patterns.append(
2025-06-07T23:23:56.9224092Z +                    {"structure": structure, "count": len(lines), "examples": lines[:3]}
2025-06-07T23:23:56.9224423Z +                )
2025-06-07T23:23:56.9224594Z +
2025-06-07T23:23:56.9224757Z          return patterns
2025-06-07T23:23:56.9224949Z -    
2025-06-07T23:23:56.9225102Z +
2025-06-07T23:23:56.9225277Z      def generate_report(self) -> Dict:
2025-06-07T23:23:56.9225558Z          """Generate comprehensive analysis report."""
2025-06-07T23:23:56.9225814Z          return {
2025-06-07T23:23:56.9226023Z @@ -165,82 +177,106 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9226346Z                  "total_pdfs_analyzed": self.parsing_stats["total_pdfs"],
2025-06-07T23:23:56.9226741Z                  "total_transactions_parsed": self.parsing_stats["total_parsed"],
2025-06-07T23:23:56.9227135Z                  "total_failed_lines": self.parsing_stats["total_failed"],
2025-06-07T23:23:56.9227735Z -                "overall_success_rate": self.parsing_stats["total_parsed"] / max(1, self.parsing_stats["total_parsed"] + self.parsing_stats["total_failed"])
2025-06-07T23:23:56.9228434Z +                "overall_success_rate": self.parsing_stats["total_parsed"]
2025-06-07T23:23:56.9228870Z +                / max(
2025-06-07T23:23:56.9229066Z +                    1,
2025-06-07T23:23:56.9229277Z +                    self.parsing_stats["total_parsed"]
2025-06-07T23:23:56.9229567Z +                    + self.parsing_stats["total_failed"],
2025-06-07T23:23:56.9229816Z +                ),
2025-06-07T23:23:56.9229990Z              },
2025-06-07T23:23:56.9230176Z              "pattern_insights": {
2025-06-07T23:23:56.9230460Z                  "unique_amount_formats": len(self.amount_formats),
2025-06-07T23:23:56.9230788Z                  "unique_date_formats": len(self.date_formats),
2025-06-07T23:23:56.9231127Z                  "unique_merchant_patterns": len(self.merchant_patterns),
2025-06-07T23:23:56.9231494Z                  "amount_format_examples": list(self.amount_formats)[:10],
2025-06-07T23:23:56.9231852Z -                "date_format_examples": list(self.date_formats)[:10]
2025-06-07T23:23:56.9232198Z +                "date_format_examples": list(self.date_formats)[:10],
2025-06-07T23:23:56.9232472Z              },
2025-06-07T23:23:56.9232843Z              "discovered_patterns": self.discover_new_patterns(),
2025-06-07T23:23:56.9233140Z              "totals_extraction": {
2025-06-07T23:23:56.9233413Z                  "successful_extractions": len(self.totals_found),
2025-06-07T23:23:56.9233830Z -                "failed_extractions": self.parsing_stats["total_pdfs"] - len(self.totals_found),
2025-06-07T23:23:56.9234243Z -                "extracted_totals": self.totals_found
2025-06-07T23:23:56.9234498Z -            }
2025-06-07T23:23:56.9234747Z +                "failed_extractions": self.parsing_stats["total_pdfs"]
2025-06-07T23:23:56.9235070Z +                - len(self.totals_found),
2025-06-07T23:23:56.9235356Z +                "extracted_totals": self.totals_found,
2025-06-07T23:23:56.9235749Z +            },
2025-06-07T23:23:56.9235924Z          }
2025-06-07T23:23:56.9236078Z  
2025-06-07T23:23:56.9236223Z  
2025-06-07T23:23:56.9236371Z  def main():
2025-06-07T23:23:56.9236754Z -    parser = argparse.ArgumentParser(description="Comprehensive PDF analysis for pattern discovery")
2025-06-07T23:23:56.9237227Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9237570Z +        description="Comprehensive PDF analysis for pattern discovery"
2025-06-07T23:23:56.9237884Z +    )
2025-06-07T23:23:56.9238147Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9238755Z -    parser.add_argument("--output", "-o", default="diagnostics/comprehensive_analysis.json", 
2025-06-07T23:23:56.9239183Z -                       help="Output file for analysis report")
2025-06-07T23:23:56.9239464Z +    parser.add_argument(
2025-06-07T23:23:56.9239671Z +        "--output",
2025-06-07T23:23:56.9239858Z +        "-o",
2025-06-07T23:23:56.9240096Z +        default="diagnostics/comprehensive_analysis.json",
2025-06-07T23:23:56.9240415Z +        help="Output file for analysis report",
2025-06-07T23:23:56.9240656Z +    )
2025-06-07T23:23:56.9240834Z      args = parser.parse_args()
2025-06-07T23:23:56.9241051Z -    
2025-06-07T23:23:56.9241203Z +
2025-06-07T23:23:56.9241366Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9241604Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9241876Z          logger.error(f"Directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9242152Z          return 1
2025-06-07T23:23:56.9242318Z -    
2025-06-07T23:23:56.9242470Z +
2025-06-07T23:23:56.9242633Z      # Create output directory
2025-06-07T23:23:56.9242866Z      output_path = Path(args.output)
2025-06-07T23:23:56.9243171Z      output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9243450Z -    
2025-06-07T23:23:56.9243601Z +
2025-06-07T23:23:56.9243763Z      analyzer = PatternAnalyzer()
2025-06-07T23:23:56.9243993Z      pdf_analyses = []
2025-06-07T23:23:56.9244178Z -    
2025-06-07T23:23:56.9244329Z +
2025-06-07T23:23:56.9244486Z      # Analyze all PDFs
2025-06-07T23:23:56.9244724Z      for pdf_path in sorted(pdf_dir.glob("*.pdf")):
2025-06-07T23:23:56.9245034Z          analysis = analyzer.analyze_pdf(pdf_path)
2025-06-07T23:23:56.9245323Z          pdf_analyses.append(analysis)
2025-06-07T23:23:56.9245551Z -        
2025-06-07T23:23:56.9245706Z +
2025-06-07T23:23:56.9245867Z          # Print brief summary
2025-06-07T23:23:56.9246089Z          if "error" not in analysis:
2025-06-07T23:23:56.9246373Z              success_rate = analysis.get("success_rate", 0) * 100
2025-06-07T23:23:56.9246771Z -            logger.info(f"{pdf_path.name}: {analysis['parsed_transactions']} parsed, "
2025-06-07T23:23:56.9247280Z -                       f"{analysis['failed_potential_transactions']} failed ({success_rate:.1f}% success)")
2025-06-07T23:23:56.9247654Z -    
2025-06-07T23:23:56.9247818Z +            logger.info(
2025-06-07T23:23:56.9248100Z +                f"{pdf_path.name}: {analysis['parsed_transactions']} parsed, "
2025-06-07T23:23:56.9248759Z +                f"{analysis['failed_potential_transactions']} failed ({success_rate:.1f}% success)"
2025-06-07T23:23:56.9249134Z +            )
2025-06-07T23:23:56.9249431Z +
2025-06-07T23:23:56.9249604Z      # Generate comprehensive report
2025-06-07T23:23:56.9249867Z      report = analyzer.generate_report()
2025-06-07T23:23:56.9250140Z      report["individual_pdfs"] = pdf_analyses
2025-06-07T23:23:56.9250382Z -    
2025-06-07T23:23:56.9250532Z +
2025-06-07T23:23:56.9250679Z      # Save report
2025-06-07T23:23:56.9250884Z -    with open(output_path, 'w') as f:
2025-06-07T23:23:56.9251134Z +    with open(output_path, "w") as f:
2025-06-07T23:23:56.9251409Z          json.dump(report, f, indent=2, default=str)
2025-06-07T23:23:56.9251665Z -    
2025-06-07T23:23:56.9251813Z +
2025-06-07T23:23:56.9252069Z      logger.info(f"Analysis complete. Report saved to {output_path}")
2025-06-07T23:23:56.9252380Z -    
2025-06-07T23:23:56.9252524Z +
2025-06-07T23:23:56.9252785Z      # Print summary
2025-06-07T23:23:56.9252987Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9253192Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9253427Z      print("COMPREHENSIVE ANALYSIS SUMMARY")
2025-06-07T23:23:56.9253679Z -    print("="*60)
2025-06-07T23:23:56.9253860Z +    print("=" * 60)
2025-06-07T23:23:56.9254133Z      print(f"PDFs Analyzed: {report['summary']['total_pdfs_analyzed']}")
2025-06-07T23:23:56.9254584Z      print(f"Transactions Parsed: {report['summary']['total_transactions_parsed']}")
2025-06-07T23:23:56.9255023Z      print(f"Failed Lines: {report['summary']['total_failed_lines']}")
2025-06-07T23:23:56.9255447Z      print(f"Overall Success Rate: {report['summary']['overall_success_rate']:.1%}")
2025-06-07T23:23:56.9255942Z -    print(f"Unique Amount Formats: {report['pattern_insights']['unique_amount_formats']}")
2025-06-07T23:23:56.9256315Z +    print(
2025-06-07T23:23:56.9256610Z +        f"Unique Amount Formats: {report['pattern_insights']['unique_amount_formats']}"
2025-06-07T23:23:56.9256962Z +    )
2025-06-07T23:23:56.9257225Z      print(f"Discovered Patterns: {len(report['discovered_patterns'])}")
2025-06-07T23:23:56.9257870Z -    print(f"Total Extractions Successful: {report['totals_extraction']['successful_extractions']}/{report['summary']['total_pdfs_analyzed']}")
2025-06-07T23:23:56.9258509Z -    
2025-06-07T23:23:56.9258684Z -    if report['discovered_patterns']:
2025-06-07T23:23:56.9258917Z +    print(
2025-06-07T23:23:56.9259369Z +        f"Total Extractions Successful: {report['totals_extraction']['successful_extractions']}/{report['summary']['total_pdfs_analyzed']}"
2025-06-07T23:23:56.9259871Z +    )
2025-06-07T23:23:56.9260020Z +
2025-06-07T23:23:56.9260190Z +    if report["discovered_patterns"]:
2025-06-07T23:23:56.9260464Z          print("\nMOST COMMON FAILED PATTERNS:")
2025-06-07T23:23:56.9260944Z -        for i, pattern in enumerate(sorted(report['discovered_patterns'], key=lambda x: x['count'], reverse=True)[:5]):
2025-06-07T23:23:56.9261534Z -            print(f"{i+1}. Structure: {pattern['structure']} (appears {pattern['count']} times)")
2025-06-07T23:23:56.9261914Z +        for i, pattern in enumerate(
2025-06-07T23:23:56.9262143Z +            sorted(
2025-06-07T23:23:56.9262440Z +                report["discovered_patterns"], key=lambda x: x["count"], reverse=True
2025-06-07T23:23:56.9262765Z +            )[:5]
2025-06-07T23:23:56.9262935Z +        ):
2025-06-07T23:23:56.9263097Z +            print(
2025-06-07T23:23:56.9263399Z +                f"{i + 1}. Structure: {pattern['structure']} (appears {pattern['count']} times)"
2025-06-07T23:23:56.9263731Z +            )
2025-06-07T23:23:56.9263954Z              print(f"   Example: {pattern['examples'][0]}")
2025-06-07T23:23:56.9264215Z -    
2025-06-07T23:23:56.9264362Z +
2025-06-07T23:23:56.9264509Z      return 0
2025-06-07T23:23:56.9264673Z  
2025-06-07T23:23:56.9264816Z  
2025-06-07T23:23:56.9265108Z diff --git a/scripts/generate_golden_csvs.py b/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9265483Z index 5e375ac..22ac203 100644
2025-06-07T23:23:56.9265712Z --- a/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9265961Z +++ b/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9266349Z @@ -14,89 +14,94 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9266605Z  
2025-06-07T23:23:56.9266788Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9267024Z  
2025-06-07T23:23:56.9267169Z +
2025-06-07T23:23:56.9267413Z  def generate_golden_csv(pdf_path: Path, output_dir: Path) -> Path:
2025-06-07T23:23:56.9267763Z      """Generate golden CSV for a single PDF."""
2025-06-07T23:23:56.9268072Z      # Extract the date part from filename for golden CSV name
2025-06-07T23:23:56.9268522Z      pdf_name = pdf_path.stem
2025-06-07T23:23:56.9268825Z -    if '_' in pdf_name:
2025-06-07T23:23:56.9269059Z -        date_part = pdf_name.split('_')[-1]
2025-06-07T23:23:56.9269310Z +    if "_" in pdf_name:
2025-06-07T23:23:56.9269533Z +        date_part = pdf_name.split("_")[-1]
2025-06-07T23:23:56.9269887Z      else:
2025-06-07T23:23:56.9270145Z -        date_part = pdf_name.lower().replace('itau', '').replace('-', '')
2025-06-07T23:23:56.9270461Z -    
2025-06-07T23:23:56.9270702Z +        date_part = pdf_name.lower().replace("itau", "").replace("-", "")
2025-06-07T23:23:56.9271024Z +
2025-06-07T23:23:56.9271204Z      golden_name = f"golden_{date_part}.csv"
2025-06-07T23:23:56.9271467Z      golden_path = output_dir / golden_name
2025-06-07T23:23:56.9271701Z -    
2025-06-07T23:23:56.9271846Z +
2025-06-07T23:23:56.9272066Z      print(f"Generating {golden_name} from {pdf_path.name}")
2025-06-07T23:23:56.9272343Z -    
2025-06-07T23:23:56.9272492Z +
2025-06-07T23:23:56.9272759Z      # Generate CSV using current parser - call directly without file conflicts
2025-06-07T23:23:56.9273095Z      import io
2025-06-07T23:23:56.9273279Z      import contextlib
2025-06-07T23:23:56.9273493Z -    
2025-06-07T23:23:56.9273636Z +
2025-06-07T23:23:56.9273792Z      # Capture output
2025-06-07T23:23:56.9273998Z      buffer = io.StringIO()
2025-06-07T23:23:56.9274237Z      with contextlib.redirect_stdout(buffer):
2025-06-07T23:23:56.9274510Z          pdf_to_csv.main([str(pdf_path)])
2025-06-07T23:23:56.9274769Z -    
2025-06-07T23:23:56.9274924Z +
2025-06-07T23:23:56.9275084Z      # Write to golden file
2025-06-07T23:23:56.9275302Z -    with open(golden_path, 'w') as f:
2025-06-07T23:23:56.9275551Z +    with open(golden_path, "w") as f:
2025-06-07T23:23:56.9275798Z          f.write(buffer.getvalue())
2025-06-07T23:23:56.9276018Z -    
2025-06-07T23:23:56.9276170Z +
2025-06-07T23:23:56.9276555Z      print(f"  â†’ Generated {golden_path.name}")
2025-06-07T23:23:56.9276823Z      return golden_path
2025-06-07T23:23:56.9277011Z  
2025-06-07T23:23:56.9277149Z +
2025-06-07T23:23:56.9277300Z  def main():
2025-06-07T23:23:56.9277599Z      parser = argparse.ArgumentParser(description="Generate golden CSV files")
2025-06-07T23:23:56.9278056Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9278586Z -    parser.add_argument("--output-dir", default="tests/data", 
2025-06-07T23:23:56.9278930Z -                       help="Directory to write golden CSV files")
2025-06-07T23:23:56.9279266Z -    parser.add_argument("--force", action="store_true",
2025-06-07T23:23:56.9279594Z -                       help="Overwrite existing golden files")
2025-06-07T23:23:56.9279863Z +    parser.add_argument(
2025-06-07T23:23:56.9280199Z +        "--output-dir", default="tests/data", help="Directory to write golden CSV files"
2025-06-07T23:23:56.9280553Z +    )
2025-06-07T23:23:56.9280726Z +    parser.add_argument(
2025-06-07T23:23:56.9281024Z +        "--force", action="store_true", help="Overwrite existing golden files"
2025-06-07T23:23:56.9281347Z +    )
2025-06-07T23:23:56.9281524Z      args = parser.parse_args()
2025-06-07T23:23:56.9281733Z -    
2025-06-07T23:23:56.9281886Z +
2025-06-07T23:23:56.9282045Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9282294Z      output_dir = Path(args.output_dir)
2025-06-07T23:23:56.9282533Z -    
2025-06-07T23:23:56.9282680Z +
2025-06-07T23:23:56.9282843Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9283125Z          print(f"Error: PDF directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9283531Z          return 1
2025-06-07T23:23:56.9283704Z -    
2025-06-07T23:23:56.9283846Z +
2025-06-07T23:23:56.9284036Z      output_dir.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9284296Z -    
2025-06-07T23:23:56.9284445Z +
2025-06-07T23:23:56.9284600Z      # Find all PDFs
2025-06-07T23:23:56.9284813Z      pdf_files = list(pdf_dir.glob("*.pdf"))
2025-06-07T23:23:56.9285091Z      print(f"Found {len(pdf_files)} PDF files")
2025-06-07T23:23:56.9285333Z -    
2025-06-07T23:23:56.9285484Z +
2025-06-07T23:23:56.9285633Z      generated = 0
2025-06-07T23:23:56.9285815Z      skipped = 0
2025-06-07T23:23:56.9285989Z -    
2025-06-07T23:23:56.9286134Z +
2025-06-07T23:23:56.9286304Z      for pdf_path in sorted(pdf_files):
2025-06-07T23:23:56.9286674Z          # Check if golden CSV already exists
2025-06-07T23:23:56.9286926Z          pdf_name = pdf_path.stem
2025-06-07T23:23:56.9287156Z -        if '_' in pdf_name:
2025-06-07T23:23:56.9287399Z -            date_part = pdf_name.split('_')[-1]
2025-06-07T23:23:56.9287658Z +        if "_" in pdf_name:
2025-06-07T23:23:56.9287888Z +            date_part = pdf_name.split("_")[-1]
2025-06-07T23:23:56.9288126Z          else:
2025-06-07T23:23:56.9288584Z -            date_part = pdf_name.lower().replace('itau', '').replace('-', '')
2025-06-07T23:23:56.9288900Z -        
2025-06-07T23:23:56.9289141Z +            date_part = pdf_name.lower().replace("itau", "").replace("-", "")
2025-06-07T23:23:56.9289441Z +
2025-06-07T23:23:56.9289622Z          golden_name = f"golden_{date_part}.csv"
2025-06-07T23:23:56.9289895Z          golden_path = output_dir / golden_name
2025-06-07T23:23:56.9290136Z -        
2025-06-07T23:23:56.9290294Z +
2025-06-07T23:23:56.9290485Z          if golden_path.exists() and not args.force:
2025-06-07T23:23:56.9290846Z              print(f"Skipping {pdf_path.name} - {golden_name} already exists")
2025-06-07T23:23:56.9291170Z              skipped += 1
2025-06-07T23:23:56.9291365Z              continue
2025-06-07T23:23:56.9291553Z -        
2025-06-07T23:23:56.9291706Z +
2025-06-07T23:23:56.9291853Z          try:
2025-06-07T23:23:56.9292066Z              generate_golden_csv(pdf_path, output_dir)
2025-06-07T23:23:56.9292330Z              generated += 1
2025-06-07T23:23:56.9292548Z          except Exception as e:
2025-06-07T23:23:56.9292832Z              print(f"Error generating CSV for {pdf_path.name}: {e}")
2025-06-07T23:23:56.9293114Z -    
2025-06-07T23:23:56.9293266Z +
2025-06-07T23:23:56.9293422Z      print("\nSummary:")
2025-06-07T23:23:56.9293643Z      print(f"  Generated: {generated}")
2025-06-07T23:23:56.9293899Z      print(f"  Skipped: {skipped}")
2025-06-07T23:23:56.9294157Z      print(f"  Total PDFs: {len(pdf_files)}")
2025-06-07T23:23:56.9294391Z -    
2025-06-07T23:23:56.9294535Z +
2025-06-07T23:23:56.9294686Z      return 0
2025-06-07T23:23:56.9294849Z  
2025-06-07T23:23:56.9294990Z +
2025-06-07T23:23:56.9295155Z  if __name__ == "__main__":
2025-06-07T23:23:56.9295358Z      sys.exit(main())
2025-06-07T23:23:56.9295688Z diff --git a/scripts/incremental_learner.py b/scripts/incremental_learner.py
2025-06-07T23:23:56.9296052Z index a335e17..9e85598 100644
2025-06-07T23:23:56.9296280Z --- a/scripts/incremental_learner.py
2025-06-07T23:23:56.9296533Z +++ b/scripts/incremental_learner.py
2025-06-07T23:23:56.9296807Z @@ -19,7 +19,7 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9297065Z  
2025-06-07T23:23:56.9297236Z  class IncrementalLearner:
2025-06-07T23:23:56.9297537Z      """Learns from validation feedback to improve parsing patterns."""
2025-06-07T23:23:56.9297845Z -    
2025-06-07T23:23:56.9297997Z +
2025-06-07T23:23:56.9298147Z      def __init__(self):
2025-06-07T23:23:56.9298462Z          self.learned_patterns = []
2025-06-07T23:23:56.9298707Z          self.pattern_confidence = {}
2025-06-07T23:23:56.9298969Z @@ -28,77 +28,81 @@ class IncrementalLearner:
2025-06-07T23:23:56.9299235Z              "initial_success_rate": 0.0,
2025-06-07T23:23:56.9299489Z              "current_success_rate": 0.0,
2025-06-07T23:23:56.9299858Z              "patterns_added": 0,
2025-06-07T23:23:56.9300095Z -            "transactions_recovered": 0
2025-06-07T23:23:56.9300349Z +            "transactions_recovered": 0,
2025-06-07T23:23:56.9300572Z          }
2025-06-07T23:23:56.9300731Z -    
2025-06-07T23:23:56.9301068Z -    def analyze_missing_transactions(self, pdf_path: Path, validation_results: Dict) -> List[Dict]:
2025-06-07T23:23:56.9301467Z +
2025-06-07T23:23:56.9301640Z +    def analyze_missing_transactions(
2025-06-07T23:23:56.9301921Z +        self, pdf_path: Path, validation_results: Dict
2025-06-07T23:23:56.9302188Z +    ) -> List[Dict]:
2025-06-07T23:23:56.9302457Z          """Analyze missing transactions to discover new patterns."""
2025-06-07T23:23:56.9302749Z -        
2025-06-07T23:23:56.9302909Z +
2025-06-07T23:23:56.9303345Z          missing_lines = validation_results["missing_transactions"]["missing_lines"]
2025-06-07T23:23:56.9303716Z          new_patterns = []
2025-06-07T23:23:56.9303916Z -        
2025-06-07T23:23:56.9304076Z +
2025-06-07T23:23:56.9304248Z          # Group similar missing lines
2025-06-07T23:23:56.9304509Z          pattern_groups = defaultdict(list)
2025-06-07T23:23:56.9304743Z -        
2025-06-07T23:23:56.9304895Z +
2025-06-07T23:23:56.9305062Z          for missing in missing_lines:
2025-06-07T23:23:56.9305320Z              if missing["confidence"] == "high":
2025-06-07T23:23:56.9305596Z                  line = missing["line_content"]
2025-06-07T23:23:56.9305837Z -                
2025-06-07T23:23:56.9306007Z +
2025-06-07T23:23:56.9306186Z                  # Create structural signature
2025-06-07T23:23:56.9306481Z                  structure = self._create_structure_signature(line)
2025-06-07T23:23:56.9306807Z                  pattern_groups[structure].append(line)
2025-06-07T23:23:56.9307064Z -        
2025-06-07T23:23:56.9307220Z +
2025-06-07T23:23:56.9307433Z          # Generate patterns for groups with multiple examples
2025-06-07T23:23:56.9307773Z          for structure, examples in pattern_groups.items():
2025-06-07T23:23:56.9308109Z              if len(examples) >= 2:  # Need at least 2 examples
2025-06-07T23:23:56.9308639Z                  pattern = self._generate_pattern_from_examples(structure, examples)
2025-06-07T23:23:56.9309056Z                  if pattern:
2025-06-07T23:23:56.9309297Z                      new_patterns.append(pattern)
2025-06-07T23:23:56.9309542Z -        
2025-06-07T23:23:56.9309700Z +
2025-06-07T23:23:56.9309861Z          return new_patterns
2025-06-07T23:23:56.9310064Z -    
2025-06-07T23:23:56.9310219Z +
2025-06-07T23:23:56.9310445Z      def _create_structure_signature(self, line: str) -> str:
2025-06-07T23:23:56.9310803Z          """Create a structural signature for pattern matching."""
2025-06-07T23:23:56.9311134Z          # Replace specific patterns with placeholders
2025-06-07T23:23:56.9311405Z          sig = line
2025-06-07T23:23:56.9311589Z -        
2025-06-07T23:23:56.9311743Z +
2025-06-07T23:23:56.9311902Z          # Replace amounts
2025-06-07T23:23:56.9312170Z -        sig = re.sub(r'\d{1,3}(?:\.\d{3})*,\d{2}', 'AMOUNT', sig)
2025-06-07T23:23:56.9312442Z -        
2025-06-07T23:23:56.9312651Z +        sig = re.sub(r"\d{1,3}(?:\.\d{3})*,\d{2}", "AMOUNT", sig)
2025-06-07T23:23:56.9312909Z +
2025-06-07T23:23:56.9313069Z          # Replace dates
2025-06-07T23:23:56.9313302Z -        sig = re.sub(r'\d{1,2}/\d{1,2}', 'DATE', sig)
2025-06-07T23:23:56.9313552Z -        
2025-06-07T23:23:56.9313739Z +        sig = re.sub(r"\d{1,2}/\d{1,2}", "DATE", sig)
2025-06-07T23:23:56.9313982Z +
2025-06-07T23:23:56.9314145Z          # Replace card numbers
2025-06-07T23:23:56.9314380Z -        sig = re.sub(r'\d{4}', 'CARD', sig)
2025-06-07T23:23:56.9314612Z -        
2025-06-07T23:23:56.9314791Z +        sig = re.sub(r"\d{4}", "CARD", sig)
2025-06-07T23:23:56.9315022Z +
2025-06-07T23:23:56.9315198Z          # Replace long number sequences
2025-06-07T23:23:56.9315466Z -        sig = re.sub(r'\d{4,}', 'LONGNUM', sig)
2025-06-07T23:23:56.9315707Z -        
2025-06-07T23:23:56.9316026Z +        sig = re.sub(r"\d{4,}", "LONGNUM", sig)
2025-06-07T23:23:56.9316259Z +
2025-06-07T23:23:56.9316421Z          # Replace remaining numbers
2025-06-07T23:23:56.9316663Z -        sig = re.sub(r'\d+', 'NUM', sig)
2025-06-07T23:23:56.9316891Z -        
2025-06-07T23:23:56.9317065Z +        sig = re.sub(r"\d+", "NUM", sig)
2025-06-07T23:23:56.9317291Z +
2025-06-07T23:23:56.9317456Z          # Normalize whitespace
2025-06-07T23:23:56.9317693Z -        sig = re.sub(r'\s+', ' ', sig).strip()
2025-06-07T23:23:56.9317934Z -        
2025-06-07T23:23:56.9318107Z +        sig = re.sub(r"\s+", " ", sig).strip()
2025-06-07T23:23:56.9318573Z +
2025-06-07T23:23:56.9318730Z          return sig
2025-06-07T23:23:56.9318908Z -    
2025-06-07T23:23:56.9319373Z -    def _generate_pattern_from_examples(self, structure: str, examples: List[str]) -> Optional[Dict]:
2025-06-07T23:23:56.9319782Z +
2025-06-07T23:23:56.9319955Z +    def _generate_pattern_from_examples(
2025-06-07T23:23:56.9320227Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9320500Z +    ) -> Optional[Dict]:
2025-06-07T23:23:56.9320778Z          """Generate regex pattern from structure and examples."""
2025-06-07T23:23:56.9321063Z -        
2025-06-07T23:23:56.9321218Z +
2025-06-07T23:23:56.9321420Z          # Analyze the examples to understand the pattern
2025-06-07T23:23:56.9321700Z          if not examples:
2025-06-07T23:23:56.9321899Z              return None
2025-06-07T23:23:56.9322092Z -        
2025-06-07T23:23:56.9322243Z +
2025-06-07T23:23:56.9322429Z          # Common pattern types we can recognize
2025-06-07T23:23:56.9322771Z          pattern_info = self._classify_pattern_type(structure, examples)
2025-06-07T23:23:56.9323096Z          if not pattern_info:
2025-06-07T23:23:56.9323316Z              return None
2025-06-07T23:23:56.9323510Z -        
2025-06-07T23:23:56.9323667Z +
2025-06-07T23:23:56.9323876Z          # Generate appropriate regex based on pattern type
2025-06-07T23:23:56.9324243Z          regex_pattern = self._build_regex_pattern(pattern_info, examples)
2025-06-07T23:23:56.9324571Z          if not regex_pattern:
2025-06-07T23:23:56.9324788Z              return None
2025-06-07T23:23:56.9324976Z -        
2025-06-07T23:23:56.9325127Z +
2025-06-07T23:23:56.9325276Z          return {
2025-06-07T23:23:56.9325474Z              "name": pattern_info["name"],
2025-06-07T23:23:56.9325720Z              "regex": regex_pattern,
2025-06-07T23:23:56.9325981Z @@ -106,141 +110,155 @@ class IncrementalLearner:
2025-06-07T23:23:56.9326255Z              "examples": examples[:3],
2025-06-07T23:23:56.9326563Z              "confidence": self._calculate_pattern_confidence(examples),
2025-06-07T23:23:56.9326894Z              "handler": pattern_info["handler"],
2025-06-07T23:23:56.9327179Z -            "description": pattern_info["description"]
2025-06-07T23:23:56.9327480Z +            "description": pattern_info["description"],
2025-06-07T23:23:56.9327736Z          }
2025-06-07T23:23:56.9327892Z -    
2025-06-07T23:23:56.9328209Z -    def _classify_pattern_type(self, structure: str, examples: List[str]) -> Optional[Dict]:
2025-06-07T23:23:56.9328994Z +
2025-06-07T23:23:56.9329185Z +    def _classify_pattern_type(
2025-06-07T23:23:56.9329456Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9329729Z +    ) -> Optional[Dict]:
2025-06-07T23:23:56.9330032Z          """Classify the type of pattern based on structure and content."""
2025-06-07T23:23:56.9330350Z -        
2025-06-07T23:23:56.9330510Z +
2025-06-07T23:23:56.9330692Z          first_example = examples[0].upper()
2025-06-07T23:23:56.9330922Z -        
2025-06-07T23:23:56.9331076Z +
2025-06-07T23:23:56.9331267Z          # Transaction with embedded date and amount
2025-06-07T23:23:56.9331576Z          if "DATE" in structure and "AMOUNT" in structure:
2025-06-07T23:23:56.9331967Z              if any(word in first_example for word in ["COMPRA", "VENDA", "PAGAMENTO"]):
2025-06-07T23:23:56.9332308Z                  return {
2025-06-07T23:23:56.9332539Z                      "name": "transaction_with_date",
2025-06-07T23:23:56.9332985Z                      "handler": "parse_transaction",
2025-06-07T23:23:56.9333292Z -                    "description": "Transaction with date and amount"
2025-06-07T23:23:56.9333630Z +                    "description": "Transaction with date and amount",
2025-06-07T23:23:56.9333910Z                  }
2025-06-07T23:23:56.9334086Z -        
2025-06-07T23:23:56.9334246Z +
2025-06-07T23:23:56.9334412Z          # Fee or charge line
2025-06-07T23:23:56.9334810Z -        if "AMOUNT" in structure and any(word in first_example for word in ["TAXA", "TARIFA", "JUROS", "MULTA"]):
2025-06-07T23:23:56.9335246Z +        if "AMOUNT" in structure and any(
2025-06-07T23:23:56.9335626Z +            word in first_example for word in ["TAXA", "TARIFA", "JUROS", "MULTA"]
2025-06-07T23:23:56.9336066Z +        ):
2025-06-07T23:23:56.9336230Z              return {
2025-06-07T23:23:56.9336433Z                  "name": "fee_charge",
2025-06-07T23:23:56.9336676Z                  "handler": "parse_fee",
2025-06-07T23:23:56.9336938Z -                "description": "Fee or charge line"
2025-06-07T23:23:56.9337214Z +                "description": "Fee or charge line",
2025-06-07T23:23:56.9337455Z              }
2025-06-07T23:23:56.9337620Z -        
2025-06-07T23:23:56.9337772Z +
2025-06-07T23:23:56.9337933Z          # Installment information
2025-06-07T23:23:56.9338202Z          if "/" in structure and "AMOUNT" in structure:
2025-06-07T23:23:56.9338758Z              if any(word in first_example for word in ["PARCELA", "PARC"]):
2025-06-07T23:23:56.9339064Z                  return {
2025-06-07T23:23:56.9339281Z                      "name": "installment_info",
2025-06-07T23:23:56.9339548Z                      "handler": "parse_installment",
2025-06-07T23:23:56.9339856Z -                    "description": "Installment payment information"
2025-06-07T23:23:56.9340191Z +                    "description": "Installment payment information",
2025-06-07T23:23:56.9340462Z                  }
2025-06-07T23:23:56.9340633Z -        
2025-06-07T23:23:56.9340789Z +
2025-06-07T23:23:56.9340967Z          # International transaction details
2025-06-07T23:23:56.9341358Z -        if "AMOUNT" in structure and any(word in first_example for word in ["USD", "EUR", "DOLAR"]):
2025-06-07T23:23:56.9341754Z +        if "AMOUNT" in structure and any(
2025-06-07T23:23:56.9342052Z +            word in first_example for word in ["USD", "EUR", "DOLAR"]
2025-06-07T23:23:56.9342337Z +        ):
2025-06-07T23:23:56.9342506Z              return {
2025-06-07T23:23:56.9342719Z                  "name": "international_detail",
2025-06-07T23:23:56.9342990Z                  "handler": "parse_international",
2025-06-07T23:23:56.9343306Z -                "description": "International transaction details"
2025-06-07T23:23:56.9343661Z +                "description": "International transaction details",
2025-06-07T23:23:56.9343940Z              }
2025-06-07T23:23:56.9344109Z -        
2025-06-07T23:23:56.9344265Z +
2025-06-07T23:23:56.9344443Z          # Generic transaction with amount
2025-06-07T23:23:56.9344753Z          if "AMOUNT" in structure and len(structure.split()) >= 3:
2025-06-07T23:23:56.9345035Z              return {
2025-06-07T23:23:56.9345250Z                  "name": "generic_transaction",
2025-06-07T23:23:56.9345516Z                  "handler": "parse_generic",
2025-06-07T23:23:56.9345807Z -                "description": "Generic transaction pattern"
2025-06-07T23:23:56.9346127Z +                "description": "Generic transaction pattern",
2025-06-07T23:23:56.9346389Z              }
2025-06-07T23:23:56.9346554Z -        
2025-06-07T23:23:56.9346715Z +
2025-06-07T23:23:56.9346874Z          return None
2025-06-07T23:23:56.9347048Z -    
2025-06-07T23:23:56.9347365Z -    def _build_regex_pattern(self, pattern_info: Dict, examples: List[str]) -> Optional[str]:
2025-06-07T23:23:56.9347749Z +
2025-06-07T23:23:56.9347917Z +    def _build_regex_pattern(
2025-06-07T23:23:56.9348176Z +        self, pattern_info: Dict, examples: List[str]
2025-06-07T23:23:56.9348753Z +    ) -> Optional[str]:
2025-06-07T23:23:56.9349023Z          """Build regex pattern from classified pattern type."""
2025-06-07T23:23:56.9349302Z -        
2025-06-07T23:23:56.9349450Z +
2025-06-07T23:23:56.9349626Z          pattern_type = pattern_info["name"]
2025-06-07T23:23:56.9349861Z -        
2025-06-07T23:23:56.9350012Z +
2025-06-07T23:23:56.9350202Z          if pattern_type == "transaction_with_date":
2025-06-07T23:23:56.9350486Z              # Pattern: DATE DESCRIPTION AMOUNT
2025-06-07T23:23:56.9350990Z              return r"^(?P<date>\d{1,2}/\d{1,2})\s+(?P<desc>.+?)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+.*)?$"
2025-06-07T23:23:56.9351533Z -        
2025-06-07T23:23:56.9351791Z +
2025-06-07T23:23:56.9352084Z          elif pattern_type == "fee_charge":
2025-06-07T23:23:56.9352689Z              # Pattern: DESCRIPTION AMOUNT
2025-06-07T23:23:56.9353354Z              return r"^(?P<desc>(?i)(?:taxa|tarifa|juros|multa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9353966Z -        
2025-06-07T23:23:56.9354224Z +
2025-06-07T23:23:56.9354526Z          elif pattern_type == "installment_info":
2025-06-07T23:23:56.9355017Z              # Pattern: DESCRIPTION XX/YY AMOUNT
2025-06-07T23:23:56.9355909Z              return r"^(?P<desc>.+?)\s+(?P<installment>\d{1,2}/\d{1,2})\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9356526Z -        
2025-06-07T23:23:56.9356693Z +
2025-06-07T23:23:56.9356902Z          elif pattern_type == "international_detail":
2025-06-07T23:23:56.9357314Z              # Pattern: DESCRIPTION CURRENCY AMOUNT
2025-06-07T23:23:56.9357763Z              return r"^(?P<desc>.+?)\s+(?P<currency>USD|EUR|GBP)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9358207Z -        
2025-06-07T23:23:56.9358551Z +
2025-06-07T23:23:56.9358769Z          elif pattern_type == "generic_transaction":
2025-06-07T23:23:56.9359122Z              # Pattern: Any line with amount that looks like a transaction
2025-06-07T23:23:56.9359514Z              return r"^(?P<desc>.+?)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+.*)?$"
2025-06-07T23:23:56.9360063Z -        
2025-06-07T23:23:56.9376285Z +
2025-06-07T23:23:56.9376475Z          return None
2025-06-07T23:23:56.9376677Z -    
2025-06-07T23:23:56.9376835Z +
2025-06-07T23:23:56.9377112Z      def _calculate_pattern_confidence(self, examples: List[str]) -> float:
2025-06-07T23:23:56.9377548Z          """Calculate confidence score for a pattern based on examples."""
2025-06-07T23:23:56.9377942Z          # Base confidence on number of examples and consistency
2025-06-07T23:23:56.9378509Z          base_confidence = min(0.9, 0.3 + 0.1 * len(examples))
2025-06-07T23:23:56.9378809Z -        
2025-06-07T23:23:56.9378978Z +
2025-06-07T23:23:56.9379157Z          # Check consistency in structure
2025-06-07T23:23:56.9379521Z          structures = [self._create_structure_signature(ex) for ex in examples]
2025-06-07T23:23:56.9379916Z          if len(set(structures)) == 1:  # All have same structure
2025-06-07T23:23:56.9380214Z              base_confidence += 0.1
2025-06-07T23:23:56.9380434Z -        
2025-06-07T23:23:56.9380591Z +
2025-06-07T23:23:56.9380766Z          # Check for transaction indicators
2025-06-07T23:23:56.9381111Z          transaction_keywords = ["COMPRA", "VENDA", "PAGAMENTO", "PARCELA"]
2025-06-07T23:23:56.9381543Z          if any(kw in " ".join(examples).upper() for kw in transaction_keywords):
2025-06-07T23:23:56.9381874Z              base_confidence += 0.1
2025-06-07T23:23:56.9382098Z -        
2025-06-07T23:23:56.9382257Z +
2025-06-07T23:23:56.9382433Z          return min(1.0, base_confidence)
2025-06-07T23:23:56.9382663Z -    
2025-06-07T23:23:56.9382821Z +
2025-06-07T23:23:56.9383102Z      def generate_enhanced_patterns(self, pdf_paths: List[Path]) -> List[Dict]:
2025-06-07T23:23:56.9383511Z          """Generate enhanced patterns from multiple PDFs."""
2025-06-07T23:23:56.9383787Z -        
2025-06-07T23:23:56.9383942Z +
2025-06-07T23:23:56.9384103Z          all_patterns = []
2025-06-07T23:23:56.9384485Z -        
2025-06-07T23:23:56.9384640Z +
2025-06-07T23:23:56.9384811Z          for pdf_path in pdf_paths:
2025-06-07T23:23:56.9385085Z              print(f"Learning from {pdf_path.name}...")
2025-06-07T23:23:56.9385344Z -            
2025-06-07T23:23:56.9385508Z +
2025-06-07T23:23:56.9385705Z              # Run validation to get missing transactions
2025-06-07T23:23:56.9385984Z              import importlib.util
2025-06-07T23:23:56.9386329Z -            spec = importlib.util.spec_from_file_location("semantic_validator", 
2025-06-07T23:23:56.9386718Z -                                                         ROOT / "scripts" / "semantic_validator.py")
2025-06-07T23:23:56.9387005Z +
2025-06-07T23:23:56.9387212Z +            spec = importlib.util.spec_from_file_location(
2025-06-07T23:23:56.9387692Z +                "semantic_validator", ROOT / "scripts" / "semantic_validator.py"
2025-06-07T23:23:56.9388006Z +            )
2025-06-07T23:23:56.9388455Z              semantic_validator = importlib.util.module_from_spec(spec)
2025-06-07T23:23:56.9388825Z              spec.loader.exec_module(semantic_validator)
2025-06-07T23:23:56.9389082Z -            
2025-06-07T23:23:56.9389250Z +
2025-06-07T23:23:56.9389467Z              validator = semantic_validator.SemanticValidator()
2025-06-07T23:23:56.9389840Z              validation_results = validator.validate_pdf_parsing(pdf_path)
2025-06-07T23:23:56.9390150Z -            
2025-06-07T23:23:56.9390312Z +
2025-06-07T23:23:56.9390488Z              # Analyze missing transactions
2025-06-07T23:23:56.9390851Z              patterns = self.analyze_missing_transactions(pdf_path, validation_results)
2025-06-07T23:23:56.9391226Z              all_patterns.extend(patterns)
2025-06-07T23:23:56.9391463Z -            
2025-06-07T23:23:56.9391617Z +
2025-06-07T23:23:56.9391780Z              # Track metrics
2025-06-07T23:23:56.9392027Z              file_info = validation_results["file_info"]
2025-06-07T23:23:56.9392426Z -            success_rate = file_info["parsed_transactions"] / max(1, file_info["total_lines"])
2025-06-07T23:23:56.9392866Z +            success_rate = file_info["parsed_transactions"] / max(
2025-06-07T23:23:56.9393170Z +                1, file_info["total_lines"]
2025-06-07T23:23:56.9393402Z +            )
2025-06-07T23:23:56.9393629Z              print(f"  Current success rate: {success_rate:.1%}")
2025-06-07T23:23:56.9393952Z              print(f"  Found {len(patterns)} new patterns")
2025-06-07T23:23:56.9394207Z -        
2025-06-07T23:23:56.9394361Z +
2025-06-07T23:23:56.9394538Z          # Deduplicate and rank patterns
2025-06-07T23:23:56.9394850Z          unique_patterns = self._deduplicate_patterns(all_patterns)
2025-06-07T23:23:56.9395310Z -        ranked_patterns = sorted(unique_patterns, key=lambda p: p["confidence"], reverse=True)
2025-06-07T23:23:56.9395697Z -        
2025-06-07T23:23:56.9395877Z +        ranked_patterns = sorted(
2025-06-07T23:23:56.9396184Z +            unique_patterns, key=lambda p: p["confidence"], reverse=True
2025-06-07T23:23:56.9396496Z +        )
2025-06-07T23:23:56.9396648Z +
2025-06-07T23:23:56.9396813Z          return ranked_patterns
2025-06-07T23:23:56.9397021Z -    
2025-06-07T23:23:56.9397173Z +
2025-06-07T23:23:56.9397425Z      def _deduplicate_patterns(self, patterns: List[Dict]) -> List[Dict]:
2025-06-07T23:23:56.9397813Z          """Remove duplicate patterns and merge similar ones."""
2025-06-07T23:23:56.9398114Z          unique_patterns = []
2025-06-07T23:23:56.9398495Z          seen_structures = set()
2025-06-07T23:23:56.9398709Z -        
2025-06-07T23:23:56.9398863Z +
2025-06-07T23:23:56.9399028Z          for pattern in patterns:
2025-06-07T23:23:56.9399277Z              structure = pattern["structure"]
2025-06-07T23:23:56.9399550Z              if structure not in seen_structures:
2025-06-07T23:23:56.9399838Z @@ -251,19 +269,23 @@ class IncrementalLearner:
2025-06-07T23:23:56.9400116Z                  for existing in unique_patterns:
2025-06-07T23:23:56.9400397Z                      if existing["structure"] == structure:
2025-06-07T23:23:56.9400836Z                          existing["examples"].extend(pattern["examples"])
2025-06-07T23:23:56.9401211Z -                        existing["examples"] = existing["examples"][:5]  # Keep only top 5
2025-06-07T23:23:56.9401584Z +                        existing["examples"] = existing["examples"][
2025-06-07T23:23:56.9401855Z +                            :5
2025-06-07T23:23:56.9402076Z +                        ]  # Keep only top 5
2025-06-07T23:23:56.9402352Z                          # Update confidence based on more examples
2025-06-07T23:23:56.9402743Z -                        existing["confidence"] = max(existing["confidence"], pattern["confidence"])
2025-06-07T23:23:56.9403136Z +                        existing["confidence"] = max(
2025-06-07T23:23:56.9403546Z +                            existing["confidence"], pattern["confidence"]
2025-06-07T23:23:56.9403831Z +                        )
2025-06-07T23:23:56.9404026Z                          break
2025-06-07T23:23:56.9404228Z -        
2025-06-07T23:23:56.9404384Z +
2025-06-07T23:23:56.9404552Z          return unique_patterns
2025-06-07T23:23:56.9404757Z -    
2025-06-07T23:23:56.9404910Z +
2025-06-07T23:23:56.9405176Z      def generate_pattern_implementation(self, patterns: List[Dict]) -> str:
2025-06-07T23:23:56.9405611Z          """Generate Python code to implement the learned patterns."""
2025-06-07T23:23:56.9405900Z -        
2025-06-07T23:23:56.9406056Z +
2025-06-07T23:23:56.9406241Z          # Filter high-confidence patterns
2025-06-07T23:23:56.9406612Z          high_confidence_patterns = [p for p in patterns if p["confidence"] >= 0.6]
2025-06-07T23:23:56.9406960Z -        
2025-06-07T23:23:56.9407117Z +
2025-06-07T23:23:56.9407268Z          code = '''
2025-06-07T23:23:56.9407489Z  # ===== LEARNED PATTERNS (Auto-generated) =====
2025-06-07T23:23:56.9407746Z  
2025-06-07T23:23:56.9407937Z @@ -278,16 +300,16 @@ from decimal import Decimal
2025-06-07T23:23:56.9408195Z  import hashlib
2025-06-07T23:23:56.9408546Z  
2025-06-07T23:23:56.9408707Z  '''
2025-06-07T23:23:56.9408865Z -        
2025-06-07T23:23:56.9409030Z +
2025-06-07T23:23:56.9409201Z          # Generate regex constants
2025-06-07T23:23:56.9409513Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9409884Z              const_name = f"RE_LEARNED_{pattern['name'].upper()}_{i}"
2025-06-07T23:23:56.9410188Z              code += f'''
2025-06-07T23:23:56.9410492Z -# {pattern['description']} (confidence: {pattern['confidence']:.1%})
2025-06-07T23:23:56.9410915Z -# Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}
2025-06-07T23:23:56.9411303Z -{const_name}: Final = re.compile(r"{pattern['regex']}")
2025-06-07T23:23:56.9411678Z +# {pattern["description"]} (confidence: {pattern["confidence"]:.1%})
2025-06-07T23:23:56.9412090Z +# Example: {pattern["examples"][0] if pattern["examples"] else "N/A"}
2025-06-07T23:23:56.9412464Z +{const_name}: Final = re.compile(r"{pattern["regex"]}")
2025-06-07T23:23:56.9412733Z  '''
2025-06-07T23:23:56.9412894Z -        
2025-06-07T23:23:56.9413053Z +
2025-06-07T23:23:56.9413212Z          code += '''
2025-06-07T23:23:56.9413395Z  
2025-06-07T23:23:56.9413671Z  def parse_with_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9414170Z @@ -298,28 +320,28 @@ def parse_with_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9414546Z      if not line:
2025-06-07T23:23:56.9414728Z          return None
2025-06-07T23:23:56.9414921Z  '''
2025-06-07T23:23:56.9415074Z -        
2025-06-07T23:23:56.9415230Z +
2025-06-07T23:23:56.9415406Z          # Generate pattern matching code
2025-06-07T23:23:56.9415722Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9416084Z              const_name = f"RE_LEARNED_{pattern['name'].upper()}_{i}"
2025-06-07T23:23:56.9416449Z              handler_name = f"_handle_learned_{pattern['handler']}_{i}"
2025-06-07T23:23:56.9416742Z -            
2025-06-07T23:23:56.9416914Z -            code += f'''
2025-06-07T23:23:56.9417240Z +
2025-06-07T23:23:56.9417395Z +            code += f"""
2025-06-07T23:23:56.9417585Z      
2025-06-07T23:23:56.9417764Z -    # {pattern['description']}
2025-06-07T23:23:56.9418000Z +    # {pattern["description"]}
2025-06-07T23:23:56.9418223Z      m = {const_name}.match(line)
2025-06-07T23:23:56.9418618Z      if m:
2025-06-07T23:23:56.9418832Z          return {handler_name}(m, original_line, year)
2025-06-07T23:23:56.9419093Z -'''
2025-06-07T23:23:56.9419245Z -        
2025-06-07T23:23:56.9419401Z +"""
2025-06-07T23:23:56.9419546Z +
2025-06-07T23:23:56.9419712Z          # Generate handler functions
2025-06-07T23:23:56.9420011Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9420489Z              handler_name = f"_handle_learned_{pattern['handler']}_{i}"
2025-06-07T23:23:56.9420790Z -            
2025-06-07T23:23:56.9420958Z +
2025-06-07T23:23:56.9421121Z              code += f'''
2025-06-07T23:23:56.9421317Z  
2025-06-07T23:23:56.9421567Z  def {handler_name}(m, original_line: str, year: int = None) -> dict:
2025-06-07T23:23:56.9421907Z -    """Handle {pattern['description']}"""
2025-06-07T23:23:56.9422177Z +    """Handle {pattern["description"]}"""
2025-06-07T23:23:56.9422430Z      from datetime import date
2025-06-07T23:23:56.9422643Z      
2025-06-07T23:23:56.9422835Z      # Extract common fields with error handling
2025-06-07T23:23:56.9423206Z @@ -364,7 +386,7 @@ def {handler_name}(m, original_line: str, year: int = None) -> dict:
2025-06-07T23:23:56.9423597Z          # If parsing fails, return None to skip this line
2025-06-07T23:23:56.9423865Z          return None
2025-06-07T23:23:56.9424044Z  '''
2025-06-07T23:23:56.9424192Z -        
2025-06-07T23:23:56.9424348Z +
2025-06-07T23:23:56.9424498Z          code += '''
2025-06-07T23:23:56.9424679Z  
2025-06-07T23:23:56.9424855Z  # Integration function for main parser
2025-06-07T23:23:56.9425281Z @@ -372,76 +394,86 @@ def try_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9425693Z      """Try all learned patterns in order of confidence."""
2025-06-07T23:23:56.9426014Z      return parse_with_learned_patterns(line, year)
2025-06-07T23:23:56.9426294Z  '''
2025-06-07T23:23:56.9426455Z -        
2025-06-07T23:23:56.9426610Z +
2025-06-07T23:23:56.9426758Z          return code
2025-06-07T23:23:56.9426933Z  
2025-06-07T23:23:56.9427078Z  
2025-06-07T23:23:56.9427226Z  def main():
2025-06-07T23:23:56.9427583Z -    parser = argparse.ArgumentParser(description="Incremental learning for parser improvement")
2025-06-07T23:23:56.9428026Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9428499Z +        description="Incremental learning for parser improvement"
2025-06-07T23:23:56.9428808Z +    )
2025-06-07T23:23:56.9429106Z      parser.add_argument("pdf_dir", help="Directory containing PDF files to learn from")
2025-06-07T23:23:56.9429543Z -    parser.add_argument("--output-dir", default="diagnostics", 
2025-06-07T23:23:56.9429883Z -                       help="Directory to save learning results")
2025-06-07T23:23:56.9430210Z -    parser.add_argument("--limit", type=int, default=5,
2025-06-07T23:23:56.9430524Z -                       help="Limit number of PDFs to process")
2025-06-07T23:23:56.9430798Z +    parser.add_argument(
2025-06-07T23:23:56.9431135Z +        "--output-dir", default="diagnostics", help="Directory to save learning results"
2025-06-07T23:23:56.9431484Z +    )
2025-06-07T23:23:56.9431651Z +    parser.add_argument(
2025-06-07T23:23:56.9431943Z +        "--limit", type=int, default=5, help="Limit number of PDFs to process"
2025-06-07T23:23:56.9432258Z +    )
2025-06-07T23:23:56.9432433Z      args = parser.parse_args()
2025-06-07T23:23:56.9432645Z -    
2025-06-07T23:23:56.9432796Z +
2025-06-07T23:23:56.9432965Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9433216Z      output_dir = Path(args.output_dir)
2025-06-07T23:23:56.9433452Z -    
2025-06-07T23:23:56.9433598Z +
2025-06-07T23:23:56.9433766Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9434173Z          print(f"Error: PDF directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9434458Z          return 1
2025-06-07T23:23:56.9434629Z -    
2025-06-07T23:23:56.9434778Z +
2025-06-07T23:23:56.9434969Z      output_dir.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9435227Z -    
2025-06-07T23:23:56.9435373Z +
2025-06-07T23:23:56.9435542Z      # Get PDF files to learn from
2025-06-07T23:23:56.9435852Z -    pdf_files = list(pdf_dir.glob("*.pdf"))[:args.limit]
2025-06-07T23:23:56.9436181Z +    pdf_files = list(pdf_dir.glob("*.pdf"))[: args.limit]
2025-06-07T23:23:56.9436457Z      if not pdf_files:
2025-06-07T23:23:56.9436663Z          print("No PDF files found")
2025-06-07T23:23:56.9436885Z          return 1
2025-06-07T23:23:56.9437052Z -    
2025-06-07T23:23:56.9437197Z +
2025-06-07T23:23:56.9437550Z      print(f"Learning from {len(pdf_files)} PDF files...")
2025-06-07T23:23:56.9437821Z -    
2025-06-07T23:23:56.9437966Z +
2025-06-07T23:23:56.9438135Z      learner = IncrementalLearner()
2025-06-07T23:23:56.9438599Z      patterns = learner.generate_enhanced_patterns(pdf_files)
2025-06-07T23:23:56.9438889Z -    
2025-06-07T23:23:56.9439033Z +
2025-06-07T23:23:56.9439195Z      # Save learning results
2025-06-07T23:23:56.9439405Z      results = {
2025-06-07T23:23:56.9439612Z          "timestamp": str(Path().absolute()),
2025-06-07T23:23:56.9439901Z          "pdfs_processed": [p.name for p in pdf_files],
2025-06-07T23:23:56.9440189Z          "patterns_discovered": len(patterns),
2025-06-07T23:23:56.9440570Z -        "high_confidence_patterns": len([p for p in patterns if p["confidence"] >= 0.6]),
2025-06-07T23:23:56.9440953Z +        "high_confidence_patterns": len(
2025-06-07T23:23:56.9441237Z +            [p for p in patterns if p["confidence"] >= 0.6]
2025-06-07T23:23:56.9441499Z +        ),
2025-06-07T23:23:56.9441684Z          "patterns": patterns,
2025-06-07T23:23:56.9442009Z -        "implementation": learner.generate_pattern_implementation(patterns)
2025-06-07T23:23:56.9442449Z +        "implementation": learner.generate_pattern_implementation(patterns),
2025-06-07T23:23:56.9442780Z      }
2025-06-07T23:23:56.9442933Z -    
2025-06-07T23:23:56.9443083Z +
2025-06-07T23:23:56.9443245Z      # Save JSON report
2025-06-07T23:23:56.9443486Z      report_file = output_dir / "learning_results.json"
2025-06-07T23:23:56.9443770Z -    with open(report_file, 'w') as f:
2025-06-07T23:23:56.9444024Z +    with open(report_file, "w") as f:
2025-06-07T23:23:56.9444292Z          json.dump(results, f, indent=2, default=str)
2025-06-07T23:23:56.9444551Z -    
2025-06-07T23:23:56.9444701Z +
2025-06-07T23:23:56.9444870Z      # Save Python implementation
2025-06-07T23:23:56.9445139Z      impl_file = output_dir / "learned_patterns.py"
2025-06-07T23:23:56.9445412Z -    with open(impl_file, 'w') as f:
2025-06-07T23:23:56.9445660Z +    with open(impl_file, "w") as f:
2025-06-07T23:23:56.9445911Z          f.write(results["implementation"])
2025-06-07T23:23:56.9446150Z -    
2025-06-07T23:23:56.9446318Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9446517Z +
2025-06-07T23:23:56.9446682Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9446913Z      print("INCREMENTAL LEARNING RESULTS")
2025-06-07T23:23:56.9447157Z -    print("="*60)
2025-06-07T23:23:56.9447343Z +    print("=" * 60)
2025-06-07T23:23:56.9447564Z      print(f"PDFs processed: {len(pdf_files)}")
2025-06-07T23:23:56.9447864Z      print(f"Patterns discovered: {len(patterns)}")
2025-06-07T23:23:56.9448467Z -    print(f"High-confidence patterns: {len([p for p in patterns if p['confidence'] >= 0.6])}")
2025-06-07T23:23:56.9448864Z -    
2025-06-07T23:23:56.9449021Z +    print(
2025-06-07T23:23:56.9449332Z +        f"High-confidence patterns: {len([p for p in patterns if p['confidence'] >= 0.6])}"
2025-06-07T23:23:56.9449698Z +    )
2025-06-07T23:23:56.9449844Z +
2025-06-07T23:23:56.9450005Z      if patterns:
2025-06-07T23:23:56.9450211Z          print("\nTOP 5 LEARNED PATTERNS:")
2025-06-07T23:23:56.9450497Z          for i, pattern in enumerate(patterns[:5], 1):
2025-06-07T23:23:56.9450992Z              print(f"{i}. {pattern['name']} (confidence: {pattern['confidence']:.1%})")
2025-06-07T23:23:56.9451447Z -            print(f"   Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}")
2025-06-07T23:23:56.9451791Z -    
2025-06-07T23:23:56.9451948Z +            print(
2025-06-07T23:23:56.9452228Z +                f"   Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}"
2025-06-07T23:23:56.9452551Z +            )
2025-06-07T23:23:56.9452716Z +
2025-06-07T23:23:56.9452879Z      print("\nResults saved to:")
2025-06-07T23:23:56.9453120Z      print(f"  Report: {report_file}")
2025-06-07T23:23:56.9453385Z      print(f"  Implementation: {impl_file}")
2025-06-07T23:23:56.9453623Z -    
2025-06-07T23:23:56.9453771Z +
2025-06-07T23:23:56.9454021Z      return 0
2025-06-07T23:23:56.9454186Z  
2025-06-07T23:23:56.9454329Z  
2025-06-07T23:23:56.9454597Z diff --git a/scripts/pattern_enhancer.py b/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9454950Z index 83b4126..5a2c312 100644
2025-06-07T23:23:56.9455187Z --- a/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9455428Z +++ b/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9455696Z @@ -17,24 +17,24 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9455958Z  
2025-06-07T23:23:56.9456116Z  class PatternEnhancer:
2025-06-07T23:23:56.9456409Z      """Analyzes failed patterns and generates new regex patterns."""
2025-06-07T23:23:56.9456712Z -    
2025-06-07T23:23:56.9456861Z +
2025-06-07T23:23:56.9457038Z      def __init__(self, analysis_file: Path):
2025-06-07T23:23:56.9457308Z          with open(analysis_file) as f:
2025-06-07T23:23:56.9457565Z              self.analysis = json.load(f)
2025-06-07T23:23:56.9457631Z -        
2025-06-07T23:23:56.9457699Z +
2025-06-07T23:23:56.9457785Z          self.new_patterns = []
2025-06-07T23:23:56.9457873Z          self.enhanced_patterns = {}
2025-06-07T23:23:56.9457943Z -        
2025-06-07T23:23:56.9458004Z +
2025-06-07T23:23:56.9458126Z      def analyze_failed_patterns(self) -> List[Dict]:
2025-06-07T23:23:56.9458453Z          """Analyze the most common failed patterns and generate solutions."""
2025-06-07T23:23:56.9458621Z          discovered = self.analysis.get("discovered_patterns", [])
2025-06-07T23:23:56.9458697Z          solutions = []
2025-06-07T23:23:56.9458768Z -        
2025-06-07T23:23:56.9458829Z +
2025-06-07T23:23:56.9458918Z          for pattern in discovered:
2025-06-07T23:23:56.9459011Z              structure = pattern["structure"]
2025-06-07T23:23:56.9459094Z              count = pattern["count"]
2025-06-07T23:23:56.9459187Z              examples = pattern["examples"]
2025-06-07T23:23:56.9459251Z -            
2025-06-07T23:23:56.9459317Z +
2025-06-07T23:23:56.9459434Z              # Generate solutions based on pattern analysis
2025-06-07T23:23:56.9459592Z              if self._is_currency_conversion_pattern(structure, examples):
2025-06-07T23:23:56.9459776Z                  solutions.append(self._create_currency_conversion_pattern(pattern))
2025-06-07T23:23:56.9459880Z @@ -46,109 +46,119 @@ class PatternEnhancer:
2025-06-07T23:23:56.9460015Z                  solutions.append(self._create_fee_pattern(pattern))
2025-06-07T23:23:56.9460173Z              elif self._is_embedded_transaction_pattern(structure, examples):
2025-06-07T23:23:56.9460356Z                  solutions.append(self._create_embedded_transaction_pattern(pattern))
2025-06-07T23:23:56.9460423Z -        
2025-06-07T23:23:56.9460485Z +
2025-06-07T23:23:56.9460561Z          return solutions
2025-06-07T23:23:56.9460629Z -    
2025-06-07T23:23:56.9460855Z -    def _is_currency_conversion_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9460923Z +
2025-06-07T23:23:56.9461017Z +    def _is_currency_conversion_pattern(
2025-06-07T23:23:56.9461128Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9461197Z +    ) -> bool:
2025-06-07T23:23:56.9461322Z          """Check if this is a currency conversion line."""
2025-06-07T23:23:56.9461679Z          indicators = ["dÃ³lar", "conversÃ£o", "BRL", "USD", "EUR"]
2025-06-07T23:23:56.9462038Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9462104Z -    
2025-06-07T23:23:56.9462180Z +        return any(
2025-06-07T23:23:56.9462365Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9462430Z +        )
2025-06-07T23:23:56.9462496Z +
2025-06-07T23:23:56.9462702Z      def _is_payment_summary_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9462816Z          """Check if this is a payment summary line."""
2025-06-07T23:23:56.9463012Z          indicators = ["pagamentos efetuados", "saldo financiado", "total desta fatura"]
2025-06-07T23:23:56.9463432Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9463501Z -    
2025-06-07T23:23:56.9463576Z +        return any(
2025-06-07T23:23:56.9463758Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9463829Z +        )
2025-06-07T23:23:56.9463892Z +
2025-06-07T23:23:56.9464101Z      def _is_transaction_code_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9464213Z          """Check if this is a transaction code line."""
2025-06-07T23:23:56.9464368Z -        return any(re.search(r'[A-Z]{2,3} - \d+', ex) for ex in examples)
2025-06-07T23:23:56.9464434Z -    
2025-06-07T23:23:56.9464581Z +        return any(re.search(r"[A-Z]{2,3} - \d+", ex) for ex in examples)
2025-06-07T23:23:56.9464646Z +
2025-06-07T23:23:56.9464829Z      def _is_fee_info_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9464942Z          """Check if this is a fee information line."""
2025-06-07T23:23:56.9465080Z          indicators = ["valor juros", "multa", "encargo", "tarifa"]
2025-06-07T23:23:56.9465290Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9465356Z -    
2025-06-07T23:23:56.9465585Z -    def _is_embedded_transaction_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9465656Z +        return any(
2025-06-07T23:23:56.9465837Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9465900Z +        )
2025-06-07T23:23:56.9465962Z +
2025-06-07T23:23:56.9466064Z +    def _is_embedded_transaction_pattern(
2025-06-07T23:23:56.9466171Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9466245Z +    ) -> bool:
2025-06-07T23:23:56.9466372Z          """Check if this contains embedded transaction data."""
2025-06-07T23:23:56.9466547Z -        return any(re.search(r'\d{1,2}/\d{1,2}.*\d+,\d{2}', ex) for ex in examples)
2025-06-07T23:23:56.9466612Z -    
2025-06-07T23:23:56.9466771Z +        return any(re.search(r"\d{1,2}/\d{1,2}.*\d+,\d{2}", ex) for ex in examples)
2025-06-07T23:23:56.9466832Z +
2025-06-07T23:23:56.9467013Z      def _create_currency_conversion_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9467135Z          """Create pattern for currency conversion lines."""
2025-06-07T23:23:56.9467439Z          # Pattern: "DÃ³lar de ConversÃ£o R$ 5,71 DÃ³lar de ConversÃ£o R$ 5,77"
2025-06-07T23:23:56.9467814Z          regex = r"(?i)DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate1>\d+,\d{2})(?:\s+DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate2>\d+,\d{2}))?"
2025-06-07T23:23:56.9467888Z -        
2025-06-07T23:23:56.9467951Z +
2025-06-07T23:23:56.9468019Z          return {
2025-06-07T23:23:56.9468118Z              "name": "currency_conversion",
2025-06-07T23:23:56.9468201Z              "pattern": regex,
2025-06-07T23:23:56.9468621Z              "description": "Currency conversion rate information",
2025-06-07T23:23:56.9468797Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9468935Z              "count": pattern["count"],
2025-06-07T23:23:56.9469077Z -            "action": "extract_fx_rate"
2025-06-07T23:23:56.9469375Z +            "action": "extract_fx_rate",
2025-06-07T23:23:56.9469445Z          }
2025-06-07T23:23:56.9469516Z -    
2025-06-07T23:23:56.9469579Z +
2025-06-07T23:23:56.9469754Z      def _create_payment_summary_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9469877Z          """Create pattern for payment summary lines."""
2025-06-07T23:23:56.9469994Z          # Pattern: "P Pagamentos efetuados - 16.744,62"
2025-06-07T23:23:56.9470188Z          regex = r"^(?P<type>[A-Z])\s+(?P<desc>[\w\s]+)\s+-\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9470254Z -        
2025-06-07T23:23:56.9470321Z +
2025-06-07T23:23:56.9470390Z          return {
2025-06-07T23:23:56.9470483Z              "name": "payment_summary",
2025-06-07T23:23:56.9470563Z              "pattern": regex,
2025-06-07T23:23:56.9470805Z              "description": "Payment summary lines with amounts",
2025-06-07T23:23:56.9470907Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9470994Z              "count": pattern["count"],
2025-06-07T23:23:56.9471087Z -            "action": "parse_as_summary"
2025-06-07T23:23:56.9471174Z +            "action": "parse_as_summary",
2025-06-07T23:23:56.9471244Z          }
2025-06-07T23:23:56.9471308Z -    
2025-06-07T23:23:56.9471378Z +
2025-06-07T23:23:56.9471549Z      def _create_transaction_code_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9471669Z          """Create pattern for transaction code lines."""
2025-06-07T23:23:56.9471828Z          # Pattern: "PC - 00 01290 VK045 03/05/2024 VKRPOF01 G4082 0622596"
2025-06-07T23:23:56.9472073Z          regex = r"^(?P<code>[A-Z]{2,3})\s+-\s+(?P<ref>\d+\s+\d+\s+[A-Z0-9]+)\s+(?P<date>\d{2}/\d{2}/\d{4})\s+(?P<details>[\w\s]+)$"
2025-06-07T23:23:56.9472137Z -        
2025-06-07T23:23:56.9472205Z +
2025-06-07T23:23:56.9472276Z          return {
2025-06-07T23:23:56.9472365Z              "name": "transaction_code",
2025-06-07T23:23:56.9472450Z              "pattern": regex,
2025-06-07T23:23:56.9472589Z              "description": "Transaction reference codes with dates",
2025-06-07T23:23:56.9472691Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9472773Z              "count": pattern["count"],
2025-06-07T23:23:56.9472870Z -            "action": "parse_as_reference"
2025-06-07T23:23:56.9472963Z +            "action": "parse_as_reference",
2025-06-07T23:23:56.9473032Z          }
2025-06-07T23:23:56.9473097Z -    
2025-06-07T23:23:56.9473164Z +
2025-06-07T23:23:56.9473294Z      def _create_fee_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9473410Z          """Create pattern for fee information lines."""
2025-06-07T23:23:56.9473498Z          # Pattern: "Valor juros 477,06"
2025-06-07T23:23:56.9473754Z          regex = r"^(?P<desc>(?i)(?:valor\s+)?(?:juros|multa|encargo|tarifa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9473823Z -        
2025-06-07T23:23:56.9473883Z +
2025-06-07T23:23:56.9473958Z          return {
2025-06-07T23:23:56.9474041Z              "name": "fee_information",
2025-06-07T23:23:56.9474128Z              "pattern": regex,
2025-06-07T23:23:56.9474244Z              "description": "Fee and interest information",
2025-06-07T23:23:56.9474344Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9474425Z              "count": pattern["count"],
2025-06-07T23:23:56.9474515Z -            "action": "parse_as_fee"
2025-06-07T23:23:56.9474600Z +            "action": "parse_as_fee",
2025-06-07T23:23:56.9474665Z          }
2025-06-07T23:23:56.9474733Z -    
2025-06-07T23:23:56.9474796Z +
2025-06-07T23:23:56.9474989Z      def _create_embedded_transaction_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9475118Z          """Create pattern for embedded transaction data."""
2025-06-07T23:23:56.9475275Z          # Pattern: Lines with date and amount but different structure
2025-06-07T23:23:56.9475574Z          regex = r"(?P<date>\d{1,2}/\d{1,2})(?:\s+(?P<desc1>[\w\s]+?))?\s+(?P<amount1>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+(?P<currency>[A-Z]{3}))?\s+(?P<amount2>\d{1,3}(?:\.\d{3})*,\d{2})"
2025-06-07T23:23:56.9475731Z -        
2025-06-07T23:23:56.9475794Z +
2025-06-07T23:23:56.9475866Z          return {
2025-06-07T23:23:56.9475962Z              "name": "embedded_transaction",
2025-06-07T23:23:56.9476044Z              "pattern": regex,
2025-06-07T23:23:56.9476198Z              "description": "Embedded transaction with multiple amounts",
2025-06-07T23:23:56.9476297Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9476380Z              "count": pattern["count"],
2025-06-07T23:23:56.9476477Z -            "action": "parse_as_transaction"
2025-06-07T23:23:56.9476577Z +            "action": "parse_as_transaction",
2025-06-07T23:23:56.9476642Z          }
2025-06-07T23:23:56.9476712Z -    
2025-06-07T23:23:56.9476774Z +
2025-06-07T23:23:56.9476954Z      def generate_enhanced_parser(self) -> str:
2025-06-07T23:23:56.9477088Z          """Generate enhanced parser code with new patterns."""
2025-06-07T23:23:56.9477199Z          solutions = self.analyze_failed_patterns()
2025-06-07T23:23:56.9477266Z -        
2025-06-07T23:23:56.9477333Z +
2025-06-07T23:23:56.9477416Z          # Sort by impact (count)
2025-06-07T23:23:56.9477548Z          solutions.sort(key=lambda x: x["count"], reverse=True)
2025-06-07T23:23:56.9477618Z -        
2025-06-07T23:23:56.9477681Z +
2025-06-07T23:23:56.9477769Z          parser_code = '''
2025-06-07T23:23:56.9477983Z  def parse_statement_line_enhanced(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9478157Z      """Enhanced parser with additional patterns for better coverage."""
2025-06-07T23:23:56.9478653Z @@ -164,41 +174,41 @@ def parse_statement_line_enhanced(line: str, year: int | None = None) -> dict |
2025-06-07T23:23:56.9478776Z      
2025-06-07T23:23:56.9479011Z      # Enhanced patterns (generated from failed line analysis)
2025-06-07T23:23:56.9479084Z  '''
2025-06-07T23:23:56.9479152Z -        
2025-06-07T23:23:56.9479216Z +
2025-06-07T23:23:56.9479381Z          for i, solution in enumerate(solutions[:10]):  # Top 10 patterns
2025-06-07T23:23:56.9479528Z              pattern_var = f"RE_ENHANCED_{solution['name'].upper()}"
2025-06-07T23:23:56.9479618Z              parser_code += f'''
2025-06-07T23:23:56.9479764Z -    {pattern_var}: Final = re.compile(r"{solution['pattern']}")
2025-06-07T23:23:56.9479908Z +    {pattern_var}: Final = re.compile(r"{solution["pattern"]}")
2025-06-07T23:23:56.9479975Z  '''
2025-06-07T23:23:56.9480045Z -        
2025-06-07T23:23:56.9480127Z -        parser_code += '''
2025-06-07T23:23:56.9480194Z +
2025-06-07T23:23:56.9480272Z +        parser_code += """
2025-06-07T23:23:56.9480336Z      
2025-06-07T23:23:56.9480433Z      # Try enhanced patterns first
2025-06-07T23:23:56.9480495Z -'''
2025-06-07T23:23:56.9480564Z -        
2025-06-07T23:23:56.9480626Z +"""
2025-06-07T23:23:56.9480697Z +
2025-06-07T23:23:56.9480788Z          for solution in solutions[:10]:
2025-06-07T23:23:56.9480923Z              pattern_var = f"RE_ENHANCED_{solution['name'].upper()}"
2025-06-07T23:23:56.9481007Z -            parser_code += f'''
2025-06-07T23:23:56.9481178Z -    # {solution['description']} (covers {solution['count']} failed lines)
2025-06-07T23:23:56.9481255Z +            parser_code += f"""
2025-06-07T23:23:56.9481413Z +    # {solution["description"]} (covers {solution["count"]} failed lines)
2025-06-07T23:23:56.9481503Z      m = {pattern_var}.match(line)
2025-06-07T23:23:56.9481567Z      if m:
2025-06-07T23:23:56.9481716Z -        return _handle_{solution['action']}(m, original_line, year)
2025-06-07T23:23:56.9481779Z -'''
2025-06-07T23:23:56.9481848Z -        
2025-06-07T23:23:56.9481925Z -        parser_code += '''
2025-06-07T23:23:56.9482066Z +        return _handle_{solution["action"]}(m, original_line, year)
2025-06-07T23:23:56.9482129Z +"""
2025-06-07T23:23:56.9482196Z +
2025-06-07T23:23:56.9482274Z +        parser_code += """
2025-06-07T23:23:56.9482337Z      
2025-06-07T23:23:56.9482435Z      # Fall back to original parsing logic
2025-06-07T23:23:56.9482554Z      return parse_statement_line_original(line, year)
2025-06-07T23:23:56.9482772Z -'''
2025-06-07T23:23:56.9482838Z -        
2025-06-07T23:23:56.9482906Z +"""
2025-06-07T23:23:56.9482968Z +
2025-06-07T23:23:56.9483063Z          # Generate handler functions
2025-06-07T23:23:56.9483153Z          for solution in solutions[:10]:
2025-06-07T23:23:56.9483237Z              parser_code += f'''
2025-06-07T23:23:56.9483300Z  
2025-06-07T23:23:56.9483516Z -def _handle_{solution['action']}(m, original_line: str, year: int | None = None) -> dict:
2025-06-07T23:23:56.9483619Z -    """Handle {solution['description']}."""
2025-06-07T23:23:56.9483727Z -    # Custom logic for {solution['name']} pattern
2025-06-07T23:23:56.9483826Z -    # Example line: {solution['example']}
2025-06-07T23:23:56.9484133Z +def _handle_{solution["action"]}(m, original_line: str, year: int | None = None) -> dict:
2025-06-07T23:23:56.9484236Z +    """Handle {solution["description"]}."""
2025-06-07T23:23:56.9484338Z +    # Custom logic for {solution["name"]} pattern
2025-06-07T23:23:56.9484435Z +    # Example line: {solution["example"]}
2025-06-07T23:23:56.9484500Z      
2025-06-07T23:23:56.9484588Z      # Extract common fields
2025-06-07T23:23:56.9484735Z      card_last4 = "0000"  # Default since these may not have card info
2025-06-07T23:23:56.9484959Z @@ -226,72 +236,82 @@ def _handle_{solution['action']}(m, original_line: str, year: int | None = None)
2025-06-07T23:23:56.9485046Z          "amount_usd": Decimal("0.00"),
2025-06-07T23:23:56.9485111Z      }}
2025-06-07T23:23:56.9485183Z  '''
2025-06-07T23:23:56.9485247Z -        
2025-06-07T23:23:56.9485315Z +
2025-06-07T23:23:56.9485395Z          return parser_code
2025-06-07T23:23:56.9485463Z -    
2025-06-07T23:23:56.9485526Z +
2025-06-07T23:23:56.9485638Z      def generate_pattern_report(self) -> Dict:
2025-06-07T23:23:56.9485789Z          """Generate a comprehensive pattern enhancement report."""
2025-06-07T23:23:56.9485900Z          solutions = self.analyze_failed_patterns()
2025-06-07T23:23:56.9486020Z          total_covered = sum(s["count"] for s in solutions)
2025-06-07T23:23:56.9486170Z          total_failed = self.analysis["summary"]["total_failed_lines"]
2025-06-07T23:23:56.9486241Z -        
2025-06-07T23:23:56.9486307Z +
2025-06-07T23:23:56.9486378Z          return {
2025-06-07T23:23:56.9486464Z              "enhancement_summary": {
2025-06-07T23:23:56.9486579Z                  "new_patterns_generated": len(solutions),
2025-06-07T23:23:56.9486690Z                  "lines_potentially_covered": total_covered,
2025-06-07T23:23:56.9486793Z                  "current_failed_lines": total_failed,
2025-06-07T23:23:56.9486997Z -                "potential_success_improvement": f"{(total_covered / total_failed) * 100:.1f}%"
2025-06-07T23:23:56.9487209Z +                "potential_success_improvement": f"{(total_covered / total_failed) * 100:.1f}%",
2025-06-07T23:23:56.9487276Z              },
2025-06-07T23:23:56.9487376Z              "generated_patterns": solutions,
2025-06-07T23:23:56.9487613Z -            "implementation_priority": sorted(solutions, key=lambda x: x["count"], reverse=True)[:5],
2025-06-07T23:23:56.9487713Z +            "implementation_priority": sorted(
2025-06-07T23:23:56.9487843Z +                solutions, key=lambda x: x["count"], reverse=True
2025-06-07T23:23:56.9487911Z +            )[:5],
2025-06-07T23:23:56.9487994Z              "next_steps": [
2025-06-07T23:23:56.9488126Z                  "Implement handler functions for each pattern type",
2025-06-07T23:23:56.9488229Z                  "Add pattern validation tests",
2025-06-07T23:23:56.9488561Z                  "Integrate with main parser in prioritized order",
2025-06-07T23:23:56.9488696Z -                "Create golden CSV updates for improved parsing"
2025-06-07T23:23:56.9488762Z -            ]
2025-06-07T23:23:56.9488889Z +                "Create golden CSV updates for improved parsing",
2025-06-07T23:23:56.9488954Z +            ],
2025-06-07T23:23:56.9489022Z          }
2025-06-07T23:23:56.9489084Z  
2025-06-07T23:23:56.9489145Z  
2025-06-07T23:23:56.9489340Z  def main():
2025-06-07T23:23:56.9489503Z      analysis_file = Path("diagnostics/comprehensive_analysis.json")
2025-06-07T23:23:56.9489596Z      if not analysis_file.exists():
2025-06-07T23:23:56.9489823Z -        print(f"Analysis file {analysis_file} not found. Run comprehensive_analysis.py first.")
2025-06-07T23:23:56.9489897Z +        print(
2025-06-07T23:23:56.9490099Z +            f"Analysis file {analysis_file} not found. Run comprehensive_analysis.py first."
2025-06-07T23:23:56.9490168Z +        )
2025-06-07T23:23:56.9490235Z          return 1
2025-06-07T23:23:56.9490304Z -    
2025-06-07T23:23:56.9490365Z +
2025-06-07T23:23:56.9490469Z      enhancer = PatternEnhancer(analysis_file)
2025-06-07T23:23:56.9490537Z -    
2025-06-07T23:23:56.9490602Z +
2025-06-07T23:23:56.9490792Z      # Generate pattern report
2025-06-07T23:23:56.9490903Z      report = enhancer.generate_pattern_report()
2025-06-07T23:23:56.9490974Z -    
2025-06-07T23:23:56.9491035Z +
2025-06-07T23:23:56.9491120Z      # Save enhancement report
2025-06-07T23:23:56.9491365Z      enhancement_file = Path("diagnostics/pattern_enhancement.json")
2025-06-07T23:23:56.9491783Z -    with open(enhancement_file, 'w') as f:
2025-06-07T23:23:56.9492061Z +    with open(enhancement_file, "w") as f:
2025-06-07T23:23:56.9492344Z          json.dump(report, f, indent=2, default=str)
2025-06-07T23:23:56.9492605Z -    
2025-06-07T23:23:56.9492760Z +
2025-06-07T23:23:56.9492927Z      # Generate enhanced parser code
2025-06-07T23:23:56.9493221Z      enhanced_code = enhancer.generate_enhanced_parser()
2025-06-07T23:23:56.9493495Z -    
2025-06-07T23:23:56.9493650Z +
2025-06-07T23:23:56.9493817Z      # Save enhanced parser
2025-06-07T23:23:56.9494088Z      parser_file = Path("diagnostics/enhanced_parser.py")
2025-06-07T23:23:56.9494394Z -    with open(parser_file, 'w') as f:
2025-06-07T23:23:56.9494644Z +    with open(parser_file, "w") as f:
2025-06-07T23:23:56.9494879Z          f.write(enhanced_code)
2025-06-07T23:23:56.9495085Z -    
2025-06-07T23:23:56.9495251Z -    print("="*60)
2025-06-07T23:23:56.9495426Z +
2025-06-07T23:23:56.9495581Z +    print("=" * 60)
2025-06-07T23:23:56.9495791Z      print("PATTERN ENHANCEMENT REPORT")
2025-06-07T23:23:56.9496036Z -    print("="*60)
2025-06-07T23:23:56.9496386Z -    print(f"New patterns generated: {report['enhancement_summary']['new_patterns_generated']}")
2025-06-07T23:23:56.9496972Z -    print(f"Lines potentially covered: {report['enhancement_summary']['lines_potentially_covered']}")
2025-06-07T23:23:56.9497609Z -    print(f"Potential success improvement: {report['enhancement_summary']['potential_success_improvement']}")
2025-06-07T23:23:56.9498158Z -    
2025-06-07T23:23:56.9498503Z +    print("=" * 60)
2025-06-07T23:23:56.9498698Z +    print(
2025-06-07T23:23:56.9499018Z +        f"New patterns generated: {report['enhancement_summary']['new_patterns_generated']}"
2025-06-07T23:23:56.9499390Z +    )
2025-06-07T23:23:56.9499546Z +    print(
2025-06-07T23:23:56.9499879Z +        f"Lines potentially covered: {report['enhancement_summary']['lines_potentially_covered']}"
2025-06-07T23:23:56.9500269Z +    )
2025-06-07T23:23:56.9500423Z +    print(
2025-06-07T23:23:56.9500788Z +        f"Potential success improvement: {report['enhancement_summary']['potential_success_improvement']}"
2025-06-07T23:23:56.9501214Z +    )
2025-06-07T23:23:56.9501365Z +
2025-06-07T23:23:56.9501560Z      print("\nTOP 5 IMPLEMENTATION PRIORITIES:")
2025-06-07T23:23:56.9501925Z -    for i, pattern in enumerate(report['implementation_priority'][:5], 1):
2025-06-07T23:23:56.9502350Z +    for i, pattern in enumerate(report["implementation_priority"][:5], 1):
2025-06-07T23:23:56.9502742Z          print(f"{i}. {pattern['name']} - covers {pattern['count']} lines")
2025-06-07T23:23:56.9503075Z          print(f"   Example: {pattern['example']}")
2025-06-07T23:23:56.9503335Z -    
2025-06-07T23:23:56.9503487Z +
2025-06-07T23:23:56.9503706Z      print(f"\nEnhanced parser code saved to: {parser_file}")
2025-06-07T23:23:56.9504064Z      print(f"Enhancement report saved to: {enhancement_file}")
2025-06-07T23:23:56.9504491Z -    
2025-06-07T23:23:56.9504640Z +
2025-06-07T23:23:56.9504788Z      return 0
2025-06-07T23:23:56.9504949Z  
2025-06-07T23:23:56.9505089Z  
2025-06-07T23:23:56.9505371Z diff --git a/scripts/semantic_validator.py b/scripts/semantic_validator.py
2025-06-07T23:23:56.9505733Z index 9a9804a..38af08b 100644
2025-06-07T23:23:56.9505967Z --- a/scripts/semantic_validator.py
2025-06-07T23:23:56.9506217Z +++ b/scripts/semantic_validator.py
2025-06-07T23:23:56.9506490Z @@ -19,53 +19,66 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9506793Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9507131Z  from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9507444Z  
2025-06-07T23:23:56.9507596Z +
2025-06-07T23:23:56.9507861Z  class SemanticValidator:
2025-06-07T23:23:56.9508177Z      """Validates parsed data against business logic and semantic rules."""
2025-06-07T23:23:56.9508687Z -    
2025-06-07T23:23:56.9508843Z +
2025-06-07T23:23:56.9509004Z      def __init__(self):
2025-06-07T23:23:56.9509219Z          self.validation_rules = {
2025-06-07T23:23:56.9509478Z              "min_transaction_amount": Decimal("0.01"),
2025-06-07T23:23:56.9509778Z              "max_transaction_amount": Decimal("100000.00"),
2025-06-07T23:23:56.9510048Z              "valid_categories": {
2025-06-07T23:23:56.9510349Z -                "DIVERSOS", "INTERNACIONAL", "PAGAMENTO", "ENCARGO", "AJUSTE",
2025-06-07T23:23:56.9511145Z -                "ALIMENTACAO", "TRANSPORTE", "SAUDE", "EDUCACAO", "LAZER"
2025-06-07T23:23:56.9511606Z +                "DIVERSOS",
2025-06-07T23:23:56.9511824Z +                "INTERNACIONAL",
2025-06-07T23:23:56.9512048Z +                "PAGAMENTO",
2025-06-07T23:23:56.9512431Z +                "ENCARGO",
2025-06-07T23:23:56.9512630Z +                "AJUSTE",
2025-06-07T23:23:56.9512827Z +                "ALIMENTACAO",
2025-06-07T23:23:56.9513038Z +                "TRANSPORTE",
2025-06-07T23:23:56.9513242Z +                "SAUDE",
2025-06-07T23:23:56.9513534Z +                "EDUCACAO",
2025-06-07T23:23:56.9513729Z +                "LAZER",
2025-06-07T23:23:56.9513909Z              },
2025-06-07T23:23:56.9514096Z              "required_fields": {
2025-06-07T23:23:56.9514373Z -                "card_last4", "post_date", "desc_raw", "amount_brl", 
2025-06-07T23:23:56.9514676Z -                "category", "ledger_hash"
2025-06-07T23:23:56.9514908Z -            }
2025-06-07T23:23:56.9515088Z +                "card_last4",
2025-06-07T23:23:56.9515300Z +                "post_date",
2025-06-07T23:23:56.9515507Z +                "desc_raw",
2025-06-07T23:23:56.9515710Z +                "amount_brl",
2025-06-07T23:23:56.9515917Z +                "category",
2025-06-07T23:23:56.9516124Z +                "ledger_hash",
2025-06-07T23:23:56.9516328Z +            },
2025-06-07T23:23:56.9516495Z          }
2025-06-07T23:23:56.9516654Z -        
2025-06-07T23:23:56.9516811Z +
2025-06-07T23:23:56.9516977Z          self.business_rules = {
2025-06-07T23:23:56.9517222Z              "payment_must_be_negative": True,
2025-06-07T23:23:56.9517493Z              "charges_must_be_positive": True,
2025-06-07T23:23:56.9517767Z              "international_needs_currency": True,
2025-06-07T23:23:56.9518053Z -            "installments_need_sequence": True
2025-06-07T23:23:56.9518522Z +            "installments_need_sequence": True,
2025-06-07T23:23:56.9518771Z          }
2025-06-07T23:23:56.9518931Z -    
2025-06-07T23:23:56.9519088Z +
2025-06-07T23:23:56.9519322Z      def validate_pdf_parsing(self, pdf_path: Path) -> Dict:
2025-06-07T23:23:56.9519671Z          """Comprehensive validation of PDF parsing quality."""
2025-06-07T23:23:56.9519954Z -        
2025-06-07T23:23:56.9520110Z +
2025-06-07T23:23:56.9520279Z          # Extract all lines from PDF
2025-06-07T23:23:56.9520571Z          all_lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9520845Z -        
2025-06-07T23:23:56.9520998Z +
2025-06-07T23:23:56.9521316Z          # Parse with current system
2025-06-07T23:23:56.9521559Z          parsed_transactions = []
2025-06-07T23:23:56.9521786Z          for line in all_lines:
2025-06-07T23:23:56.9522042Z              result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9522309Z              if result:
2025-06-07T23:23:56.9522534Z                  parsed_transactions.append(result)
2025-06-07T23:23:56.9522785Z -        
2025-06-07T23:23:56.9522939Z +
2025-06-07T23:23:56.9523111Z          # Get PDF total for validation
2025-06-07T23:23:56.9523352Z          pdf_total = None
2025-06-07T23:23:56.9523545Z          try:
2025-06-07T23:23:56.9523754Z              pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9524009Z          except:
2025-06-07T23:23:56.9524183Z              pass
2025-06-07T23:23:56.9524498Z -        
2025-06-07T23:23:56.9524656Z +
2025-06-07T23:23:56.9524820Z          # Calculate parsed total
2025-06-07T23:23:56.9525131Z          parsed_total = sum(t["amount_brl"] for t in parsed_transactions)
2025-06-07T23:23:56.9525442Z -        
2025-06-07T23:23:56.9525594Z +
2025-06-07T23:23:56.9525756Z          # Comprehensive validation
2025-06-07T23:23:56.9525995Z          validation_results = {
2025-06-07T23:23:56.9526217Z              "file_info": {
2025-06-07T23:23:56.9526446Z @@ -74,33 +87,39 @@ class SemanticValidator:
2025-06-07T23:23:56.9526746Z                  "parsed_transactions": len(parsed_transactions),
2025-06-07T23:23:56.9527052Z                  "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9527360Z                  "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9527854Z -                "coverage_rate": len(parsed_transactions) / max(1, len(all_lines))
2025-06-07T23:23:56.9528444Z +                "coverage_rate": len(parsed_transactions) / max(1, len(all_lines)),
2025-06-07T23:23:56.9528787Z              },
2025-06-07T23:23:56.9529279Z              "data_quality": self._validate_data_quality(parsed_transactions),
2025-06-07T23:23:56.9529709Z              "business_logic": self._validate_business_logic(parsed_transactions),
2025-06-07T23:23:56.9530207Z -            "missing_transactions": self._detect_missing_transactions(all_lines, parsed_transactions),
2025-06-07T23:23:56.9530754Z -            "total_reconciliation": self._validate_total_reconciliation(parsed_total, pdf_total),
2025-06-07T23:23:56.9531214Z +            "missing_transactions": self._detect_missing_transactions(
2025-06-07T23:23:56.9531535Z +                all_lines, parsed_transactions
2025-06-07T23:23:56.9531776Z +            ),
2025-06-07T23:23:56.9532032Z +            "total_reconciliation": self._validate_total_reconciliation(
2025-06-07T23:23:56.9532356Z +                parsed_total, pdf_total
2025-06-07T23:23:56.9532582Z +            ),
2025-06-07T23:23:56.9532867Z              "categorization": self._validate_categorization(parsed_transactions),
2025-06-07T23:23:56.9533217Z -            "recommendations": []
2025-06-07T23:23:56.9533459Z +            "recommendations": [],
2025-06-07T23:23:56.9533685Z          }
2025-06-07T23:23:56.9533842Z -        
2025-06-07T23:23:56.9534001Z +
2025-06-07T23:23:56.9534172Z          # Generate recommendations
2025-06-07T23:23:56.9534562Z -        validation_results["recommendations"] = self._generate_recommendations(validation_results)
2025-06-07T23:23:56.9534959Z -        
2025-06-07T23:23:56.9535235Z +        validation_results["recommendations"] = self._generate_recommendations(
2025-06-07T23:23:56.9535583Z +            validation_results
2025-06-07T23:23:56.9535821Z +        )
2025-06-07T23:23:56.9535976Z +
2025-06-07T23:23:56.9536143Z          return validation_results
2025-06-07T23:23:56.9536362Z -    
2025-06-07T23:23:56.9536510Z +
2025-06-07T23:23:56.9536759Z      def _validate_data_quality(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9537118Z          """Validate basic data quality issues."""
2025-06-07T23:23:56.9537369Z          issues = []
2025-06-07T23:23:56.9537563Z          stats = defaultdict(int)
2025-06-07T23:23:56.9537917Z -        
2025-06-07T23:23:56.9538072Z +
2025-06-07T23:23:56.9538252Z          for i, txn in enumerate(transactions):
2025-06-07T23:23:56.9538705Z              # Check required fields
2025-06-07T23:23:56.9539061Z              missing_fields = self.validation_rules["required_fields"] - set(txn.keys())
2025-06-07T23:23:56.9539424Z              if missing_fields:
2025-06-07T23:23:56.9539736Z                  issues.append(f"Transaction {i}: Missing fields {missing_fields}")
2025-06-07T23:23:56.9540082Z                  stats["missing_fields"] += 1
2025-06-07T23:23:56.9540318Z -            
2025-06-07T23:23:56.9540479Z +
2025-06-07T23:23:56.9540645Z              # Check amount ranges
2025-06-07T23:23:56.9540906Z              amount = txn.get("amount_brl", Decimal("0"))
2025-06-07T23:23:56.9541367Z              if abs(amount) < self.validation_rules["min_transaction_amount"]:
2025-06-07T23:23:56.9541718Z @@ -109,114 +128,153 @@ class SemanticValidator:
2025-06-07T23:23:56.9542060Z              elif abs(amount) > self.validation_rules["max_transaction_amount"]:
2025-06-07T23:23:56.9542469Z                  issues.append(f"Transaction {i}: Amount too large ({amount})")
2025-06-07T23:23:56.9542805Z                  stats["amount_too_large"] += 1
2025-06-07T23:23:56.9543038Z -            
2025-06-07T23:23:56.9543203Z +
2025-06-07T23:23:56.9543370Z              # Check category validity
2025-06-07T23:23:56.9543622Z              category = txn.get("category", "")
2025-06-07T23:23:56.9543940Z              if category not in self.validation_rules["valid_categories"]:
2025-06-07T23:23:56.9544344Z                  issues.append(f"Transaction {i}: Invalid category '{category}'")
2025-06-07T23:23:56.9544689Z                  stats["invalid_category"] += 1
2025-06-07T23:23:56.9544923Z -            
2025-06-07T23:23:56.9545090Z +
2025-06-07T23:23:56.9545256Z              # Check date format
2025-06-07T23:23:56.9545507Z              post_date = txn.get("post_date", "")
2025-06-07T23:23:56.9545847Z              if not post_date or len(post_date) != 10 or post_date.count("-") != 2:
2025-06-07T23:23:56.9546282Z                  issues.append(f"Transaction {i}: Invalid date format '{post_date}'")
2025-06-07T23:23:56.9546635Z                  stats["invalid_date"] += 1
2025-06-07T23:23:56.9546866Z -        
2025-06-07T23:23:56.9547025Z +
2025-06-07T23:23:56.9547171Z          return {
2025-06-07T23:23:56.9547363Z              "total_issues": len(issues),
2025-06-07T23:23:56.9547631Z              "issues": issues[:20],  # First 20 issues
2025-06-07T23:23:56.9547900Z              "issue_statistics": dict(stats),
2025-06-07T23:23:56.9548239Z -            "data_quality_score": max(0, 1 - len(issues) / max(1, len(transactions)))
2025-06-07T23:23:56.9548844Z +            "data_quality_score": max(0, 1 - len(issues) / max(1, len(transactions))),
2025-06-07T23:23:56.9549162Z          }
2025-06-07T23:23:56.9549321Z -    
2025-06-07T23:23:56.9549475Z +
2025-06-07T23:23:56.9549727Z      def _validate_business_logic(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9550081Z          """Validate business logic rules."""
2025-06-07T23:23:56.9550328Z          violations = []
2025-06-07T23:23:56.9550540Z          stats = defaultdict(int)
2025-06-07T23:23:56.9550754Z -        
2025-06-07T23:23:56.9550902Z +
2025-06-07T23:23:56.9551081Z          for i, txn in enumerate(transactions):
2025-06-07T23:23:56.9551351Z              category = txn.get("category", "")
2025-06-07T23:23:56.9551631Z              amount = txn.get("amount_brl", Decimal("0"))
2025-06-07T23:23:56.9551894Z -            
2025-06-07T23:23:56.9552057Z +
2025-06-07T23:23:56.9552232Z              # Payments should be negative
2025-06-07T23:23:56.9552506Z              if category == "PAGAMENTO" and amount >= 0:
2025-06-07T23:23:56.9552917Z -                violations.append(f"Transaction {i}: Payment should be negative, got {amount}")
2025-06-07T23:23:56.9553299Z +                violations.append(
2025-06-07T23:23:56.9553607Z +                    f"Transaction {i}: Payment should be negative, got {amount}"
2025-06-07T23:23:56.9554027Z +                )
2025-06-07T23:23:56.9554227Z                  stats["positive_payment"] += 1
2025-06-07T23:23:56.9554465Z -            
2025-06-07T23:23:56.9554625Z +
2025-06-07T23:23:56.9554795Z              # Charges should be positive
2025-06-07T23:23:56.9559898Z              if category == "ENCARGO" and amount <= 0:
2025-06-07T23:23:56.9560349Z -                violations.append(f"Transaction {i}: Charge should be positive, got {amount}")
2025-06-07T23:23:56.9560743Z +                violations.append(
2025-06-07T23:23:56.9561075Z +                    f"Transaction {i}: Charge should be positive, got {amount}"
2025-06-07T23:23:56.9561388Z +                )
2025-06-07T23:23:56.9561594Z                  stats["negative_charge"] += 1
2025-06-07T23:23:56.9562008Z -            
2025-06-07T23:23:56.9562183Z +
2025-06-07T23:23:56.9562411Z              # International transactions should have currency info
2025-06-07T23:23:56.9562722Z              if category == "INTERNACIONAL":
2025-06-07T23:23:56.9562999Z                  if not txn.get("currency_orig"):
2025-06-07T23:23:56.9563417Z -                    violations.append(f"Transaction {i}: International transaction missing currency")
2025-06-07T23:23:56.9563822Z +                    violations.append(
2025-06-07T23:23:56.9564146Z +                        f"Transaction {i}: International transaction missing currency"
2025-06-07T23:23:56.9564458Z +                    )
2025-06-07T23:23:56.9564671Z                      stats["missing_currency"] += 1
2025-06-07T23:23:56.9564962Z                  if txn.get("amount_orig", Decimal("0")) == 0:
2025-06-07T23:23:56.9565392Z -                    violations.append(f"Transaction {i}: International transaction missing original amount")
2025-06-07T23:23:56.9565805Z +                    violations.append(
2025-06-07T23:23:56.9566139Z +                        f"Transaction {i}: International transaction missing original amount"
2025-06-07T23:23:56.9566471Z +                    )
2025-06-07T23:23:56.9566688Z                      stats["missing_orig_amount"] += 1
2025-06-07T23:23:56.9566936Z -            
2025-06-07T23:23:56.9567101Z +
2025-06-07T23:23:56.9567297Z              # Installments should have proper sequence
2025-06-07T23:23:56.9567590Z              inst_seq = txn.get("installment_seq", 0)
2025-06-07T23:23:56.9567873Z              inst_tot = txn.get("installment_tot", 0)
2025-06-07T23:23:56.9568188Z              if inst_seq > 0 and (inst_tot == 0 or inst_seq > inst_tot):
2025-06-07T23:23:56.9568835Z -                violations.append(f"Transaction {i}: Invalid installment {inst_seq}/{inst_tot}")
2025-06-07T23:23:56.9569220Z +                violations.append(
2025-06-07T23:23:56.9569538Z +                    f"Transaction {i}: Invalid installment {inst_seq}/{inst_tot}"
2025-06-07T23:23:56.9569846Z +                )
2025-06-07T23:23:56.9570050Z                  stats["invalid_installment"] += 1
2025-06-07T23:23:56.9570294Z -        
2025-06-07T23:23:56.9570457Z +
2025-06-07T23:23:56.9570609Z          return {
2025-06-07T23:23:56.9570811Z              "total_violations": len(violations),
2025-06-07T23:23:56.9571071Z              "violations": violations[:20],
2025-06-07T23:23:56.9571344Z              "violation_statistics": dict(stats),
2025-06-07T23:23:56.9571719Z -            "business_logic_score": max(0, 1 - len(violations) / max(1, len(transactions)))
2025-06-07T23:23:56.9572086Z +            "business_logic_score": max(
2025-06-07T23:23:56.9572373Z +                0, 1 - len(violations) / max(1, len(transactions))
2025-06-07T23:23:56.9572647Z +            ),
2025-06-07T23:23:56.9572818Z          }
2025-06-07T23:23:56.9572978Z -    
2025-06-07T23:23:56.9573340Z -    def _detect_missing_transactions(self, all_lines: List[str], parsed_transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9573768Z +
2025-06-07T23:23:56.9573942Z +    def _detect_missing_transactions(
2025-06-07T23:23:56.9574257Z +        self, all_lines: List[str], parsed_transactions: List[Dict]
2025-06-07T23:23:56.9574683Z +    ) -> Dict:
2025-06-07T23:23:56.9574904Z          """Detect potentially missing transactions."""
2025-06-07T23:23:56.9575265Z          parsed_hashes = {txn["ledger_hash"] for txn in parsed_transactions}
2025-06-07T23:23:56.9575580Z -        
2025-06-07T23:23:56.9575732Z +
2025-06-07T23:23:56.9575893Z          potentially_missing = []
2025-06-07T23:23:56.9576159Z          for line_num, line in enumerate(all_lines, 1):
2025-06-07T23:23:56.9576429Z              # Skip empty lines
2025-06-07T23:23:56.9576673Z              if not line.strip():
2025-06-07T23:23:56.9576893Z                  continue
2025-06-07T23:23:56.9577084Z -            
2025-06-07T23:23:56.9577250Z +
2025-06-07T23:23:56.9577485Z              # Check if line has transaction-like patterns but wasn't parsed
2025-06-07T23:23:56.9577982Z              line_hash = pdf_to_csv.hashlib.sha1(line.encode()).hexdigest()
2025-06-07T23:23:56.9578488Z              if line_hash not in parsed_hashes:
2025-06-07T23:23:56.9578790Z                  # Look for transaction indicators
2025-06-07T23:23:56.9579153Z -                has_amount = bool(pdf_to_csv.re.search(r'\d{1,3}(?:\.\d{3})*,\d{2}', line))
2025-06-07T23:23:56.9579560Z -                has_date = bool(pdf_to_csv.re.search(r'\d{1,2}/\d{1,2}', line))
2025-06-07T23:23:56.9579853Z -                
2025-06-07T23:23:56.9580041Z +                has_amount = bool(
2025-06-07T23:23:56.9580324Z +                    pdf_to_csv.re.search(r"\d{1,3}(?:\.\d{3})*,\d{2}", line)
2025-06-07T23:23:56.9580601Z +                )
2025-06-07T23:23:56.9580848Z +                has_date = bool(pdf_to_csv.re.search(r"\d{1,2}/\d{1,2}", line))
2025-06-07T23:23:56.9581130Z +
2025-06-07T23:23:56.9581306Z                  # Skip obvious headers/footers
2025-06-07T23:23:56.9581562Z                  skip_keywords = [
2025-06-07T23:23:56.9581863Z -                    "FATURA", "VENCIMENTO", "LIMITE", "TOTAL", "PAGINA", "CARTAO",
2025-06-07T23:23:56.9582245Z -                    "MASTERCARD", "VISA", "SAC", "OUVIDORIA", "TELEFONE", "EMAIL",
2025-06-07T23:23:56.9582577Z -                    "EXTRATO", "RESUMO", "PERIODO"
2025-06-07T23:23:56.9582829Z +                    "FATURA",
2025-06-07T23:23:56.9583042Z +                    "VENCIMENTO",
2025-06-07T23:23:56.9583262Z +                    "LIMITE",
2025-06-07T23:23:56.9583463Z +                    "TOTAL",
2025-06-07T23:23:56.9583668Z +                    "PAGINA",
2025-06-07T23:23:56.9583871Z +                    "CARTAO",
2025-06-07T23:23:56.9584072Z +                    "MASTERCARD",
2025-06-07T23:23:56.9584284Z +                    "VISA",
2025-06-07T23:23:56.9584487Z +                    "SAC",
2025-06-07T23:23:56.9584690Z +                    "OUVIDORIA",
2025-06-07T23:23:56.9584907Z +                    "TELEFONE",
2025-06-07T23:23:56.9585114Z +                    "EMAIL",
2025-06-07T23:23:56.9585318Z +                    "EXTRATO",
2025-06-07T23:23:56.9585522Z +                    "RESUMO",
2025-06-07T23:23:56.9585730Z +                    "PERIODO",
2025-06-07T23:23:56.9585962Z                  ]
2025-06-07T23:23:56.9586140Z -                
2025-06-07T23:23:56.9586310Z +
2025-06-07T23:23:56.9586559Z                  has_skip_keyword = any(kw in line.upper() for kw in skip_keywords)
2025-06-07T23:23:56.9586867Z -                
2025-06-07T23:23:56.9587035Z +
2025-06-07T23:23:56.9587243Z                  if (has_amount or has_date) and not has_skip_keyword:
2025-06-07T23:23:56.9587550Z -                    potentially_missing.append({
2025-06-07T23:23:56.9587817Z -                        "line_number": line_num,
2025-06-07T23:23:56.9588101Z -                        "line_content": line[:100],  # First 100 chars
2025-06-07T23:23:56.9588554Z -                        "has_amount": has_amount,
2025-06-07T23:23:56.9588819Z -                        "has_date": has_date,
2025-06-07T23:23:56.9589154Z -                        "confidence": "high" if (has_amount and has_date) else "medium"
2025-06-07T23:23:56.9589470Z -                    })
2025-06-07T23:23:56.9589778Z -        
2025-06-07T23:23:56.9589964Z +                    potentially_missing.append(
2025-06-07T23:23:56.9590209Z +                        {
2025-06-07T23:23:56.9590425Z +                            "line_number": line_num,
2025-06-07T23:23:56.9590711Z +                            "line_content": line[:100],  # First 100 chars
2025-06-07T23:23:56.9591003Z +                            "has_amount": has_amount,
2025-06-07T23:23:56.9591261Z +                            "has_date": has_date,
2025-06-07T23:23:56.9591514Z +                            "confidence": "high"
2025-06-07T23:23:56.9591772Z +                            if (has_amount and has_date)
2025-06-07T23:23:56.9592032Z +                            else "medium",
2025-06-07T23:23:56.9592259Z +                        }
2025-06-07T23:23:56.9592558Z +                    )
2025-06-07T23:23:56.9592738Z +
2025-06-07T23:23:56.9592896Z          # Sort by confidence
2025-06-07T23:23:56.9593333Z -        potentially_missing.sort(key=lambda x: (x["confidence"] == "high", x["has_amount"], x["has_date"]), reverse=True)
2025-06-07T23:23:56.9593772Z -        
2025-06-07T23:23:56.9593949Z +        potentially_missing.sort(
2025-06-07T23:23:56.9594276Z +            key=lambda x: (x["confidence"] == "high", x["has_amount"], x["has_date"]),
2025-06-07T23:23:56.9594610Z +            reverse=True,
2025-06-07T23:23:56.9594804Z +        )
2025-06-07T23:23:56.9594957Z +
2025-06-07T23:23:56.9595106Z          return {
2025-06-07T23:23:56.9595348Z              "total_potentially_missing": len(potentially_missing),
2025-06-07T23:23:56.9595801Z -            "high_confidence_missing": len([m for m in potentially_missing if m["confidence"] == "high"]),
2025-06-07T23:23:56.9596212Z +            "high_confidence_missing": len(
2025-06-07T23:23:56.9596524Z +                [m for m in potentially_missing if m["confidence"] == "high"]
2025-06-07T23:23:56.9596813Z +            ),
2025-06-07T23:23:56.9597069Z              "missing_lines": potentially_missing[:30],  # Top 30 candidates
2025-06-07T23:23:56.9597462Z -            "missing_rate": len(potentially_missing) / max(1, len(all_lines))
2025-06-07T23:23:56.9597857Z +            "missing_rate": len(potentially_missing) / max(1, len(all_lines)),
2025-06-07T23:23:56.9598159Z          }
2025-06-07T23:23:56.9598546Z -    
2025-06-07T23:23:56.9598922Z -    def _validate_total_reconciliation(self, parsed_total: Decimal, pdf_total: Optional[Decimal]) -> Dict:
2025-06-07T23:23:56.9599343Z +
2025-06-07T23:23:56.9599515Z +    def _validate_total_reconciliation(
2025-06-07T23:23:56.9599831Z +        self, parsed_total: Decimal, pdf_total: Optional[Decimal]
2025-06-07T23:23:56.9600125Z +    ) -> Dict:
2025-06-07T23:23:56.9600338Z          """Validate total amount reconciliation."""
2025-06-07T23:23:56.9600604Z          if pdf_total is None:
2025-06-07T23:23:56.9600821Z              return {
2025-06-07T23:23:56.9601039Z @@ -224,12 +282,12 @@ class SemanticValidator:
2025-06-07T23:23:56.9601333Z                  "message": "PDF total could not be extracted",
2025-06-07T23:23:56.9601634Z                  "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9601888Z                  "pdf_total": None,
2025-06-07T23:23:56.9602112Z -                "delta": None
2025-06-07T23:23:56.9602325Z +                "delta": None,
2025-06-07T23:23:56.9602528Z              }
2025-06-07T23:23:56.9602693Z -        
2025-06-07T23:23:56.9602847Z +
2025-06-07T23:23:56.9603024Z          delta = abs(parsed_total - pdf_total)
2025-06-07T23:23:56.9603281Z          tolerance = Decimal("0.01")
2025-06-07T23:23:56.9603497Z -        
2025-06-07T23:23:56.9603653Z +
2025-06-07T23:23:56.9603810Z          if delta <= tolerance:
2025-06-07T23:23:56.9604023Z              status = "match"
2025-06-07T23:23:56.9604265Z              message = "Totals match within tolerance"
2025-06-07T23:23:56.9604551Z @@ -239,54 +297,60 @@ class SemanticValidator:
2025-06-07T23:23:56.9604791Z          else:
2025-06-07T23:23:56.9604974Z              status = "major_mismatch"
2025-06-07T23:23:56.9605360Z              message = f"Major total mismatch: {delta}"
2025-06-07T23:23:56.9605612Z -        
2025-06-07T23:23:56.9605766Z +
2025-06-07T23:23:56.9605917Z          return {
2025-06-07T23:23:56.9606099Z              "status": status,
2025-06-07T23:23:56.9606319Z              "message": message,
2025-06-07T23:23:56.9606561Z              "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9606835Z              "pdf_total": float(pdf_total),
2025-06-07T23:23:56.9607075Z              "delta": float(delta),
2025-06-07T23:23:56.9607406Z -            "delta_percentage": float(delta / pdf_total * 100) if pdf_total else None
2025-06-07T23:23:56.9607855Z +            "delta_percentage": float(delta / pdf_total * 100) if pdf_total else None,
2025-06-07T23:23:56.9608188Z          }
2025-06-07T23:23:56.9608663Z -    
2025-06-07T23:23:56.9608825Z +
2025-06-07T23:23:56.9609088Z      def _validate_categorization(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9609466Z          """Validate transaction categorization quality."""
2025-06-07T23:23:56.9609871Z -        category_counts = Counter(txn.get("category", "UNKNOWN") for txn in transactions)
2025-06-07T23:23:56.9610220Z -        
2025-06-07T23:23:56.9610387Z +        category_counts = Counter(
2025-06-07T23:23:56.9610664Z +            txn.get("category", "UNKNOWN") for txn in transactions
2025-06-07T23:23:56.9610935Z +        )
2025-06-07T23:23:56.9611083Z +
2025-06-07T23:23:56.9611262Z          # Detect potential categorization issues
2025-06-07T23:23:56.9611510Z          issues = []
2025-06-07T23:23:56.9611780Z          if category_counts.get("DIVERSOS", 0) > len(transactions) * 0.8:
2025-06-07T23:23:56.9612171Z              issues.append("Too many transactions categorized as DIVERSOS")
2025-06-07T23:23:56.9612468Z -        
2025-06-07T23:23:56.9612622Z +
2025-06-07T23:23:56.9612799Z          if category_counts.get("UNKNOWN", 0) > 0:
2025-06-07T23:23:56.9613184Z -            issues.append(f"{category_counts['UNKNOWN']} transactions with unknown category")
2025-06-07T23:23:56.9613540Z -        
2025-06-07T23:23:56.9613703Z +            issues.append(
2025-06-07T23:23:56.9614001Z +                f"{category_counts['UNKNOWN']} transactions with unknown category"
2025-06-07T23:23:56.9614310Z +            )
2025-06-07T23:23:56.9614476Z +
2025-06-07T23:23:56.9614644Z          # Check for missing common categories
2025-06-07T23:23:56.9614897Z          common_patterns = {
2025-06-07T23:23:56.9615186Z              "ALIMENTACAO": ["IFOOD", "RESTAURANTE", "PADARIA", "MERCADO"],
2025-06-07T23:23:56.9615548Z              "TRANSPORTE": ["UBER", "99", "POSTO", "COMBUSTIVEL"],
2025-06-07T23:23:56.9615872Z -            "SAUDE": ["FARMACIA", "HOSPITAL", "CLINICA", "MEDICO"]
2025-06-07T23:23:56.9616198Z +            "SAUDE": ["FARMACIA", "HOSPITAL", "CLINICA", "MEDICO"],
2025-06-07T23:23:56.9616465Z          }
2025-06-07T23:23:56.9616617Z -        
2025-06-07T23:23:56.9616766Z +
2025-06-07T23:23:56.9616967Z          for category, patterns in common_patterns.items():
2025-06-07T23:23:56.9617278Z              if category_counts.get(category, 0) == 0:
2025-06-07T23:23:56.9617607Z                  # Check if we have transactions that should be in this category
2025-06-07T23:23:56.9617921Z                  for txn in transactions:
2025-06-07T23:23:56.9618182Z                      desc = txn.get("desc_raw", "").upper()
2025-06-07T23:23:56.9618619Z                      if any(pattern in desc for pattern in patterns):
2025-06-07T23:23:56.9619013Z -                        issues.append(f"Found {category} transactions not properly categorized")
2025-06-07T23:23:56.9619376Z +                        issues.append(
2025-06-07T23:23:56.9619683Z +                            f"Found {category} transactions not properly categorized"
2025-06-07T23:23:56.9619983Z +                        )
2025-06-07T23:23:56.9620182Z                          break
2025-06-07T23:23:56.9620380Z -        
2025-06-07T23:23:56.9620529Z +
2025-06-07T23:23:56.9620674Z          return {
2025-06-07T23:23:56.9621016Z              "category_distribution": dict(category_counts),
2025-06-07T23:23:56.9621304Z              "categorization_issues": issues,
2025-06-07T23:23:56.9621634Z -            "categorization_score": 1 - len(issues) / 10  # Normalize to 0-1
2025-06-07T23:23:56.9622035Z +            "categorization_score": 1 - len(issues) / 10,  # Normalize to 0-1
2025-06-07T23:23:56.9622333Z          }
2025-06-07T23:23:56.9622484Z -    
2025-06-07T23:23:56.9622629Z +
2025-06-07T23:23:56.9622898Z      def _generate_recommendations(self, validation_results: Dict) -> List[str]:
2025-06-07T23:23:56.9623341Z          """Generate actionable recommendations based on validation results."""
2025-06-07T23:23:56.9623678Z          recommendations = []
2025-06-07T23:23:56.9623879Z -        
2025-06-07T23:23:56.9624025Z +
2025-06-07T23:23:56.9624284Z          # Missing transactions
2025-06-07T23:23:56.9624554Z          missing = validation_results["missing_transactions"]
2025-06-07T23:23:56.9624867Z          if missing["high_confidence_missing"] > 0:
2025-06-07T23:23:56.9625151Z @@ -294,7 +358,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9625498Z                  f"HIGH PRIORITY: {missing['high_confidence_missing']} high-confidence "
2025-06-07T23:23:56.9625921Z                  f"transactions appear to be missing. Review parsing patterns."
2025-06-07T23:23:56.9626233Z              )
2025-06-07T23:23:56.9626395Z -        
2025-06-07T23:23:56.9626540Z +
2025-06-07T23:23:56.9626695Z          # Total reconciliation
2025-06-07T23:23:56.9626960Z          total_val = validation_results["total_reconciliation"]
2025-06-07T23:23:56.9627272Z          if total_val["status"] == "major_mismatch":
2025-06-07T23:23:56.9627545Z @@ -302,7 +366,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9627928Z                  f"CRITICAL: Major total mismatch ({total_val['delta_percentage']:.1f}% difference). "
2025-06-07T23:23:56.9628438Z                  f"Significant transactions are being missed."
2025-06-07T23:23:56.9628720Z              )
2025-06-07T23:23:56.9628897Z -        
2025-06-07T23:23:56.9629041Z +
2025-06-07T23:23:56.9629190Z          # Data quality
2025-06-07T23:23:56.9629423Z          quality = validation_results["data_quality"]
2025-06-07T23:23:56.9629711Z          if quality["data_quality_score"] < 0.9:
2025-06-07T23:23:56.9629981Z @@ -310,7 +374,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9630319Z                  f"Data quality issues detected ({quality['total_issues']} issues). "
2025-06-07T23:23:56.9630687Z                  f"Review field validation and parsing logic."
2025-06-07T23:23:56.9630950Z              )
2025-06-07T23:23:56.9631110Z -        
2025-06-07T23:23:56.9631256Z +
2025-06-07T23:23:56.9631407Z          # Business logic
2025-06-07T23:23:56.9631650Z          business = validation_results["business_logic"]
2025-06-07T23:23:56.9631946Z          if business["business_logic_score"] < 0.95:
2025-06-07T23:23:56.9632220Z @@ -318,7 +382,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9632428Z                  f"Business logic violations found ({business['total_violations']} violations). "
2025-06-07T23:23:56.9632549Z                  f"Review categorization and amount parsing."
2025-06-07T23:23:56.9632613Z              )
2025-06-07T23:23:56.9632679Z -        
2025-06-07T23:23:56.9632740Z +
2025-06-07T23:23:56.9632817Z          # Coverage rate
2025-06-07T23:23:56.9632963Z          coverage = validation_results["file_info"]["coverage_rate"]
2025-06-07T23:23:56.9633080Z          if coverage < 0.3:  # Less than 30% of lines parsed
2025-06-07T23:23:56.9633171Z @@ -326,7 +390,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9633360Z                  f"LOW COVERAGE: Only {coverage:.1%} of lines were parsed as transactions. "
2025-06-07T23:23:56.9633467Z                  f"Consider adding more parsing patterns."
2025-06-07T23:23:56.9633536Z              )
2025-06-07T23:23:56.9633598Z -        
2025-06-07T23:23:56.9633659Z +
2025-06-07T23:23:56.9633742Z          return recommendations
2025-06-07T23:23:56.9633803Z  
2025-06-07T23:23:56.9633987Z  
2025-06-07T23:23:56.9634062Z @@ -335,59 +399,63 @@ def main():
2025-06-07T23:23:56.9634238Z      parser.add_argument("pdf_path", help="Path to PDF file to validate")
2025-06-07T23:23:56.9634427Z      parser.add_argument("--output", "-o", help="Output file for validation report")
2025-06-07T23:23:56.9634513Z      args = parser.parse_args()
2025-06-07T23:23:56.9634576Z -    
2025-06-07T23:23:56.9634636Z +
2025-06-07T23:23:56.9634726Z      pdf_path = Path(args.pdf_path)
2025-06-07T23:23:56.9634810Z      if not pdf_path.exists():
2025-06-07T23:23:56.9634932Z          print(f"Error: PDF file {pdf_path} does not exist")
2025-06-07T23:23:56.9634997Z          return 1
2025-06-07T23:23:56.9635062Z -    
2025-06-07T23:23:56.9635122Z +
2025-06-07T23:23:56.9635213Z      validator = SemanticValidator()
2025-06-07T23:23:56.9635374Z -    
2025-06-07T23:23:56.9635440Z +
2025-06-07T23:23:56.9635536Z      print(f"Validating {pdf_path.name}...")
2025-06-07T23:23:56.9635726Z      validation_results = validator.validate_pdf_parsing(pdf_path)
2025-06-07T23:23:56.9635796Z -    
2025-06-07T23:23:56.9635855Z +
2025-06-07T23:23:56.9635937Z      # Save report if requested
2025-06-07T23:23:56.9636011Z      if args.output:
2025-06-07T23:23:56.9636102Z          output_path = Path(args.output)
2025-06-07T23:23:56.9636245Z          output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9636345Z -        with open(output_path, 'w') as f:
2025-06-07T23:23:56.9636429Z +        with open(output_path, "w") as f:
2025-06-07T23:23:56.9636566Z              json.dump(validation_results, f, indent=2, default=str)
2025-06-07T23:23:56.9636687Z          print(f"Validation report saved to {output_path}")
2025-06-07T23:23:56.9636749Z -    
2025-06-07T23:23:56.9636811Z +
2025-06-07T23:23:56.9636881Z      # Print summary
2025-06-07T23:23:56.9636963Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9637037Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9637130Z      print("SEMANTIC VALIDATION SUMMARY")
2025-06-07T23:23:56.9637200Z -    print("="*60)
2025-06-07T23:23:56.9637269Z -    
2025-06-07T23:23:56.9637338Z +    print("=" * 60)
2025-06-07T23:23:56.9637402Z +
2025-06-07T23:23:56.9637510Z      file_info = validation_results["file_info"]
2025-06-07T23:23:56.9637603Z      print(f"File: {file_info['pdf_name']}")
2025-06-07T23:23:56.9637735Z      print(f"Lines processed: {file_info['total_lines']}")
2025-06-07T23:23:56.9637904Z      print(f"Transactions parsed: {file_info['parsed_transactions']}")
2025-06-07T23:23:56.9638039Z      print(f"Coverage rate: {file_info['coverage_rate']:.1%}")
2025-06-07T23:23:56.9638102Z -    
2025-06-07T23:23:56.9638164Z +
2025-06-07T23:23:56.9638405Z      total_val = validation_results["total_reconciliation"]
2025-06-07T23:23:56.9638561Z      print(f"Total reconciliation: {total_val['status'].upper()}")
2025-06-07T23:23:56.9638704Z      if total_val["delta"]:
2025-06-07T23:23:56.9638835Z          print(f"  Parsed: R$ {total_val['parsed_total']:.2f}")
2025-06-07T23:23:56.9638949Z          print(f"  PDF: R$ {total_val['pdf_total']:.2f}")
2025-06-07T23:23:56.9639144Z -        print(f"  Delta: R$ {total_val['delta']:.2f} ({total_val['delta_percentage']:.1f}%)")
2025-06-07T23:23:56.9639207Z -    
2025-06-07T23:23:56.9639272Z +        print(
2025-06-07T23:23:56.9639447Z +            f"  Delta: R$ {total_val['delta']:.2f} ({total_val['delta_percentage']:.1f}%)"
2025-06-07T23:23:56.9639509Z +        )
2025-06-07T23:23:56.9639572Z +
2025-06-07T23:23:56.9639683Z      quality = validation_results["data_quality"]
2025-06-07T23:23:56.9639846Z      print(f"Data quality score: {quality['data_quality_score']:.1%}")
2025-06-07T23:23:56.9639907Z -    
2025-06-07T23:23:56.9639969Z +
2025-06-07T23:23:56.9640082Z      business = validation_results["business_logic"]
2025-06-07T23:23:56.9640258Z      print(f"Business logic score: {business['business_logic_score']:.1%}")
2025-06-07T23:23:56.9640319Z -    
2025-06-07T23:23:56.9640382Z +
2025-06-07T23:23:56.9640508Z      missing = validation_results["missing_transactions"]
2025-06-07T23:23:56.9640888Z -    print(f"Potentially missing transactions: {missing['total_potentially_missing']} "
2025-06-07T23:23:56.9641030Z -          f"({missing['high_confidence_missing']} high confidence)")
2025-06-07T23:23:56.9641093Z -    
2025-06-07T23:23:56.9641161Z +    print(
2025-06-07T23:23:56.9641362Z +        f"Potentially missing transactions: {missing['total_potentially_missing']} "
2025-06-07T23:23:56.9641498Z +        f"({missing['high_confidence_missing']} high confidence)"
2025-06-07T23:23:56.9641560Z +    )
2025-06-07T23:23:56.9641622Z +
2025-06-07T23:23:56.9641765Z      recommendations = validation_results["recommendations"]
2025-06-07T23:23:56.9641847Z      if recommendations:
2025-06-07T23:23:56.9641937Z          print("\nRECOMMENDATIONS:")
2025-06-07T23:23:56.9642149Z          for i, rec in enumerate(recommendations, 1):
2025-06-07T23:23:56.9642234Z              print(f"{i}. {rec}")
2025-06-07T23:23:56.9642295Z -    
2025-06-07T23:23:56.9642361Z +
2025-06-07T23:23:56.9642425Z      return 0
2025-06-07T23:23:56.9642491Z  
2025-06-07T23:23:56.9642552Z  
2025-06-07T23:23:56.9642780Z diff --git a/scripts/validate_real_accuracy.py b/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9642858Z index 6f522d2..84bb478 100644
2025-06-07T23:23:56.9642955Z --- a/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9643044Z +++ b/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9643154Z @@ -17,35 +17,38 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9643258Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9643422Z  from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9643486Z  
2025-06-07T23:23:56.9643546Z +
2025-06-07T23:23:56.9643671Z  def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9643826Z      """Validate parsing accuracy using PDF total as ground truth."""
2025-06-07T23:23:56.9643890Z -    
2025-06-07T23:23:56.9643949Z +
2025-06-07T23:23:56.9644024Z      # Extract all lines
2025-06-07T23:23:56.9644148Z      all_lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9644214Z -    
2025-06-07T23:23:56.9644278Z +
2025-06-07T23:23:56.9644356Z      # Parse transactions
2025-06-07T23:23:56.9644442Z      parsed_transactions = []
2025-06-07T23:23:56.9644520Z      for line in all_lines:
2025-06-07T23:23:56.9644637Z          result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9644703Z          if result:
2025-06-07T23:23:56.9644806Z              parsed_transactions.append(result)
2025-06-07T23:23:56.9644868Z -    
2025-06-07T23:23:56.9644931Z +
2025-06-07T23:23:56.9645004Z      # Calculate totals
2025-06-07T23:23:56.9645155Z      parsed_total = sum(t["amount_brl"] for t in parsed_transactions)
2025-06-07T23:23:56.9645219Z -    
2025-06-07T23:23:56.9645278Z +
2025-06-07T23:23:56.9645345Z      try:
2025-06-07T23:23:56.9645455Z          pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9645538Z          total_available = True
2025-06-07T23:23:56.9645618Z -    except Exception as e:
2025-06-07T23:23:56.9645698Z +    except Exception:
2025-06-07T23:23:56.9645772Z          pdf_total = None
2025-06-07T23:23:56.9645854Z          total_available = False
2025-06-07T23:23:56.9645914Z -    
2025-06-07T23:23:56.9645974Z +
2025-06-07T23:23:56.9646057Z      # Calculate accuracy metrics
2025-06-07T23:23:56.9646212Z      coverage_rate = len(parsed_transactions) / max(1, len(all_lines))
2025-06-07T23:23:56.9646275Z -    
2025-06-07T23:23:56.9646336Z +
2025-06-07T23:23:56.9646428Z      if total_available and pdf_total:
2025-06-07T23:23:56.9646532Z          total_delta = abs(parsed_total - pdf_total)
2025-06-07T23:23:56.9646729Z -        total_accuracy = max(0, 1 - (total_delta / abs(pdf_total))) if pdf_total != 0 else 0
2025-06-07T23:23:56.9646803Z +        total_accuracy = (
2025-06-07T23:23:56.9646954Z +            max(0, 1 - (total_delta / abs(pdf_total))) if pdf_total != 0 else 0
2025-06-07T23:23:56.9647017Z +        )
2025-06-07T23:23:56.9647124Z          missing_amount = pdf_total - parsed_total
2025-06-07T23:23:56.9647412Z          missing_percentage = (missing_amount / pdf_total * 100) if pdf_total != 0 else 0
2025-06-07T23:23:56.9647477Z      else:
2025-06-07T23:23:56.9647624Z @@ -53,13 +56,13 @@ def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9647705Z          total_accuracy = None
2025-06-07T23:23:56.9647784Z          missing_amount = None
2025-06-07T23:23:56.9647865Z          missing_percentage = None
2025-06-07T23:23:56.9647929Z -    
2025-06-07T23:23:56.9647992Z +
2025-06-07T23:23:56.9648058Z      return {
2025-06-07T23:23:56.9648141Z          "pdf_name": pdf_path.name,
2025-06-07T23:23:56.9648215Z          "line_coverage": {
2025-06-07T23:23:56.9648403Z              "total_lines": len(all_lines),
2025-06-07T23:23:56.9648620Z              "parsed_lines": len(parsed_transactions),
2025-06-07T23:23:56.9648718Z -            "coverage_rate": coverage_rate
2025-06-07T23:23:56.9648809Z +            "coverage_rate": coverage_rate,
2025-06-07T23:23:56.9648875Z          },
2025-06-07T23:23:56.9648958Z          "financial_accuracy": {
2025-06-07T23:23:56.9649087Z              "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9649227Z @@ -68,14 +71,15 @@ def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9649322Z              "total_accuracy": total_accuracy,
2025-06-07T23:23:56.9649486Z              "missing_amount": float(missing_amount) if missing_amount else None,
2025-06-07T23:23:56.9649590Z              "missing_percentage": missing_percentage,
2025-06-07T23:23:56.9649682Z -            "total_available": total_available
2025-06-07T23:23:56.9649780Z +            "total_available": total_available,
2025-06-07T23:23:56.9649843Z          },
2025-06-07T23:23:56.9650012Z -        "quality_assessment": _assess_quality(coverage_rate, total_accuracy)
2025-06-07T23:23:56.9650187Z +        "quality_assessment": _assess_quality(coverage_rate, total_accuracy),
2025-06-07T23:23:56.9650251Z      }
2025-06-07T23:23:56.9650317Z  
2025-06-07T23:23:56.9650382Z +
2025-06-07T23:23:56.9650567Z  def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9650662Z      """Assess overall parsing quality."""
2025-06-07T23:23:56.9650729Z -    
2025-06-07T23:23:56.9650790Z +
2025-06-07T23:23:56.9650871Z      # Coverage assessment
2025-06-07T23:23:56.9650951Z      if coverage_rate >= 0.8:
2025-06-07T23:23:56.9651036Z          coverage_grade = "A"
2025-06-07T23:23:56.9651241Z @@ -85,7 +89,7 @@ def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9651317Z          coverage_grade = "C"
2025-06-07T23:23:56.9651386Z      else:
2025-06-07T23:23:56.9651461Z          coverage_grade = "F"
2025-06-07T23:23:56.9651526Z -    
2025-06-07T23:23:56.9651589Z +
2025-06-07T23:23:56.9651696Z      # Total accuracy assessment (if available)
2025-06-07T23:23:56.9651781Z      if total_accuracy is not None:
2025-06-07T23:23:56.9651864Z          if total_accuracy >= 0.99:
2025-06-07T23:23:56.9652079Z @@ -100,111 +104,136 @@ def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9652162Z              accuracy_grade = "F"
2025-06-07T23:23:56.9652229Z      else:
2025-06-07T23:23:56.9652307Z          accuracy_grade = "Unknown"
2025-06-07T23:23:56.9652371Z -    
2025-06-07T23:23:56.9652431Z +
2025-06-07T23:23:56.9652499Z      return {
2025-06-07T23:23:56.9652589Z          "coverage_grade": coverage_grade,
2025-06-07T23:23:56.9652678Z          "accuracy_grade": accuracy_grade,
2025-06-07T23:23:56.9652854Z -        "overall_assessment": _get_overall_grade(coverage_grade, accuracy_grade)
2025-06-07T23:23:56.9653030Z +        "overall_assessment": _get_overall_grade(coverage_grade, accuracy_grade),
2025-06-07T23:23:56.9653094Z      }
2025-06-07T23:23:56.9653154Z  
2025-06-07T23:23:56.9653218Z +
2025-06-07T23:23:56.9653396Z  def _get_overall_grade(coverage_grade: str, accuracy_grade: str) -> str:
2025-06-07T23:23:56.9653487Z      """Get overall quality grade."""
2025-06-07T23:23:56.9653568Z      if accuracy_grade == "Unknown":
2025-06-07T23:23:56.9653848Z          return f"Coverage: {coverage_grade} (Financial accuracy unknown)"
2025-06-07T23:23:56.9653910Z -    
2025-06-07T23:23:56.9653973Z +
2025-06-07T23:23:56.9654095Z      grades = {"A+": 4.3, "A": 4.0, "B": 3.0, "C": 2.0, "F": 0.0}
2025-06-07T23:23:56.9654271Z      avg = (grades.get(coverage_grade, 0) + grades.get(accuracy_grade, 0)) / 2
2025-06-07T23:23:56.9654332Z -    
2025-06-07T23:23:56.9654400Z +
2025-06-07T23:23:56.9654470Z      if avg >= 4.0:
2025-06-07T23:23:56.9654546Z          return "EXCELLENT"
2025-06-07T23:23:56.9654621Z      elif avg >= 3.0:
2025-06-07T23:23:56.9654695Z -        return "GOOD" 
2025-06-07T23:23:56.9654766Z +        return "GOOD"
2025-06-07T23:23:56.9654836Z      elif avg >= 2.0:
2025-06-07T23:23:56.9654985Z          return "FAIR"
2025-06-07T23:23:56.9655052Z      else:
2025-06-07T23:23:56.9655129Z          return "POOR"
2025-06-07T23:23:56.9655189Z  
2025-06-07T23:23:56.9655250Z +
2025-06-07T23:23:56.9655320Z  def main():
2025-06-07T23:23:56.9655572Z -    parser = argparse.ArgumentParser(description="Real accuracy validation using PDF totals")
2025-06-07T23:23:56.9655673Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9655813Z +        description="Real accuracy validation using PDF totals"
2025-06-07T23:23:56.9655878Z +    )
2025-06-07T23:23:56.9656044Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9656230Z -    parser.add_argument("--output", default="diagnostics/real_accuracy.json", 
2025-06-07T23:23:56.9656331Z -                       help="Output file for results")
2025-06-07T23:23:56.9656413Z +    parser.add_argument(
2025-06-07T23:23:56.9656484Z +        "--output",
2025-06-07T23:23:56.9656595Z +        default="diagnostics/real_accuracy.json",
2025-06-07T23:23:56.9656687Z +        help="Output file for results",
2025-06-07T23:23:56.9656750Z +    )
2025-06-07T23:23:56.9656840Z      args = parser.parse_args()
2025-06-07T23:23:56.9656901Z -    
2025-06-07T23:23:56.9656970Z +
2025-06-07T23:23:56.9657055Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9657140Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9657261Z          print(f"Error: Directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9657332Z          return 1
2025-06-07T23:23:56.9657394Z -    
2025-06-07T23:23:56.9657455Z +
2025-06-07T23:23:56.9657536Z      # Validate all PDFs
2025-06-07T23:23:56.9657603Z      results = []
2025-06-07T23:23:56.9657697Z      total_missing_amount = Decimal("0")
2025-06-07T23:23:56.9657781Z      total_pdf_amount = Decimal("0")
2025-06-07T23:23:56.9657866Z      validatable_pdfs = 0
2025-06-07T23:23:56.9657930Z -    
2025-06-07T23:23:56.9657995Z +
2025-06-07T23:23:56.9658083Z      print("REAL ACCURACY VALIDATION")
2025-06-07T23:23:56.9658158Z      print("=" * 50)
2025-06-07T23:23:56.9658223Z -    
2025-06-07T23:23:56.9658381Z +
2025-06-07T23:23:56.9658502Z      for pdf_path in sorted(pdf_dir.glob("*.pdf")):
2025-06-07T23:23:56.9658606Z          result = validate_real_accuracy(pdf_path)
2025-06-07T23:23:56.9658699Z          results.append(result)
2025-06-07T23:23:56.9658763Z -        
2025-06-07T23:23:56.9658830Z +
2025-06-07T23:23:56.9658930Z          financial = result["financial_accuracy"]
2025-06-07T23:23:56.9659030Z          quality = result["quality_assessment"]
2025-06-07T23:23:56.9659094Z -        
2025-06-07T23:23:56.9659160Z +
2025-06-07T23:23:56.9659382Z          print(f"\nðŸ“„ {result['pdf_name']}")
2025-06-07T23:23:56.9659634Z -        print(f"   Coverage: {result['line_coverage']['coverage_rate']:.1%} ({quality['coverage_grade']})")
2025-06-07T23:23:56.9659702Z -        
2025-06-07T23:23:56.9659770Z +        print(
2025-06-07T23:23:56.9659992Z +            f"   Coverage: {result['line_coverage']['coverage_rate']:.1%} ({quality['coverage_grade']})"
2025-06-07T23:23:56.9660063Z +        )
2025-06-07T23:23:56.9660131Z +
2025-06-07T23:23:56.9660224Z          if financial["total_available"]:
2025-06-07T23:23:56.9660314Z              validatable_pdfs += 1
2025-06-07T23:23:56.9660561Z              pdf_total = Decimal(str(financial["pdf_total"]))
2025-06-07T23:23:56.9660688Z              missing = Decimal(str(financial["missing_amount"]))
2025-06-07T23:23:56.9660775Z              total_pdf_amount += pdf_total
2025-06-07T23:23:56.9660863Z              total_missing_amount += missing
2025-06-07T23:23:56.9660930Z -            
2025-06-07T23:23:56.9661184Z -            print(f"   Financial: {financial['missing_percentage']:.1f}% missing ({quality['accuracy_grade']})")
2025-06-07T23:23:56.9661396Z -            print(f"   Total: R$ {financial['parsed_total']:.2f} / R$ {financial['pdf_total']:.2f}")
2025-06-07T23:23:56.9661457Z +
2025-06-07T23:23:56.9661530Z +            print(
2025-06-07T23:23:56.9661862Z +                f"   Financial: {financial['missing_percentage']:.1f}% missing ({quality['accuracy_grade']})"
2025-06-07T23:23:56.9661931Z +            )
2025-06-07T23:23:56.9661998Z +            print(
2025-06-07T23:23:56.9662187Z +                f"   Total: R$ {financial['parsed_total']:.2f} / R$ {financial['pdf_total']:.2f}"
2025-06-07T23:23:56.9662255Z +            )
2025-06-07T23:23:56.9662322Z          else:
2025-06-07T23:23:56.9662488Z -            print(f"   Financial: Cannot validate (PDF total not extractable)")
2025-06-07T23:23:56.9662554Z -        
2025-06-07T23:23:56.9662712Z +            print("   Financial: Cannot validate (PDF total not extractable)")
2025-06-07T23:23:56.9662774Z +
2025-06-07T23:23:56.9662903Z          print(f"   Overall: {quality['overall_assessment']}")
2025-06-07T23:23:56.9662965Z -    
2025-06-07T23:23:56.9663029Z +
2025-06-07T23:23:56.9663103Z      # Overall summary
2025-06-07T23:23:56.9663187Z      if validatable_pdfs > 0:
2025-06-07T23:23:56.9663438Z -        overall_missing_pct = (total_missing_amount / total_pdf_amount * 100) if total_pdf_amount > 0 else 0
2025-06-07T23:23:56.9663694Z -        overall_accuracy = max(0, 1 - (total_missing_amount / total_pdf_amount)) if total_pdf_amount > 0 else 0
2025-06-07T23:23:56.9663778Z +        overall_missing_pct = (
2025-06-07T23:23:56.9663900Z +            (total_missing_amount / total_pdf_amount * 100)
2025-06-07T23:23:56.9663982Z +            if total_pdf_amount > 0
2025-06-07T23:23:56.9664052Z +            else 0
2025-06-07T23:23:56.9664116Z +        )
2025-06-07T23:23:56.9664192Z +        overall_accuracy = (
2025-06-07T23:23:56.9664320Z +            max(0, 1 - (total_missing_amount / total_pdf_amount))
2025-06-07T23:23:56.9664399Z +            if total_pdf_amount > 0
2025-06-07T23:23:56.9664470Z +            else 0
2025-06-07T23:23:56.9664531Z +        )
2025-06-07T23:23:56.9664597Z      else:
2025-06-07T23:23:56.9664681Z          overall_missing_pct = None
2025-06-07T23:23:56.9664768Z          overall_accuracy = None
2025-06-07T23:23:56.9664831Z -    
2025-06-07T23:23:56.9664891Z +
2025-06-07T23:23:56.9664968Z      summary = {
2025-06-07T23:23:56.9665089Z          "validation_timestamp": str(Path().absolute()),
2025-06-07T23:23:56.9665177Z          "total_pdfs": len(results),
2025-06-07T23:23:56.9665279Z          "validatable_pdfs": validatable_pdfs,
2025-06-07T23:23:56.9665398Z          "overall_financial_accuracy": overall_accuracy,
2025-06-07T23:23:56.9665636Z -        "overall_missing_percentage": float(overall_missing_pct) if overall_missing_pct else None,
2025-06-07T23:23:56.9665777Z +        "overall_missing_percentage": float(overall_missing_pct)
2025-06-07T23:23:56.9665858Z +        if overall_missing_pct
2025-06-07T23:23:56.9665929Z +        else None,
2025-06-07T23:23:56.9666048Z          "total_missing_amount": float(total_missing_amount),
2025-06-07T23:23:56.9666156Z          "total_pdf_amount": float(total_pdf_amount),
2025-06-07T23:23:56.9666244Z -        "individual_results": results
2025-06-07T23:23:56.9666330Z +        "individual_results": results,
2025-06-07T23:23:56.9666403Z      }
2025-06-07T23:23:56.9666464Z -    
2025-06-07T23:23:56.9666528Z +
2025-06-07T23:23:56.9666598Z      # Save results
2025-06-07T23:23:56.9666688Z      output_path = Path(args.output)
2025-06-07T23:23:56.9666911Z      output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9667006Z -    with open(output_path, 'w') as f:
2025-06-07T23:23:56.9667089Z +    with open(output_path, "w") as f:
2025-06-07T23:23:56.9667200Z          json.dump(summary, f, indent=2, default=str)
2025-06-07T23:23:56.9667261Z -    
2025-06-07T23:23:56.9667338Z -    print(f"\n" + "=" * 50)
2025-06-07T23:23:56.9667402Z +
2025-06-07T23:23:56.9667474Z +    print("\n" + "=" * 50)
2025-06-07T23:23:56.9667579Z      print("OVERALL REAL ACCURACY ASSESSMENT")
2025-06-07T23:23:56.9667650Z      print("=" * 50)
2025-06-07T23:23:56.9667755Z      print(f"PDFs processed: {len(results)}")
2025-06-07T23:23:56.9667885Z      print(f"Financially validatable: {validatable_pdfs}")
2025-06-07T23:23:56.9667952Z -    
2025-06-07T23:23:56.9668095Z +
2025-06-07T23:23:56.9668190Z      if overall_accuracy is not None:
2025-06-07T23:23:56.9668429Z          print(f"REAL FINANCIAL ACCURACY: {overall_accuracy:.1%}")
2025-06-07T23:23:56.9668648Z -        print(f"Missing amount: R$ {total_missing_amount:.2f} of R$ {total_pdf_amount:.2f}")
2025-06-07T23:23:56.9668723Z +        print(
2025-06-07T23:23:56.9668909Z +            f"Missing amount: R$ {total_missing_amount:.2f} of R$ {total_pdf_amount:.2f}"
2025-06-07T23:23:56.9668975Z +        )
2025-06-07T23:23:56.9669112Z          print(f"Missing percentage: {overall_missing_pct:.1f}%")
2025-06-07T23:23:56.9669179Z -        
2025-06-07T23:23:56.9669240Z +
2025-06-07T23:23:56.9669326Z          if overall_accuracy >= 0.99:
2025-06-07T23:23:56.9669481Z              print("ðŸŽ¯ STATUS: PRODUCTION READY")
2025-06-07T23:23:56.9669570Z          elif overall_accuracy >= 0.95:
2025-06-07T23:23:56.9669646Z @@ -215,10 +244,11 @@ def main():
2025-06-07T23:23:56.9669847Z              print("âŒ STATUS: POOR - Major improvements required")
2025-06-07T23:23:56.9669912Z      else:
2025-06-07T23:23:56.9670120Z          print("â“ STATUS: UNKNOWN - Cannot validate without PDF totals")
2025-06-07T23:23:56.9670186Z -    
2025-06-07T23:23:56.9670254Z +
2025-06-07T23:23:56.9670361Z      print(f"\nResults saved to: {output_path}")
2025-06-07T23:23:56.9670426Z -    
2025-06-07T23:23:56.9670490Z +
2025-06-07T23:23:56.9670554Z      return 0
2025-06-07T23:23:56.9670618Z  
2025-06-07T23:23:56.9670679Z +
2025-06-07T23:23:56.9670753Z  if __name__ == "__main__":
2025-06-07T23:23:56.9670829Z      sys.exit(main())
2025-06-07T23:23:56.9671069Z diff --git a/src/statement_refinery/pdf_to_csv.py b/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671153Z index d9bf442..2d587fc 100644
2025-06-07T23:23:56.9671251Z --- a/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671353Z +++ b/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671457Z @@ -54,10 +54,10 @@ RE_FX_LINE2: Final = re.compile(
2025-06-07T23:23:56.9671550Z  # Currency conversion rate lines
2025-06-07T23:23:56.9671652Z  RE_CURRENCY_CONVERSION: Final = re.compile(
2025-06-07T23:23:56.9672035Z      r"DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate1>\d+,\d{2})(?:\s+DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate2>\d+,\d{2}))?",
2025-06-07T23:23:56.9672107Z -    re.I
2025-06-07T23:23:56.9672174Z +    re.I,
2025-06-07T23:23:56.9672235Z  )
2025-06-07T23:23:56.9672296Z  
2025-06-07T23:23:56.9672423Z -# International transaction with city and amounts  
2025-06-07T23:23:56.9672537Z +# International transaction with city and amounts
2025-06-07T23:23:56.9672636Z  RE_INTL_TRANSACTION: Final = re.compile(
2025-06-07T23:23:56.9672890Z      r"^(?P<city>\w+)\s+(?P<orig_amt>\d{1,3}(?:\.\d{3})*,\d{2})\s+(?P<currency>[A-Z]{3})\s+(?P<brl_amt>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+(?P<desc>.+))?$"
2025-06-07T23:23:56.9672956Z  )
2025-06-07T23:23:56.9673074Z @@ -75,7 +75,7 @@ RE_TRANSACTION_CODE: Final = re.compile(
2025-06-07T23:23:56.9673154Z  # Fee information lines
2025-06-07T23:23:56.9673243Z  RE_FEE_INFO: Final = re.compile(
2025-06-07T23:23:56.9673477Z      r"^(?P<desc>(?:valor\s+)?(?:juros|multa|encargo|tarifa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$",
2025-06-07T23:23:56.9673540Z -    re.I
2025-06-07T23:23:56.9673732Z +    re.I,
2025-06-07T23:23:56.9673796Z  )
2025-06-07T23:23:56.9673855Z  
2025-06-07T23:23:56.9674027Z  # Learned generic transaction pattern (high-confidence catch-all)
2025-06-07T23:23:56.9674244Z @@ -391,14 +391,14 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9674311Z          }
2025-06-07T23:23:56.9674372Z  
2025-06-07T23:23:56.9674474Z      # ===== ENHANCED PATTERN MATCHING =====
2025-06-07T23:23:56.9674536Z -    
2025-06-07T23:23:56.9674600Z +
2025-06-07T23:23:56.9674695Z      # Currency conversion rate information
2025-06-07T23:23:56.9674805Z      m = RE_CURRENCY_CONVERSION.match(line_no_card)
2025-06-07T23:23:56.9674872Z      if m:
2025-06-07T23:23:56.9674998Z          # Extract conversion rates for future FX calculations
2025-06-07T23:23:56.9675218Z          # These are informational lines, not transactions
2025-06-07T23:23:56.9675337Z          return None  # Skip but log for FX rate tracking
2025-06-07T23:23:56.9675403Z -    
2025-06-07T23:23:56.9675468Z +
2025-06-07T23:23:56.9675568Z      # International transaction with city
2025-06-07T23:23:56.9675668Z      m = RE_INTL_TRANSACTION.match(line_no_card)
2025-06-07T23:23:56.9675735Z      if m:
2025-06-07T23:23:56.9675943Z @@ -407,7 +407,7 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9676033Z          currency = m.group("currency")
2025-06-07T23:23:56.9676134Z          brl_amt = parse_amount(m.group("brl_amt"))
2025-06-07T23:23:56.9676253Z          desc = m.group("desc") or f"{city} Transaction"
2025-06-07T23:23:56.9676317Z -        
2025-06-07T23:23:56.9676377Z +
2025-06-07T23:23:56.9676449Z          return {
2025-06-07T23:23:56.9676531Z              "card_last4": card_last4,
2025-06-07T23:23:56.9676689Z              "post_date": f"{year or date.today().year}-01-01",  # Default date
2025-06-07T23:23:56.9676897Z @@ -426,13 +426,13 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9676986Z              "currency_orig": currency,
2025-06-07T23:23:56.9677137Z              "amount_usd": orig_amt if currency == "USD" else Decimal("0.00"),
2025-06-07T23:23:56.9677217Z          }
2025-06-07T23:23:56.9677289Z -    
2025-06-07T23:23:56.9677360Z +
2025-06-07T23:23:56.9677442Z      # Payment summary lines
2025-06-07T23:23:56.9677543Z      m = RE_PAYMENT_SUMMARY.match(line_no_card)
2025-06-07T23:23:56.9677610Z      if m:
2025-06-07T23:23:56.9677718Z          desc = f"{m.group('type')} {m.group('desc')}"
2025-06-07T23:23:56.9677822Z          amount = parse_amount(m.group("amount"))
2025-06-07T23:23:56.9677886Z -        
2025-06-07T23:23:56.9677948Z +
2025-06-07T23:23:56.9678012Z          return {
2025-06-07T23:23:56.9678095Z              "card_last4": card_last4,
2025-06-07T23:23:56.9678246Z              "post_date": f"{year or date.today().year}-12-31",  # End of period
2025-06-07T23:23:56.9678552Z @@ -451,13 +451,13 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9678637Z              "currency_orig": "",
2025-06-07T23:23:56.9678727Z              "amount_usd": Decimal("0.00"),
2025-06-07T23:23:56.9678789Z          }
2025-06-07T23:23:56.9678851Z -    
2025-06-07T23:23:56.9678915Z +
2025-06-07T23:23:56.9678993Z      # Fee information lines
2025-06-07T23:23:56.9679084Z      m = RE_FEE_INFO.match(line_no_card)
2025-06-07T23:23:56.9679147Z      if m:
2025-06-07T23:23:56.9679227Z          desc = m.group("desc")
2025-06-07T23:23:56.9679324Z          amount = parse_amount(m.group("amount"))
2025-06-07T23:23:56.9679391Z -        
2025-06-07T23:23:56.9679450Z +
2025-06-07T23:23:56.9679515Z          return {
2025-06-07T23:23:56.9679597Z              "card_last4": card_last4,
2025-06-07T23:23:56.9679743Z              "post_date": f"{year or date.today().year}-12-31",  # End of period
2025-06-07T23:23:56.9679906Z diff --git a/tests/test_pdf_to_csv.py b/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9679986Z index f863dc4..06d169d 100644
2025-06-07T23:23:56.9680190Z --- a/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9680273Z +++ b/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9680376Z @@ -7,4 +7,4 @@ def test_parse_lines_simple():
2025-06-07T23:23:56.9680465Z      lines = ["01/01 STORE final 1234 9,99"]
2025-06-07T23:23:56.9680552Z      rows = parse_lines(iter(lines))
2025-06-07T23:23:56.9680663Z      assert rows[0]["amount_brl"] == Decimal("9.99")
2025-06-07T23:23:56.9680757Z -    assert rows[0]["card_last4"] == "1234"
2025-06-07T23:23:56.9680841Z \ No newline at end of file
2025-06-07T23:23:56.9680929Z +    assert rows[0]["card_last4"] == "1234"
2025-06-07T23:23:56.9681127Z diff --git a/tests/test_pre_commit_config.py b/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681208Z index 0dcbd2d..943ba36 100644
2025-06-07T23:23:56.9681399Z --- a/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681489Z +++ b/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681584Z @@ -4,10 +4,12 @@ from pathlib import Path
2025-06-07T23:23:56.9681648Z  
2025-06-07T23:23:56.9681774Z  CONFIG_PATH = Path(".pre-commit-config.yaml")
2025-06-07T23:23:56.9681835Z  
2025-06-07T23:23:56.9681901Z +
2025-06-07T23:23:56.9681972Z  def load_config():
2025-06-07T23:23:56.9682094Z      with CONFIG_PATH.open("r", encoding="utf-8") as f:
2025-06-07T23:23:56.9682180Z          return yaml.safe_load(f)
2025-06-07T23:23:56.9682244Z  
2025-06-07T23:23:56.9682306Z +
2025-06-07T23:23:56.9682391Z  def test_pre_commit_config_valid():
2025-06-07T23:23:56.9682547Z      """Test that the .pre-commit-config.yaml file is valid YAML."""
2025-06-07T23:23:56.9682616Z      try:
2025-06-07T23:23:56.9682730Z @@ -16,20 +18,25 @@ def test_pre_commit_config_valid():
2025-06-07T23:23:56.9682812Z      except Exception as e:
2025-06-07T23:23:56.9682918Z          pytest.fail(f"YAML syntax error: {e}")
2025-06-07T23:23:56.9682983Z  
2025-06-07T23:23:56.9683044Z +
2025-06-07T23:23:56.9683133Z  def test_repos_key_exists():
2025-06-07T23:23:56.9683211Z      config = load_config()
2025-06-07T23:23:56.9683380Z      assert "repos" in config, "Missing 'repos' key in pre-commit config"
2025-06-07T23:23:56.9683549Z      assert isinstance(config["repos"], list), "'repos' should be a list"
2025-06-07T23:23:56.9683615Z  
2025-06-07T23:23:56.9683676Z +
2025-06-07T23:23:56.9683776Z  def test_each_repo_has_required_fields():
2025-06-07T23:23:56.9683851Z      config = load_config()
2025-06-07T23:23:56.9683951Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9684164Z -        assert "repo" in repo or repo.get("repo", None) == "local", f"Repo #{i} missing 'repo' key"
2025-06-07T23:23:56.9684311Z +        assert "repo" in repo or repo.get("repo", None) == "local", (
2025-06-07T23:23:56.9684405Z +            f"Repo #{i} missing 'repo' key"
2025-06-07T23:23:56.9684470Z +        )
2025-06-07T23:23:56.9684569Z          if repo.get("repo", None) != "local":
2025-06-07T23:23:56.9684695Z              assert "rev" in repo, f"Repo #{i} missing 'rev' key"
2025-06-07T23:23:56.9684832Z          assert "hooks" in repo, f"Repo #{i} missing 'hooks' key"
2025-06-07T23:23:56.9685027Z          assert isinstance(repo["hooks"], list), f"Repo #{i} 'hooks' should be a list"
2025-06-07T23:23:56.9685092Z  
2025-06-07T23:23:56.9685153Z +
2025-06-07T23:23:56.9685255Z  def test_each_hook_has_required_fields():
2025-06-07T23:23:56.9685332Z      config = load_config()
2025-06-07T23:23:56.9685434Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9685556Z @@ -38,15 +45,17 @@ def test_each_hook_has_required_fields():
2025-06-07T23:23:56.9685693Z              assert "name" in hook, f"Repo #{i} Hook #{j} missing 'name'"
2025-06-07T23:23:56.9685881Z              assert "description" in hook, f"Repo #{i} Hook #{j} missing 'description'"
2025-06-07T23:23:56.9685946Z  
2025-06-07T23:23:56.9686011Z +
2025-06-07T23:23:56.9686120Z  def test_no_duplicate_hook_ids_within_repo():
2025-06-07T23:23:56.9686200Z      config = load_config()
2025-06-07T23:23:56.9686298Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9686431Z          ids = [hook["id"] for hook in repo["hooks"] if "id" in hook]
2025-06-07T23:23:56.9686687Z          assert len(ids) == len(set(ids)), f"Duplicate hook ids in repo #{i}: {ids}"
2025-06-07T23:23:56.9686754Z  
2025-06-07T23:23:56.9686814Z +
2025-06-07T23:23:56.9686910Z  def test_local_repo_hooks_have_entry():
2025-06-07T23:23:56.9686987Z      config = load_config()
2025-06-07T23:23:56.9687082Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9687175Z          if repo.get("repo", None) == "local":
2025-06-07T23:23:56.9687278Z              for j, hook in enumerate(repo["hooks"]):
2025-06-07T23:23:56.9687435Z -                assert "entry" in hook, f"Local repo hook #{j} missing 'entry'"
2025-06-07T23:23:56.9687515Z \ No newline at end of file
2025-06-07T23:23:56.9687733Z +                assert "entry" in hook, f"Local repo hook #{j} missing 'entry'"
2025-06-07T23:23:56.9704959Z ##[warning]lint failed (ignored)
2025-06-07T23:23:56.9742721Z ##[group]Run ruff check --fix . | tee diagnostics/lint.txt
2025-06-07T23:23:56.9742905Z [36;1mruff check --fix . | tee diagnostics/lint.txt[0m
2025-06-07T23:23:56.9743032Z [36;1mblack --check . | tee -a diagnostics/lint.txt[0m
2025-06-07T23:23:56.9793815Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:56.9793890Z env:
2025-06-07T23:23:56.9793973Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:56.9794049Z   MAX_TOKENS: 5000000
2025-06-07T23:23:56.9794118Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:56.9794192Z   FORCE_EVOLVE: 0
2025-06-07T23:23:56.9794345Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794534Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:56.9794684Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794821Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794954Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9795122Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:56.9795197Z ##[endgroup]
2025-06-07T23:23:56.9974688Z scripts/comprehensive_analysis.py:21:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9974862Z    |
2025-06-07T23:23:56.9975039Z 19 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9975156Z 20 |
2025-06-07T23:23:56.9975345Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9975498Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9975802Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9975917Z    |
2025-06-07T23:23:56.9975925Z 
2025-06-07T23:23:56.9976310Z scripts/comprehensive_analysis.py:22:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9976426Z    |
2025-06-07T23:23:56.9976603Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9976905Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9977094Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9977226Z 23 |
2025-06-07T23:23:56.9977403Z 24 | logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:56.9977514Z    |
2025-06-07T23:23:56.9977522Z 
2025-06-07T23:23:56.9977887Z scripts/generate_golden_csvs.py:15:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9978000Z    |
2025-06-07T23:23:56.9978168Z 13 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9978466Z 14 |
2025-06-07T23:23:56.9978667Z 15 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9978811Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9978925Z    |
2025-06-07T23:23:56.9978932Z 
2025-06-07T23:23:56.9979345Z scripts/pattern_enhancer.py:35:13: F841 Local variable `count` is assigned to but never used
2025-06-07T23:23:56.9979458Z    |
2025-06-07T23:23:56.9979619Z 33 |         for pattern in discovered:
2025-06-07T23:23:56.9979802Z 34 |             structure = pattern["structure"]
2025-06-07T23:23:56.9979953Z 35 |             count = pattern["count"]
2025-06-07T23:23:56.9980299Z    |             ^^^^^ F841
2025-06-07T23:23:56.9980462Z 36 |             examples = pattern["examples"]
2025-06-07T23:23:56.9980562Z    |
2025-06-07T23:23:56.9980772Z    = help: Remove assignment to unused variable `count`
2025-06-07T23:23:56.9980779Z 
2025-06-07T23:23:56.9981142Z scripts/semantic_validator.py:19:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9981260Z    |
2025-06-07T23:23:56.9981428Z 17 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9981540Z 18 |
2025-06-07T23:23:56.9981731Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9981881Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9982176Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9982293Z    |
2025-06-07T23:23:56.9982301Z 
2025-06-07T23:23:56.9982850Z scripts/semantic_validator.py:20:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9982973Z    |
2025-06-07T23:23:56.9983154Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9983453Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9983624Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9983734Z    |
2025-06-07T23:23:56.9983741Z 
2025-06-07T23:23:56.9984035Z scripts/semantic_validator.py:76:9: E722 Do not use bare `except`
2025-06-07T23:23:56.9984143Z    |
2025-06-07T23:23:56.9984261Z 74 |         try:
2025-06-07T23:23:56.9984448Z 75 |             pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9984565Z 76 |         except:
2025-06-07T23:23:56.9984678Z    |         ^^^^^^ E722
2025-06-07T23:23:56.9984795Z 77 |             pass
2025-06-07T23:23:56.9984892Z    |
2025-06-07T23:23:56.9984899Z 
2025-06-07T23:23:56.9985227Z scripts/validate_real_accuracy.py:17:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9985330Z    |
2025-06-07T23:23:56.9985478Z 15 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9985589Z 16 |
2025-06-07T23:23:56.9985750Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9985886Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9986147Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9986254Z    |
2025-06-07T23:23:56.9986262Z 
2025-06-07T23:23:56.9986615Z scripts/validate_real_accuracy.py:18:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9986730Z    |
2025-06-07T23:23:56.9986903Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9987190Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9987346Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9987459Z    |
2025-06-07T23:23:56.9987465Z 
2025-06-07T23:23:56.9987583Z Found 9 errors.
2025-06-07T23:23:56.9987931Z No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
2025-06-07T23:23:57.5018010Z would reformat /home/runner/work/Evolve/Evolve/scripts/pattern_enhancer.py
2025-06-07T23:23:57.5433499Z would reformat /home/runner/work/Evolve/Evolve/scripts/validate_real_accuracy.py
2025-06-07T23:23:57.6335921Z would reformat /home/runner/work/Evolve/Evolve/scripts/incremental_learner.py
2025-06-07T23:23:57.7045132Z would reformat /home/runner/work/Evolve/Evolve/tests/test_pre_commit_config.py
2025-06-07T23:23:57.7620889Z would reformat /home/runner/work/Evolve/Evolve/scripts/semantic_validator.py
2025-06-07T23:23:57.7690468Z 
2025-06-07T23:23:57.7690950Z Oh no! ðŸ’¥ ðŸ’” ðŸ’¥
2025-06-07T23:23:57.7691432Z 5 files would be reformatted, 19 files would be left unchanged.
2025-06-07T23:23:57.7944629Z ##[group]Run PYTHONPATH=src mypy --explicit-package-bases src/statement_refinery | tee diagnostics/mypy.txt
2025-06-07T23:23:57.7945360Z [36;1mPYTHONPATH=src mypy --explicit-package-bases src/statement_refinery | tee diagnostics/mypy.txt[0m
2025-06-07T23:23:57.7997218Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:57.7997894Z env:
2025-06-07T23:23:57.7998186Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:57.7998723Z   MAX_TOKENS: 5000000
2025-06-07T23:23:57.7999022Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:57.7999307Z   FORCE_EVOLVE: 0
2025-06-07T23:23:57.7999758Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8000395Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:57.8000996Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8001528Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8002082Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8002710Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:57.8003133Z ##[endgroup]
2025-06-07T23:24:03.4679730Z src/statement_refinery/pdf_to_csv.py:440: error: Unsupported operand type for unary - ("Decimal | None")  [operator]
2025-06-07T23:24:03.4711760Z Found 1 error in 1 file (checked 3 source files)
2025-06-07T23:24:03.4847628Z ##[group]Run pytest -v --cov=statement_refinery \
2025-06-07T23:24:03.4848255Z [36;1mpytest -v --cov=statement_refinery \[0m
2025-06-07T23:24:03.4848927Z [36;1m       --cov-report=xml \[0m
2025-06-07T23:24:03.4849378Z [36;1m       --cov-report=term-missing \[0m
2025-06-07T23:24:03.4849917Z [36;1m       --cov-fail-under=90 | tee diagnostics/test.txt[0m
2025-06-07T23:24:03.4913963Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:03.4914205Z env:
2025-06-07T23:24:03.4914380Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:03.4914594Z   MAX_TOKENS: 5000000
2025-06-07T23:24:03.4914793Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:03.4914980Z   FORCE_EVOLVE: 0
2025-06-07T23:24:03.4915240Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4915654Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:03.4916057Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4916449Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4916817Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4917172Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:03.4917469Z ##[endgroup]
2025-06-07T23:24:03.9910040Z ============================= test session starts ==============================
2025-06-07T23:24:03.9911050Z platform linux -- Python 3.12.10, pytest-8.4.0, pluggy-1.6.0 -- /opt/hostedtoolcache/Python/3.12.10/x64/bin/python
2025-06-07T23:24:03.9911848Z cachedir: .pytest_cache
2025-06-07T23:24:03.9912247Z rootdir: /home/runner/work/Evolve/Evolve
2025-06-07T23:24:03.9912708Z configfile: pyproject.toml
2025-06-07T23:24:03.9913128Z plugins: xdist-3.7.0, anyio-4.9.0, cov-6.1.1
2025-06-07T23:24:04.3404855Z collecting ... collected 41 items
2025-06-07T23:24:04.3405183Z 
2025-06-07T23:24:04.3453611Z tests/test_accuracy_script.py::test_check_accuracy_main_fails_on_mismatch[True] SKIPPED [  2%]
2025-06-07T23:24:04.3474752Z tests/test_accuracy_script.py::test_check_accuracy_main_fails_on_mismatch[False] SKIPPED [  4%]
2025-06-07T23:24:04.3496395Z tests/test_accuracy_script.py::test_check_accuracy_fails_on_total_delta SKIPPED [  7%]
2025-06-07T23:24:04.3509842Z tests/test_ci_summary_constants.py::test_constants_present PASSED        [  9%]
2025-06-07T23:24:04.3529138Z tests/test_parse_line.py::test_domestic_transaction PASSED               [ 12%]
2025-06-07T23:24:04.3541890Z tests/test_parse_line.py::test_fx_transaction PASSED                     [ 14%]
2025-06-07T23:24:04.3557151Z tests/test_parse_line.py::test_payment_line PASSED                       [ 17%]
2025-06-07T23:24:04.3568993Z tests/test_parse_line.py::test_adjustment_line PASSED                    [ 19%]
2025-06-07T23:24:04.3581727Z tests/test_parse_line.py::test_complex_merchant_parsed PASSED            [ 21%]
2025-06-07T23:24:04.3592801Z tests/test_parse_line.py::test_invalid_month_skipped PASSED              [ 24%]
2025-06-07T23:24:04.3604035Z tests/test_parse_line.py::test_invalid_day_skipped PASSED                [ 26%]
2025-06-07T23:24:04.3617243Z tests/test_parse_line.py::test_invalid_month_overflow_skipped PASSED     [ 29%]
2025-06-07T23:24:04.3628793Z tests/test_parse_line.py::test_invalid_day_zero_skipped PASSED           [ 31%]
2025-06-07T23:24:04.3639762Z tests/test_parse_line.py::test_header_fragment_skipped PASSED            [ 34%]
2025-06-07T23:24:04.3650932Z tests/test_parse_line.py::test_keyword_line_skipped PASSED               [ 36%]
2025-06-07T23:24:04.3662073Z tests/test_parse_line.py::test_parse_amount_brazilian_format PASSED      [ 39%]
2025-06-07T23:24:04.3673098Z tests/test_parse_line.py::test_parse_amount_negative_european PASSED     [ 41%]
2025-06-07T23:24:04.3684053Z tests/test_parse_line.py::test_parse_amount_trailing_minus PASSED        [ 43%]
2025-06-07T23:24:04.3694934Z tests/test_parse_line.py::test_parse_amount_parentheses PASSED           [ 46%]
2025-06-07T23:24:04.3705967Z tests/test_parse_line.py::test_classify_transaction_high_priority PASSED [ 48%]
2025-06-07T23:24:04.3717792Z tests/test_parse_line.py::test_classify_transaction_fx_keyword PASSED    [ 51%]
2025-06-07T23:24:04.3728976Z tests/test_parse_line.py::test_parse_fx_currency_line_with_city PASSED   [ 53%]
2025-06-07T23:24:04.3739993Z tests/test_parse_line.py::test_parse_fx_currency_line_none PASSED        [ 56%]
2025-06-07T23:24:04.3754925Z tests/test_parse_line.py::test_iso_date_invalid PASSED                   [ 58%]
2025-06-07T23:24:04.3770978Z tests/test_pdf_to_csv.py::test_parse_lines_simple PASSED                 [ 60%]
2025-06-07T23:24:04.3845708Z tests/test_pre_commit_config.py::test_pre_commit_config_valid PASSED     [ 63%]
2025-06-07T23:24:04.3915652Z tests/test_pre_commit_config.py::test_repos_key_exists PASSED            [ 65%]
2025-06-07T23:24:04.3985027Z tests/test_pre_commit_config.py::test_each_repo_has_required_fields PASSED [ 68%]
2025-06-07T23:24:04.4054650Z tests/test_pre_commit_config.py::test_each_hook_has_required_fields PASSED [ 70%]
2025-06-07T23:24:04.4129730Z tests/test_pre_commit_config.py::test_no_duplicate_hook_ids_within_repo PASSED [ 73%]
2025-06-07T23:24:04.4200652Z tests/test_pre_commit_config.py::test_local_repo_hooks_have_entry PASSED [ 75%]
2025-06-07T23:24:04.4212294Z tests/test_utils.py::test_parse_amount_various_formats PASSED            [ 78%]
2025-06-07T23:24:04.4230555Z tests/test_utils.py::test_parse_lines_deduplicates_and_updates_card PASSED [ 80%]
2025-06-07T23:24:04.4262626Z tests/test_validation_helpers.py::test_extract_total_from_pdf PASSED     [ 82%]
2025-06-07T23:24:04.4273713Z tests/test_validation_helpers.py::test_calculate_csv_total PASSED        [ 85%]
2025-06-07T23:24:04.4284836Z tests/test_validation_helpers.py::test_find_duplicates PASSED            [ 87%]
2025-06-07T23:24:04.4296026Z tests/test_validation_helpers.py::test_validate_categories PASSED        [ 90%]
2025-06-07T23:24:04.4309093Z tests/test_validation_helpers.py::test_analyze_rows PASSED               [ 92%]
2025-06-07T23:24:05.8900077Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_pdfplumber PASSED [ 95%]
2025-06-07T23:24:05.8985540Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_no_total PASSED [ 97%]
2025-06-07T23:24:06.0075632Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_pdfplumber_missing PASSED [100%]
2025-06-07T23:24:06.0076599Z ERROR: Coverage failure: total of 66 is less than fail-under=90
2025-06-07T23:24:06.0077040Z 
2025-06-07T23:24:06.0077048Z 
2025-06-07T23:24:06.0077264Z ================================ tests coverage ================================
2025-06-07T23:24:06.0077937Z _______________ coverage: platform linux, python 3.12.10-final-0 _______________
2025-06-07T23:24:06.0078704Z 
2025-06-07T23:24:06.0078919Z Name                                   Stmts   Miss  Cover   Missing
2025-06-07T23:24:06.0079542Z --------------------------------------------------------------------
2025-06-07T23:24:06.0080172Z src/statement_refinery/__init__.py         3      0   100%
2025-06-07T23:24:06.0081218Z src/statement_refinery/pdf_to_csv.py     306    123    60%   142-143, 178-180, 251-252, 300, 325, 333, 336-337, 359, 372-373, 396-495, 580-596, 622-623, 632-637, 649, 667-702, 706-721, 726-771
2025-06-07T23:24:06.0082450Z src/statement_refinery/validation.py      54      0   100%
2025-06-07T23:24:06.0082986Z --------------------------------------------------------------------
2025-06-07T23:24:06.0083485Z TOTAL                                    363    123    66%
2025-06-07T23:24:06.0083948Z Coverage XML written to file coverage.xml
2025-06-07T23:24:06.0084497Z FAIL Required test coverage of 90% not reached. Total coverage: 66.12%
2025-06-07T23:24:06.0085111Z ======================== 38 passed, 3 skipped in 1.99s =========================
2025-06-07T23:24:06.0571093Z ##[group]Run python scripts/check_accuracy.py --threshold 99 \
2025-06-07T23:24:06.0571910Z [36;1mpython scripts/check_accuracy.py --threshold 99 \[0m
2025-06-07T23:24:06.0572549Z [36;1m       --summary-file diagnostics/accuracy.json \[0m
2025-06-07T23:24:06.0573173Z [36;1m       --csv-dir csv_output | tee diagnostics/accuracy.txt[0m
2025-06-07T23:24:06.0631654Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:06.0631896Z env:
2025-06-07T23:24:06.0632068Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:06.0632283Z   MAX_TOKENS: 5000000
2025-06-07T23:24:06.0632478Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:06.0632661Z   FORCE_EVOLVE: 0
2025-06-07T23:24:06.0632927Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0633344Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:06.0633762Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634119Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634505Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634862Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:06.0635161Z ##[endgroup]
2025-06-07T23:24:06.1259626Z INFO: CSV written â†’ csv_output/Itau_2024-05.csv
2025-06-07T23:24:06.1914607Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1930986Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1947487Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1957134Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5516964Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5517823Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5518815Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5519585Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5537544Z INFO: CSV written â†’ csv_output/Itau_2024-06.csv
2025-06-07T23:24:06.5555795Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5571415Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5583681Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5592522Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5601907Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5611852Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9961628Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9962393Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9963009Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9963618Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9964182Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9964629Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9974988Z INFO: CSV written â†’ csv_output/Itau_2024-07.csv
2025-06-07T23:24:06.9994322Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0008749Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0021240Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0032329Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0042026Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0051285Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4567227Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4567975Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4569072Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4570217Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4570892Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4571524Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4580606Z INFO: CSV written â†’ csv_output/Itau_2024-08.csv
2025-06-07T23:24:07.4600377Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4615316Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4633192Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4651496Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4664161Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4673427Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4683002Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4692184Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2071309Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2072071Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2072771Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2073453Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2074150Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2074788Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2075360Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2075952Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2086340Z INFO: CSV written â†’ csv_output/Itau_2024-09.csv
2025-06-07T23:24:08.2103311Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2117482Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2128166Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2137436Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2147209Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2160611Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6276654Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6277409Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6278109Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6279019Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6279640Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6280234Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6290336Z INFO: CSV written â†’ csv_output/Itau_2024-10.csv
2025-06-07T23:24:08.6307178Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6321497Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6333248Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6342671Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6352324Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6363504Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1272287Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1273049Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1273738Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1274409Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1276828Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1277631Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1288843Z INFO: CSV written â†’ csv_output/Itau_2024-11.csv
2025-06-07T23:24:09.1306488Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1320045Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1340683Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1352353Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1361406Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1370194Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7760735Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7761597Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7762379Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7763148Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7763921Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7764726Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7774327Z INFO: CSV written â†’ csv_output/Itau_2024-12.csv
2025-06-07T23:24:09.7792691Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7806589Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7825474Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7835753Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7845153Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7853928Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4376837Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4377691Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4378735Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4379496Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4380288Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4381038Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4390428Z INFO: CSV written â†’ csv_output/Itau_2025-01.csv
2025-06-07T23:24:10.4408426Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4423197Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4442028Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4454794Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4464198Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4473415Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1151095Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1151963Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1152777Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1153548Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1154312Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1155070Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1164383Z INFO: CSV written â†’ csv_output/Itau_2025-02.csv
2025-06-07T23:24:11.1182604Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1196739Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1216129Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1229134Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1238421Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1247253Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8466108Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8467375Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8468109Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8468989Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8469572Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8470235Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8480176Z INFO: CSV written â†’ csv_output/Itau_2025-03.csv
2025-06-07T23:24:11.8498454Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8512914Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8531487Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8542480Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8552304Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8561805Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5245652Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5246301Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5246807Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5247253Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5247798Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5248213Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5259202Z INFO: CSV written â†’ csv_output/Itau_2025-04.csv
2025-06-07T23:24:12.5278009Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5292186Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5311676Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5325259Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5334948Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5344311Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2514025Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2514792Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2515525Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2516202Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2516807Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2517369Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2528988Z INFO: CSV written â†’ csv_output/Itau_2025-05.csv
2025-06-07T23:24:13.2564088Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2566171Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2568675Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2570837Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2572990Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2575148Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2577155Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2579472Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1934348Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1935116Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1935816Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1936488Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1937159Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1937836Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1939040Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1939673Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1962383Z INFO: CSV written â†’ csv_output/itau_2025-06.csv
2025-06-07T23:24:15.6573767Z mismatched parser output or low accuracy
2025-06-07T23:24:15.6574299Z 
2025-06-07T23:24:15.6574553Z Processing 1/14: Itau_2024-05.pdf
2025-06-07T23:24:15.6574930Z 
2025-06-07T23:24:15.6575091Z === Itau_2024-05.pdf ===
2025-06-07T23:24:15.6575553Z Output matches golden file exactly.
2025-06-07T23:24:15.6576062Z Match percentage: 100.00%
2025-06-07T23:24:15.6576657Z Could not verify total: Could not find total in Itau_2024-05.pdf
2025-06-07T23:24:15.6577161Z 
2025-06-07T23:24:15.6577349Z Processing 2/14: Itau_2024-06.pdf
2025-06-07T23:24:15.6577667Z 
2025-06-07T23:24:15.6577831Z === Itau_2024-06.pdf ===
2025-06-07T23:24:15.6578251Z Output matches golden file exactly.
2025-06-07T23:24:15.6578882Z Match percentage: 100.00%
2025-06-07T23:24:15.6579178Z Total mismatch: CSV 0 vs PDF 5731.86
2025-06-07T23:24:15.6579423Z 
2025-06-07T23:24:15.6579536Z Processing 3/14: Itau_2024-07.pdf
2025-06-07T23:24:15.6579771Z 
2025-06-07T23:24:15.6579871Z === Itau_2024-07.pdf ===
2025-06-07T23:24:15.6580162Z Output matches golden file exactly.
2025-06-07T23:24:15.6580423Z Match percentage: 100.00%
2025-06-07T23:24:15.6580653Z Total mismatch: CSV 0 vs PDF 22524.22
2025-06-07T23:24:15.6580830Z 
2025-06-07T23:24:15.6580922Z Processing 4/14: Itau_2024-08.pdf
2025-06-07T23:24:15.6581087Z 
2025-06-07T23:24:15.6581168Z === Itau_2024-08.pdf ===
2025-06-07T23:24:15.6581401Z Output matches golden file exactly.
2025-06-07T23:24:15.6581657Z Match percentage: 100.00%
2025-06-07T23:24:15.6581889Z Total mismatch: CSV 0 vs PDF 59574.97
2025-06-07T23:24:15.6582064Z 
2025-06-07T23:24:15.6582152Z Processing 5/14: Itau_2024-09.pdf
2025-06-07T23:24:15.6582312Z 
2025-06-07T23:24:15.6582396Z === Itau_2024-09.pdf ===
2025-06-07T23:24:15.6582621Z Output matches golden file exactly.
2025-06-07T23:24:15.6582873Z Match percentage: 100.00%
2025-06-07T23:24:15.6583108Z Total mismatch: CSV 0 vs PDF 71543.24
2025-06-07T23:24:15.6583282Z 
2025-06-07T23:24:15.6583373Z Processing 6/14: Itau_2024-10.pdf
2025-06-07T23:24:15.6583537Z 
2025-06-07T23:24:15.6583614Z === Itau_2024-10.pdf ===
2025-06-07T23:24:15.6583834Z Output matches golden file exactly.
2025-06-07T23:24:15.6584088Z Match percentage: 100.00%
2025-06-07T23:24:15.6584325Z Total mismatch: CSV 4772.90 vs PDF 8595.02
2025-06-07T23:24:15.6584516Z 
2025-06-07T23:24:15.6584601Z Processing 7/14: Itau_2024-11.pdf
2025-06-07T23:24:15.6584759Z 
2025-06-07T23:24:15.6584840Z === Itau_2024-11.pdf ===
2025-06-07T23:24:15.6585059Z Output matches golden file exactly.
2025-06-07T23:24:15.6585310Z Match percentage: 100.00%
2025-06-07T23:24:15.6585536Z Total mismatch: CSV 0 vs PDF 13787.89
2025-06-07T23:24:15.6585705Z 
2025-06-07T23:24:15.6585794Z Processing 8/14: Itau_2024-12.pdf
2025-06-07T23:24:15.6585956Z 
2025-06-07T23:24:15.6586033Z === Itau_2024-12.pdf ===
2025-06-07T23:24:15.6586252Z Output matches golden file exactly.
2025-06-07T23:24:15.6586505Z Match percentage: 100.00%
2025-06-07T23:24:15.6586733Z Total mismatch: CSV 0 vs PDF 14121.52
2025-06-07T23:24:15.6586901Z 
2025-06-07T23:24:15.6586994Z Processing 9/14: Itau_2025-01.pdf
2025-06-07T23:24:15.6587152Z 
2025-06-07T23:24:15.6587234Z === Itau_2025-01.pdf ===
2025-06-07T23:24:15.6587669Z Output matches golden file exactly.
2025-06-07T23:24:15.6587916Z Match percentage: 100.00%
2025-06-07T23:24:15.6588138Z Total mismatch: CSV 0 vs PDF 9695.65
2025-06-07T23:24:15.6588426Z 
2025-06-07T23:24:15.6588547Z Processing 10/14: Itau_2025-02.pdf
2025-06-07T23:24:15.6588805Z 
2025-06-07T23:24:15.6588883Z === Itau_2025-02.pdf ===
2025-06-07T23:24:15.6589108Z Output matches golden file exactly.
2025-06-07T23:24:15.6589362Z Match percentage: 100.00%
2025-06-07T23:24:15.6589588Z Total mismatch: CSV 0 vs PDF 11368.22
2025-06-07T23:24:15.6589756Z 
2025-06-07T23:24:15.6589850Z Processing 11/14: Itau_2025-03.pdf
2025-06-07T23:24:15.6590019Z 
2025-06-07T23:24:15.6590283Z === Itau_2025-03.pdf ===
2025-06-07T23:24:15.6590513Z Output matches golden file exactly.
2025-06-07T23:24:15.6590764Z Match percentage: 100.00%
2025-06-07T23:24:15.6590987Z Total mismatch: CSV 0 vs PDF 7704.47
2025-06-07T23:24:15.6591161Z 
2025-06-07T23:24:15.6591248Z Processing 12/14: Itau_2025-04.pdf
2025-06-07T23:24:15.6591415Z 
2025-06-07T23:24:15.6591495Z === Itau_2025-04.pdf ===
2025-06-07T23:24:15.6591709Z Output matches golden file exactly.
2025-06-07T23:24:15.6591943Z Match percentage: 100.00%
2025-06-07T23:24:15.6592155Z Total mismatch: CSV 0 vs PDF 9232.62
2025-06-07T23:24:15.6592312Z 
2025-06-07T23:24:15.6592402Z Processing 13/14: Itau_2025-05.pdf
2025-06-07T23:24:15.6592549Z 
2025-06-07T23:24:15.6592627Z === Itau_2025-05.pdf ===
2025-06-07T23:24:15.6592837Z Output matches golden file exactly.
2025-06-07T23:24:15.6593072Z Match percentage: 100.00%
2025-06-07T23:24:15.6593201Z 
2025-06-07T23:24:15.6593280Z Processing 14/14: itau_2025-06.pdf
2025-06-07T23:24:15.6593432Z 
2025-06-07T23:24:15.6593511Z === itau_2025-06.pdf ===
2025-06-07T23:24:15.6593712Z Output matches golden file exactly.
2025-06-07T23:24:15.6593940Z Match percentage: 100.00%
2025-06-07T23:24:15.6594216Z Could not verify total: Could not find total in itau_2025-06.pdf
2025-06-07T23:24:15.6594535Z Average match across PDFs: 100.00%
2025-06-07T23:24:15.6594822Z TOTAL mismatch across PDFs: CSV 25633.50 vs PDF 254740.28
2025-06-07T23:24:15.7319188Z ##[group]Run codecov/codecov-action@v4
2025-06-07T23:24:15.7319474Z with:
2025-06-07T23:24:15.7319655Z   file: coverage.xml
2025-06-07T23:24:15.7319859Z   fail_ci_if_error: true
2025-06-07T23:24:15.7320064Z env:
2025-06-07T23:24:15.7320229Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:15.7320428Z   MAX_TOKENS: 5000000
2025-06-07T23:24:15.7320612Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:15.7320787Z   FORCE_EVOLVE: 0
2025-06-07T23:24:15.7321038Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7321462Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:15.7321857Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322228Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322586Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322949Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:15.7323624Z   CODECOV_TOKEN: ***
2025-06-07T23:24:15.7323953Z ##[endgroup]
2025-06-07T23:24:15.8139508Z eventName: push
2025-06-07T23:24:15.8147960Z ==> linux OS detected
2025-06-07T23:24:16.0047157Z https://cli.codecov.io/latest/linux/codecov.SHA256SUM
2025-06-07T23:24:16.0953856Z gpg: directory '/home/runner/.gnupg' created
2025-06-07T23:24:16.0957748Z gpg: keybox '/home/runner/.gnupg/pubring.kbx' created
2025-06-07T23:24:16.0989902Z gpg: /home/runner/.gnupg/trustdb.gpg: trustdb created
2025-06-07T23:24:16.0991132Z gpg: key 806BB28AED779869: public key "Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>" imported
2025-06-07T23:24:16.1121637Z gpg: Total number processed: 1
2025-06-07T23:24:16.1129350Z gpg:               imported: 1
2025-06-07T23:24:16.1192513Z gpg: Signature made Thu May 29 21:23:31 2025 UTC
2025-06-07T23:24:16.1200386Z gpg:                using RSA key 27034E7FDB850E0BBC2C62FF806BB28AED779869
2025-06-07T23:24:16.1201535Z gpg: Good signature from "Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>" [unknown]
2025-06-07T23:24:16.1202808Z gpg: WARNING: This key is not certified with a trusted signature!
2025-06-07T23:24:16.1203547Z gpg:          There is no indication that the signature belongs to the owner.
2025-06-07T23:24:16.1204345Z Primary key fingerprint: 2703 4E7F DB85 0E0B BC2C  62FF 806B B28A ED77 9869
2025-06-07T23:24:16.1439713Z ==> Uploader SHASUM verified (8e0a7ea74f31ee893d11051143fa223cc30f110287ad275e275ca493ddd78eaa  codecov)
2025-06-07T23:24:16.1441028Z ==> Running version latest
2025-06-07T23:24:16.2234335Z Could not pull latest version information: SyntaxError: Unexpected token '<', "<!DOCTYPE "... is not valid JSON
2025-06-07T23:24:16.2236421Z ==> Running git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:16.2325110Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:16.2374122Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit'
2025-06-07T23:24:16.2376420Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit --git-service github -Z
2025-06-07T23:24:16.6100847Z info - 2025-06-07 23:24:16,609 -- ci service found: github-actions
2025-06-07T23:24:16.6194598Z warning - 2025-06-07 23:24:16,619 -- No config file could be found. Ignoring config.
2025-06-07T23:24:16.6486178Z info - 2025-06-07 23:24:16,648 -- Using token to create a commit for protected branch `main`
2025-06-07T23:24:17.1871627Z info - 2025-06-07 23:24:17,186 -- Process Commit creating complete
2025-06-07T23:24:17.2886278Z Sentry is attempting to send 2 pending events
2025-06-07T23:24:17.2886588Z Waiting up to 2 seconds
2025-06-07T23:24:17.2886801Z Press Ctrl-C to quit
2025-06-07T23:24:17.3298775Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report'
2025-06-07T23:24:17.3301189Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report --git-service github -Z
2025-06-07T23:24:17.6727361Z info - 2025-06-07 23:24:17,672 -- ci service found: github-actions
2025-06-07T23:24:17.6822558Z warning - 2025-06-07 23:24:17,681 -- No config file could be found. Ignoring config.
2025-06-07T23:24:18.0659574Z info - 2025-06-07 23:24:18,065 -- Process Report creating complete
2025-06-07T23:24:18.0664838Z info - 2025-06-07 23:24:18,066 -- Finished creating report successfully --- {"response": "{\"status\":\"queued\"}\n"}
2025-06-07T23:24:18.1284769Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload'
2025-06-07T23:24:18.1287054Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload -Z -f coverage.xml --git-service github
2025-06-07T23:24:18.4689662Z info - 2025-06-07 23:24:18,468 -- ci service found: github-actions
2025-06-07T23:24:18.4783666Z warning - 2025-06-07 23:24:18,478 -- No config file could be found. Ignoring config.
2025-06-07T23:24:18.5093174Z warning - 2025-06-07 23:24:18,509 -- xcrun is not installed or can't be found.
2025-06-07T23:24:18.5223144Z warning - 2025-06-07 23:24:18,522 -- No gcov data found.
2025-06-07T23:24:18.5229220Z info - 2025-06-07 23:24:18,522 -- Generating coverage.xml report in /home/runner/work/Evolve/Evolve
2025-06-07T23:24:18.6547945Z info - 2025-06-07 23:24:18,654 -- Wrote XML report to coverage.xml
2025-06-07T23:24:18.6958858Z info - 2025-06-07 23:24:18,695 -- Found 1 coverage files to report
2025-06-07T23:24:18.6959589Z info - 2025-06-07 23:24:18,695 -- > /home/runner/work/Evolve/Evolve/coverage.xml
2025-06-07T23:24:19.0561916Z info - 2025-06-07 23:24:19,055 -- Your upload is now processing. When finished, results will be available at: https://app.codecov.io/github/leolech14/Evolve/commit/63224c07a7ba4fd3150d60b6f60c79fd94cff7a2
2025-06-07T23:24:19.1438839Z info - 2025-06-07 23:24:19,143 -- Process Upload complete
2025-06-07T23:24:19.2400136Z ##[group]Run actions/upload-artifact@v4
2025-06-07T23:24:19.2400558Z with:
2025-06-07T23:24:19.2400732Z   name: diagnostics
2025-06-07T23:24:19.2400924Z   path: diagnostics/
2025-06-07T23:24:19.2401131Z   if-no-files-found: warn
2025-06-07T23:24:19.2401343Z   compression-level: 6
2025-06-07T23:24:19.2401533Z   overwrite: false
2025-06-07T23:24:19.2401725Z   include-hidden-files: false
2025-06-07T23:24:19.2401933Z env:
2025-06-07T23:24:19.2402101Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:19.2402292Z   MAX_TOKENS: 5000000
2025-06-07T23:24:19.2402478Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:19.2402654Z   FORCE_EVOLVE: 0
2025-06-07T23:24:19.2402896Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2403289Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:19.2403674Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404021Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404408Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404770Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:19.2405066Z ##[endgroup]
2025-06-07T23:24:19.4584479Z With the provided path, there will be 6 files uploaded
2025-06-07T23:24:19.4590594Z Artifact name is valid!
2025-06-07T23:24:19.4591334Z Root directory input is valid!
2025-06-07T23:24:19.5630272Z Beginning upload of artifact content to blob storage
2025-06-07T23:24:19.6246380Z Uploaded bytes 3477
2025-06-07T23:24:19.6414836Z Finished uploading artifact content to blob storage!
2025-06-07T23:24:19.6418603Z SHA256 digest of uploaded artifact zip is 08f202ae29fd53e7091f1c0fc113a475599e76d435eaea5cfd5927b15ec70681
2025-06-07T23:24:19.6420349Z Finalizing artifact upload
2025-06-07T23:24:19.7074414Z Artifact diagnostics.zip successfully finalized. Artifact ID 3282257397
2025-06-07T23:24:19.7075491Z Artifact diagnostics has been successfully uploaded! Final size is 3477 bytes. Artifact ID is 3282257397
2025-06-07T23:24:19.7082947Z Artifact download URL: https://github.com/leolech14/Evolve/actions/runs/15512627444/artifacts/3282257397
2025-06-07T23:24:19.7190296Z ##[group]Run actions/upload-artifact@v4
2025-06-07T23:24:19.7190590Z with:
2025-06-07T23:24:19.7190760Z   name: csvs
2025-06-07T23:24:19.7190950Z   path: csv_output/
2025-06-07T23:24:19.7191156Z   if-no-files-found: warn
2025-06-07T23:24:19.7191379Z   compression-level: 6
2025-06-07T23:24:19.7191584Z   overwrite: false
2025-06-07T23:24:19.7191787Z   include-hidden-files: false
2025-06-07T23:24:19.7192004Z env:
2025-06-07T23:24:19.7192176Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:19.7192374Z   MAX_TOKENS: 5000000
2025-06-07T23:24:19.7192564Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:19.7192747Z   FORCE_EVOLVE: 0
2025-06-07T23:24:19.7193008Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7193420Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:19.7193825Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194188Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194599Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194969Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:19.7195275Z ##[endgroup]
2025-06-07T23:24:19.9308696Z With the provided path, there will be 14 files uploaded
2025-06-07T23:24:19.9313188Z Artifact name is valid!
2025-06-07T23:24:19.9314242Z Root directory input is valid!
2025-06-07T23:24:20.0001377Z Beginning upload of artifact content to blob storage
2025-06-07T23:24:20.0745223Z Uploaded bytes 14022
2025-06-07T23:24:20.0927438Z Finished uploading artifact content to blob storage!
2025-06-07T23:24:20.0930768Z SHA256 digest of uploaded artifact zip is f0cb7aa5f71fcd01aa66bb33627487b1e693182b4d539f04b0b57428d6992aac
2025-06-07T23:24:20.0932740Z Finalizing artifact upload
2025-06-07T23:24:20.1563829Z Artifact csvs.zip successfully finalized. Artifact ID 3282257402
2025-06-07T23:24:20.1564930Z Artifact csvs has been successfully uploaded! Final size is 14022 bytes. Artifact ID is 3282257402
2025-06-07T23:24:20.1571975Z Artifact download URL: https://github.com/leolech14/Evolve/actions/runs/15512627444/artifacts/3282257402
2025-06-07T23:24:20.1672003Z ##[group]Run python scripts/ci_summary.py
2025-06-07T23:24:20.1672336Z [36;1mpython scripts/ci_summary.py[0m
2025-06-07T23:24:20.1723677Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:20.1723918Z env:
2025-06-07T23:24:20.1724098Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:20.1724317Z   MAX_TOKENS: 5000000
2025-06-07T23:24:20.1724519Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:20.1724713Z   FORCE_EVOLVE: 0
2025-06-07T23:24:20.1724982Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1725418Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:20.1725836Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726207Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726591Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726953Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:20.1727266Z ##[endgroup]
2025-06-07T23:24:20.2036324Z ## CI Run Summary
2025-06-07T23:24:20.2036633Z 
2025-06-07T23:24:20.2036752Z ### Test Results
2025-06-07T23:24:20.2037004Z - Total Tests: 38
2025-06-07T23:24:20.2037250Z - Passed: 0
2025-06-07T23:24:20.2037473Z - Failed: 0
2025-06-07T23:24:20.2037693Z - Skipped: 0
2025-06-07T23:24:20.2037918Z - Coverage: 66.0%
2025-06-07T23:24:20.2038069Z 
2025-06-07T23:24:20.2038164Z ### Lint Issues
2025-06-07T23:24:20.2038778Z ```
2025-06-07T23:24:20.2038998Z Found 9 errors.
2025-06-07T23:24:20.2039224Z ```
2025-06-07T23:24:20.2039339Z 
2025-06-07T23:24:20.2039439Z ### Parser Accuracy
2025-06-07T23:24:20.2039737Z - Average Match: Data not available
2025-06-07T23:24:20.2039961Z 
2025-06-07T23:24:20.2040073Z #### Per-File Results
2025-06-07T23:24:20.2040319Z ```
2025-06-07T23:24:20.2040515Z ```
2025-06-07T23:24:20.2040643Z 
2025-06-07T23:24:20.2111551Z Post job cleanup.
2025-06-07T23:24:20.3573947Z Cache hit occurred on the primary key setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9, not saving cache.
2025-06-07T23:24:20.3690272Z Post job cleanup.
2025-06-07T23:24:20.4638973Z [command]/usr/bin/git version
2025-06-07T23:24:20.4675379Z git version 2.49.0
2025-06-07T23:24:20.4715416Z Copying '/home/runner/.gitconfig' to '/home/runner/work/_temp/4aa82ed3-47bc-40a6-a3e6-39b2ffb98e51/.gitconfig'
2025-06-07T23:24:20.4732276Z Temporarily overriding HOME='/home/runner/work/_temp/4aa82ed3-47bc-40a6-a3e6-39b2ffb98e51' before making global git config changes
2025-06-07T23:24:20.4733275Z Adding repository directory to the temporary git global config as a safe directory
2025-06-07T23:24:20.4737764Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:20.4775502Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2025-06-07T23:24:20.4808701Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2025-06-07T23:24:20.5041984Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2025-06-07T23:24:20.5062908Z http.https://github.com/.extraheader
2025-06-07T23:24:20.5076128Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2025-06-07T23:24:20.5107660Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2025-06-07T23:24:20.5446628Z Cleaning up orphan processes

### system

2025-06-07T23:23:28.1010283Z Requested labels: ubuntu-latest
2025-06-07T23:23:28.1010283Z Job defined at: leolech14/Evolve/.github/workflows/ci.yaml@refs/heads/main
2025-06-07T23:23:28.1010283Z Waiting for a runner to pick up this job...
2025-06-07T23:23:28.4710983Z Job is waiting for a hosted runner to come online.
2025-06-07T23:23:28.4711088Z Job is about to start running on the hosted runner: GitHub Actions 1000001191
### 1_Set up job

ï»¿2025-06-07T23:23:32.7077170Z Current runner version: '2.325.0'
2025-06-07T23:23:32.7101994Z ##[group]Operating System
2025-06-07T23:23:32.7102831Z Ubuntu
2025-06-07T23:23:32.7103433Z 24.04.2
2025-06-07T23:23:32.7103991Z LTS
2025-06-07T23:23:32.7104594Z ##[endgroup]
2025-06-07T23:23:32.7105195Z ##[group]Runner Image
2025-06-07T23:23:32.7105747Z Image: ubuntu-24.04
2025-06-07T23:23:32.7106256Z Version: 20250602.3.0
2025-06-07T23:23:32.7107327Z Included Software: https://github.com/actions/runner-images/blob/ubuntu24/20250602.3/images/ubuntu/Ubuntu2404-Readme.md
2025-06-07T23:23:32.7109027Z Image Release: https://github.com/actions/runner-images/releases/tag/ubuntu24%2F20250602.3
2025-06-07T23:23:32.7109978Z ##[endgroup]
2025-06-07T23:23:32.7110484Z ##[group]Runner Image Provisioner
2025-06-07T23:23:32.7111068Z 2.0.437.1
2025-06-07T23:23:32.7111922Z ##[endgroup]
2025-06-07T23:23:32.7113018Z ##[group]GITHUB_TOKEN Permissions
2025-06-07T23:23:32.7114885Z Contents: read
2025-06-07T23:23:32.7115472Z Metadata: read
2025-06-07T23:23:32.7115944Z Packages: read
2025-06-07T23:23:32.7116758Z ##[endgroup]
2025-06-07T23:23:32.7118896Z Secret source: Actions
2025-06-07T23:23:32.7119694Z Prepare workflow directory
2025-06-07T23:23:32.7497843Z Prepare all required actions
2025-06-07T23:23:32.7534928Z Getting action download info
2025-06-07T23:23:33.0522404Z ##[group]Download immutable action package 'actions/checkout@v4'
2025-06-07T23:23:33.0523441Z Version: 4.2.2
2025-06-07T23:23:33.0524427Z Digest: sha256:ccb2698953eaebd21c7bf6268a94f9c26518a7e38e27e0b83c1fe1ad049819b1
2025-06-07T23:23:33.0525629Z Source commit SHA: 11bd71901bbe5b1630ceea73d27597364c9af683
2025-06-07T23:23:33.0526383Z ##[endgroup]
2025-06-07T23:23:33.1465046Z ##[group]Download immutable action package 'actions/setup-python@v5'
2025-06-07T23:23:33.1465891Z Version: 5.6.0
2025-06-07T23:23:33.1466639Z Digest: sha256:0b35a0c11c97499e4e0576589036d450b9f5f9da74b7774225b3614b57324404
2025-06-07T23:23:33.1467672Z Source commit SHA: a26af69be951a213d495a4c3e4e4022e16d87065
2025-06-07T23:23:33.1468644Z ##[endgroup]
2025-06-07T23:23:33.3441857Z Download action repository 'codecov/codecov-action@v4' (SHA:b9fd7d16f6d7d1b5d2bec1a2887e65ceed900238)
2025-06-07T23:23:33.5123853Z ##[group]Download immutable action package 'actions/upload-artifact@v4'
2025-06-07T23:23:33.5124671Z Version: 4.6.2
2025-06-07T23:23:33.5125451Z Digest: sha256:290722aa3281d5caf23d0acdc3dbeb3424786a1a01a9cc97e72f147225e37c38
2025-06-07T23:23:33.5126471Z Source commit SHA: ea165f8d65b6e75b540449e92b4886f43607fa02
2025-06-07T23:23:33.5127180Z ##[endgroup]
2025-06-07T23:23:33.7263042Z Complete job name: test

### 2_Run actions_checkout@v4

ï»¿2025-06-07T23:23:33.7981442Z ##[group]Run actions/checkout@v4
2025-06-07T23:23:33.7982348Z with:
2025-06-07T23:23:33.7982810Z   repository: leolech14/Evolve
2025-06-07T23:23:33.7983503Z   token: ***
2025-06-07T23:23:33.7983929Z   ssh-strict: true
2025-06-07T23:23:33.7984370Z   ssh-user: git
2025-06-07T23:23:33.7984810Z   persist-credentials: true
2025-06-07T23:23:33.7985290Z   clean: true
2025-06-07T23:23:33.7985739Z   sparse-checkout-cone-mode: true
2025-06-07T23:23:33.7986302Z   fetch-depth: 1
2025-06-07T23:23:33.7986732Z   fetch-tags: false
2025-06-07T23:23:33.7987165Z   show-progress: true
2025-06-07T23:23:33.7987606Z   lfs: false
2025-06-07T23:23:33.7988012Z   submodules: false
2025-06-07T23:23:33.7988701Z   set-safe-directory: true
2025-06-07T23:23:33.7989460Z env:
2025-06-07T23:23:33.7989881Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:33.7990337Z   MAX_TOKENS: 5000000
2025-06-07T23:23:33.7990769Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:33.7991195Z   FORCE_EVOLVE: 0
2025-06-07T23:23:33.7991820Z ##[endgroup]
2025-06-07T23:23:33.9873550Z Syncing repository: leolech14/Evolve
2025-06-07T23:23:33.9875838Z ##[group]Getting Git version info
2025-06-07T23:23:33.9876718Z Working directory is '/home/runner/work/Evolve/Evolve'
2025-06-07T23:23:33.9877901Z [command]/usr/bin/git version
2025-06-07T23:23:33.9942528Z git version 2.49.0
2025-06-07T23:23:33.9970955Z ##[endgroup]
2025-06-07T23:23:33.9990960Z Temporarily overriding HOME='/home/runner/work/_temp/97f172a7-3410-4d24-95b8-6914c7db4862' before making global git config changes
2025-06-07T23:23:33.9993400Z Adding repository directory to the temporary git global config as a safe directory
2025-06-07T23:23:33.9995599Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:23:34.0029445Z Deleting the contents of '/home/runner/work/Evolve/Evolve'
2025-06-07T23:23:34.0033089Z ##[group]Initializing the repository
2025-06-07T23:23:34.0036822Z [command]/usr/bin/git init /home/runner/work/Evolve/Evolve
2025-06-07T23:23:34.0114795Z hint: Using 'master' as the name for the initial branch. This default branch name
2025-06-07T23:23:34.0116190Z hint: is subject to change. To configure the initial branch name to use in all
2025-06-07T23:23:34.0117200Z hint: of your new repositories, which will suppress this warning, call:
2025-06-07T23:23:34.0117946Z hint:
2025-06-07T23:23:34.0118706Z hint: 	git config --global init.defaultBranch <name>
2025-06-07T23:23:34.0119369Z hint:
2025-06-07T23:23:34.0120136Z hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
2025-06-07T23:23:34.0121602Z hint: 'development'. The just-created branch can be renamed via this command:
2025-06-07T23:23:34.0122681Z hint:
2025-06-07T23:23:34.0123465Z hint: 	git branch -m <name>
2025-06-07T23:23:34.0124737Z Initialized empty Git repository in /home/runner/work/Evolve/Evolve/.git/
2025-06-07T23:23:34.0134287Z [command]/usr/bin/git remote add origin https://github.com/leolech14/Evolve
2025-06-07T23:23:34.0166225Z ##[endgroup]
2025-06-07T23:23:34.0167539Z ##[group]Disabling automatic garbage collection
2025-06-07T23:23:34.0171464Z [command]/usr/bin/git config --local gc.auto 0
2025-06-07T23:23:34.0200603Z ##[endgroup]
2025-06-07T23:23:34.0201428Z ##[group]Setting up auth
2025-06-07T23:23:34.0207764Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2025-06-07T23:23:34.0238213Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2025-06-07T23:23:34.0531027Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2025-06-07T23:23:34.0561828Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"
2025-06-07T23:23:34.0782024Z [command]/usr/bin/git config --local http.https://github.com/.extraheader AUTHORIZATION: basic ***
2025-06-07T23:23:34.0824326Z ##[endgroup]
2025-06-07T23:23:34.0825451Z ##[group]Fetching the repository
2025-06-07T23:23:34.0833911Z [command]/usr/bin/git -c protocol.version=2 fetch --no-tags --prune --no-recurse-submodules --depth=1 origin +63224c07a7ba4fd3150d60b6f60c79fd94cff7a2:refs/remotes/origin/main
2025-06-07T23:23:34.6201696Z From https://github.com/leolech14/Evolve
2025-06-07T23:23:34.6203534Z  * [new ref]         63224c07a7ba4fd3150d60b6f60c79fd94cff7a2 -> origin/main
2025-06-07T23:23:34.6232086Z ##[endgroup]
2025-06-07T23:23:34.6233967Z ##[group]Determining the checkout info
2025-06-07T23:23:34.6235992Z ##[endgroup]
2025-06-07T23:23:34.6240701Z [command]/usr/bin/git sparse-checkout disable
2025-06-07T23:23:34.6282810Z [command]/usr/bin/git config --local --unset-all extensions.worktreeConfig
2025-06-07T23:23:34.6311234Z ##[group]Checking out the ref
2025-06-07T23:23:34.6315214Z [command]/usr/bin/git checkout --progress --force -B main refs/remotes/origin/main
2025-06-07T23:23:34.6762202Z Switched to a new branch 'main'
2025-06-07T23:23:34.6764432Z branch 'main' set up to track 'origin/main'.
2025-06-07T23:23:34.6772733Z ##[endgroup]
2025-06-07T23:23:34.6814547Z [command]/usr/bin/git log -1 --format=%H
2025-06-07T23:23:34.6837946Z 63224c07a7ba4fd3150d60b6f60c79fd94cff7a2

### 3_Run actions_setup-python@v5

ï»¿2025-06-07T23:23:34.7212216Z ##[group]Run actions/setup-python@v5
2025-06-07T23:23:34.7213473Z with:
2025-06-07T23:23:34.7214344Z   python-version: 3.12
2025-06-07T23:23:34.7215563Z   cache: pip
2025-06-07T23:23:34.7216463Z   check-latest: false
2025-06-07T23:23:34.7217729Z   token: ***
2025-06-07T23:23:34.7218913Z   update-environment: true
2025-06-07T23:23:34.7220043Z   allow-prereleases: false
2025-06-07T23:23:34.7221116Z   freethreaded: false
2025-06-07T23:23:34.7222070Z env:
2025-06-07T23:23:34.7222907Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:34.7223876Z   MAX_TOKENS: 5000000
2025-06-07T23:23:34.7224842Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:34.7225771Z   FORCE_EVOLVE: 0
2025-06-07T23:23:34.7226693Z ##[endgroup]
2025-06-07T23:23:34.8903739Z ##[group]Installed versions
2025-06-07T23:23:34.8965567Z Successfully set up CPython (3.12.10)
2025-06-07T23:23:34.8968904Z ##[endgroup]
2025-06-07T23:23:34.9929490Z [command]/opt/hostedtoolcache/Python/3.12.10/x64/bin/pip cache dir
2025-06-07T23:23:35.6058677Z /home/runner/.cache/pip
2025-06-07T23:23:35.6973572Z Cache hit for: setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9
2025-06-07T23:23:36.2577796Z Received 88748529 of 88748529 (100.0%), 168.9 MBs/sec
2025-06-07T23:23:36.2579161Z Cache Size: ~85 MB (88748529 B)
2025-06-07T23:23:36.2609015Z [command]/usr/bin/tar -xf /home/runner/work/_temp/93b5cc72-95b4-4e43-8847-db820a536dda/cache.tzst -P -C /home/runner/work/Evolve/Evolve --use-compress-program unzstd
2025-06-07T23:23:36.4129895Z Cache restored successfully
2025-06-07T23:23:36.4306326Z Cache restored from key: setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9

### 4_Create dirs

ï»¿2025-06-07T23:23:36.4458950Z ##[group]Run mkdir -p diagnostics csv_output
2025-06-07T23:23:36.4459385Z [36;1mmkdir -p diagnostics csv_output[0m
2025-06-07T23:23:36.4529478Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:36.4529741Z env:
2025-06-07T23:23:36.4529926Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:36.4530134Z   MAX_TOKENS: 5000000
2025-06-07T23:23:36.4530329Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:36.4530534Z   FORCE_EVOLVE: 0
2025-06-07T23:23:36.4530836Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4531262Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:36.4531677Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532036Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532415Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4532776Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:36.4533075Z ##[endgroup]

### 5_Install dependencies

ï»¿2025-06-07T23:23:36.4666878Z ##[group]Run pip install -e '.[dev]'
2025-06-07T23:23:36.4667217Z [36;1mpip install -e '.[dev]'[0m
2025-06-07T23:23:36.4716229Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:36.4716483Z env:
2025-06-07T23:23:36.4716659Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:36.4716876Z   MAX_TOKENS: 5000000
2025-06-07T23:23:36.4717084Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:36.4717295Z   FORCE_EVOLVE: 0
2025-06-07T23:23:36.4717599Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4718013Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:36.4718655Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719033Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719395Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:36.4719765Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:36.4720069Z ##[endgroup]
2025-06-07T23:23:37.2693489Z Obtaining file:///home/runner/work/Evolve/Evolve
2025-06-07T23:23:37.2712022Z   Installing build dependencies: started
2025-06-07T23:23:37.9908752Z   Installing build dependencies: finished with status 'done'
2025-06-07T23:23:37.9915018Z   Checking if build backend supports build_editable: started
2025-06-07T23:23:38.2904850Z   Checking if build backend supports build_editable: finished with status 'done'
2025-06-07T23:23:38.2915834Z   Getting requirements to build editable: started
2025-06-07T23:23:38.6181817Z   Getting requirements to build editable: finished with status 'done'
2025-06-07T23:23:38.6191666Z   Preparing editable metadata (pyproject.toml): started
2025-06-07T23:23:38.8057478Z   Preparing editable metadata (pyproject.toml): finished with status 'done'
2025-06-07T23:23:38.8603074Z Collecting pdfplumber (from statement_refinery==0.1.0)
2025-06-07T23:23:38.8616531Z   Using cached pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)
2025-06-07T23:23:39.2028108Z Collecting ruff (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2042008Z   Using cached ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)
2025-06-07T23:23:39.2477469Z Collecting black (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2489787Z   Using cached black-25.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)
2025-06-07T23:23:39.2906088Z Collecting pytest (from statement_refinery==0.1.0)
2025-06-07T23:23:39.2917564Z   Using cached pytest-8.4.0-py3-none-any.whl.metadata (7.7 kB)
2025-06-07T23:23:39.3085611Z Collecting pytest-cov (from statement_refinery==0.1.0)
2025-06-07T23:23:39.3096685Z   Using cached pytest_cov-6.1.1-py3-none-any.whl.metadata (28 kB)
2025-06-07T23:23:39.3284922Z Collecting pytest-xdist (from statement_refinery==0.1.0)
2025-06-07T23:23:39.3296454Z   Using cached pytest_xdist-3.7.0-py3-none-any.whl.metadata (3.0 kB)
2025-06-07T23:23:39.4176480Z Collecting mypy (from statement_refinery==0.1.0)
2025-06-07T23:23:39.4189272Z   Using cached mypy-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)
2025-06-07T23:23:39.4756577Z Collecting openai>=0 (from statement_refinery==0.1.0)
2025-06-07T23:23:39.4768814Z   Using cached openai-1.84.0-py3-none-any.whl.metadata (25 kB)
2025-06-07T23:23:39.5163537Z Collecting pre-commit (from statement_refinery==0.1.0)
2025-06-07T23:23:39.5175687Z   Using cached pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)
2025-06-07T23:23:39.5370780Z Collecting anyio<5,>=3.5.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5383444Z   Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)
2025-06-07T23:23:39.5516920Z Collecting distro<2,>=1.7.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5529018Z   Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)
2025-06-07T23:23:39.5722275Z Collecting httpx<1,>=0.23.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.5733558Z   Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)
2025-06-07T23:23:39.6317866Z Collecting jiter<1,>=0.4.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.6329776Z   Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)
2025-06-07T23:23:39.7437023Z Collecting pydantic<3,>=1.9.0 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.7450076Z   Using cached pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)
2025-06-07T23:23:39.7560686Z Collecting sniffio (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.7572059Z   Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)
2025-06-07T23:23:39.8105449Z Collecting tqdm>4 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8118080Z   Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)
2025-06-07T23:23:39.8319361Z Collecting typing-extensions<5,>=4.11 (from openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8331329Z   Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)
2025-06-07T23:23:39.8453041Z Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8464814Z   Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
2025-06-07T23:23:39.8713649Z Collecting certifi (from httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8725331Z   Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:39.8903668Z Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.8915577Z   Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:39.9033392Z Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.9045193Z   Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)
2025-06-07T23:23:39.9144870Z Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:39.9156666Z   Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
2025-06-07T23:23:40.4743914Z Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:40.4757448Z   Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)
2025-06-07T23:23:40.4885842Z Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai>=0->statement_refinery==0.1.0)
2025-06-07T23:23:40.4897379Z   Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)
2025-06-07T23:23:40.5496192Z Collecting click>=8.0.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5508250Z   Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:40.5598452Z Collecting mypy-extensions>=0.4.3 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5609666Z   Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)
2025-06-07T23:23:40.5774015Z Collecting packaging>=22.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5785495Z   Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
2025-06-07T23:23:40.5889533Z Collecting pathspec>=0.9.0 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.5901225Z   Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:40.6077488Z Collecting platformdirs>=2 (from black->statement_refinery==0.1.0)
2025-06-07T23:23:40.6089562Z   Using cached platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)
2025-06-07T23:23:40.6375233Z Collecting pdfminer.six==20250327 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.6386990Z   Using cached pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)
2025-06-07T23:23:40.8039900Z Collecting Pillow>=9.1 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.8052581Z   Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.9 kB)
2025-06-07T23:23:40.8852702Z Collecting pypdfium2>=4.18.0 (from pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.8864540Z   Using cached pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)
2025-06-07T23:23:40.9635628Z Collecting charset-normalizer>=2.0.0 (from pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:40.9648578Z   Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)
2025-06-07T23:23:41.1272354Z Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.1285774Z   Using cached cryptography-45.0.3-cp311-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)
2025-06-07T23:23:41.2317061Z Collecting cffi>=1.14 (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.2330291Z   Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)
2025-06-07T23:23:41.2437475Z Collecting pycparser (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber->statement_refinery==0.1.0)
2025-06-07T23:23:41.2451846Z   Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)
2025-06-07T23:23:41.2583520Z Collecting cfgv>=2.0.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.2594533Z   Using cached cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)
2025-06-07T23:23:41.3009586Z Collecting identify>=1.0.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3021138Z   Using cached identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)
2025-06-07T23:23:41.3596124Z Collecting nodeenv>=0.11.1 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3609121Z   Using cached nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)
2025-06-07T23:23:41.3939260Z Collecting pyyaml>=5.1 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.3951349Z   Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
2025-06-07T23:23:41.4359123Z Collecting virtualenv>=20.10.0 (from pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4370575Z   Using cached virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)
2025-06-07T23:23:41.4601257Z Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4612949Z   Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)
2025-06-07T23:23:41.4797403Z Collecting filelock<4,>=3.12.2 (from virtualenv>=20.10.0->pre-commit->statement_refinery==0.1.0)
2025-06-07T23:23:41.4809396Z   Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)
2025-06-07T23:23:41.5004091Z Collecting iniconfig>=1 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5015914Z   Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)
2025-06-07T23:23:41.5155529Z Collecting pluggy<2,>=1.5 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5167173Z   Using cached pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)
2025-06-07T23:23:41.5350754Z Collecting pygments>=2.7.2 (from pytest->statement_refinery==0.1.0)
2025-06-07T23:23:41.5362581Z   Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)
2025-06-07T23:23:41.8295288Z Collecting coverage>=7.5 (from coverage[toml]>=7.5->pytest-cov->statement_refinery==0.1.0)
2025-06-07T23:23:41.8309121Z   Using cached coverage-7.8.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.9 kB)
2025-06-07T23:23:41.8465952Z Collecting execnet>=2.1 (from pytest-xdist->statement_refinery==0.1.0)
2025-06-07T23:23:41.8477356Z   Using cached execnet-2.1.1-py3-none-any.whl.metadata (2.9 kB)
2025-06-07T23:23:41.8678868Z Using cached openai-1.84.0-py3-none-any.whl (725 kB)
2025-06-07T23:23:41.8694931Z Using cached anyio-4.9.0-py3-none-any.whl (100 kB)
2025-06-07T23:23:41.8706489Z Using cached distro-1.9.0-py3-none-any.whl (20 kB)
2025-06-07T23:23:41.8717387Z Using cached httpx-0.28.1-py3-none-any.whl (73 kB)
2025-06-07T23:23:41.8728862Z Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)
2025-06-07T23:23:41.8740546Z Using cached jiter-0.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)
2025-06-07T23:23:41.8753622Z Using cached pydantic-2.11.5-py3-none-any.whl (444 kB)
2025-06-07T23:23:41.8767750Z Using cached pydantic_core-2.33.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)
2025-06-07T23:23:41.8792708Z Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)
2025-06-07T23:23:41.8803790Z Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
2025-06-07T23:23:41.8814427Z Using cached h11-0.16.0-py3-none-any.whl (37 kB)
2025-06-07T23:23:41.8825281Z Using cached idna-3.10-py3-none-any.whl (70 kB)
2025-06-07T23:23:41.8836491Z Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
2025-06-07T23:23:41.8847182Z Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)
2025-06-07T23:23:41.8858554Z Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)
2025-06-07T23:23:41.8869933Z Using cached black-25.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)
2025-06-07T23:23:41.8893260Z Using cached click-8.2.1-py3-none-any.whl (102 kB)
2025-06-07T23:23:41.8904685Z Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)
2025-06-07T23:23:41.8915391Z Using cached packaging-25.0-py3-none-any.whl (66 kB)
2025-06-07T23:23:41.8926870Z Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)
2025-06-07T23:23:41.8937852Z Using cached platformdirs-4.3.8-py3-none-any.whl (18 kB)
2025-06-07T23:23:41.8948877Z Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)
2025-06-07T23:23:41.8961147Z Using cached mypy-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (12.7 MB)
2025-06-07T23:23:41.9061622Z Using cached pdfplumber-0.11.6-py3-none-any.whl (60 kB)
2025-06-07T23:23:41.9073357Z Using cached pdfminer_six-20250327-py3-none-any.whl (5.6 MB)
2025-06-07T23:23:41.9124939Z Using cached charset_normalizer-3.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)
2025-06-07T23:23:41.9136636Z Using cached cryptography-45.0.3-cp311-abi3-manylinux_2_34_x86_64.whl (4.5 MB)
2025-06-07T23:23:41.9178832Z Using cached cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479 kB)
2025-06-07T23:23:41.9193071Z Using cached pillow-11.2.1-cp312-cp312-manylinux_2_28_x86_64.whl (4.6 MB)
2025-06-07T23:23:41.9236147Z Using cached pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)
2025-06-07T23:23:41.9266329Z Using cached pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)
2025-06-07T23:23:41.9278505Z Using cached cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)
2025-06-07T23:23:41.9289687Z Using cached identify-2.6.12-py2.py3-none-any.whl (99 kB)
2025-06-07T23:23:41.9301216Z Using cached nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)
2025-06-07T23:23:41.9312446Z Using cached PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)
2025-06-07T23:23:41.9328206Z Using cached virtualenv-20.31.2-py3-none-any.whl (6.1 MB)
2025-06-07T23:23:41.9381409Z Using cached distlib-0.3.9-py2.py3-none-any.whl (468 kB)
2025-06-07T23:23:41.9395363Z Using cached filelock-3.18.0-py3-none-any.whl (16 kB)
2025-06-07T23:23:41.9406530Z Using cached pycparser-2.22-py3-none-any.whl (117 kB)
2025-06-07T23:23:41.9418754Z Using cached pytest-8.4.0-py3-none-any.whl (363 kB)
2025-06-07T23:23:41.9432216Z Using cached pluggy-1.6.0-py3-none-any.whl (20 kB)
2025-06-07T23:23:41.9443273Z Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)
2025-06-07T23:23:41.9454165Z Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)
2025-06-07T23:23:41.9473697Z Using cached pytest_cov-6.1.1-py3-none-any.whl (23 kB)
2025-06-07T23:23:41.9485401Z Using cached coverage-7.8.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)
2025-06-07T23:23:41.9497372Z Using cached pytest_xdist-3.7.0-py3-none-any.whl (46 kB)
2025-06-07T23:23:41.9508620Z Using cached execnet-2.1.1-py3-none-any.whl (40 kB)
2025-06-07T23:23:41.9520030Z Using cached ruff-0.11.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
2025-06-07T23:23:42.0493169Z Building wheels for collected packages: statement_refinery
2025-06-07T23:23:42.0501745Z   Building editable for statement_refinery (pyproject.toml): started
2025-06-07T23:23:42.2626848Z   Building editable for statement_refinery (pyproject.toml): finished with status 'done'
2025-06-07T23:23:42.2633274Z   Created wheel for statement_refinery: filename=statement_refinery-0.1.0-0.editable-py3-none-any.whl size=6066 sha256=2cd94dca6b5aa3e58787c9f86473642409a6143d2b7435e65108c513e99fb1a0
2025-06-07T23:23:42.2635155Z   Stored in directory: /tmp/pip-ephem-wheel-cache-9tzq7rmc/wheels/28/ef/08/2643d2d3176a016c9998941a41d908b9230622f970a4566ebe
2025-06-07T23:23:42.2657615Z Successfully built statement_refinery
2025-06-07T23:23:42.3584370Z Installing collected packages: distlib, typing-extensions, tqdm, sniffio, ruff, pyyaml, pypdfium2, pygments, pycparser, pluggy, platformdirs, Pillow, pathspec, packaging, nodeenv, mypy-extensions, jiter, iniconfig, idna, identify, h11, filelock, execnet, distro, coverage, click, charset-normalizer, cfgv, certifi, annotated-types, virtualenv, typing-inspection, pytest, pydantic-core, mypy, httpcore, cffi, black, anyio, pytest-xdist, pytest-cov, pydantic, pre-commit, httpx, cryptography, pdfminer.six, openai, pdfplumber, statement_refinery
2025-06-07T23:23:47.9023956Z 
2025-06-07T23:23:47.9074048Z Successfully installed Pillow-11.2.1 annotated-types-0.7.0 anyio-4.9.0 black-25.1.0 certifi-2025.4.26 cffi-1.17.1 cfgv-3.4.0 charset-normalizer-3.4.2 click-8.2.1 coverage-7.8.2 cryptography-45.0.3 distlib-0.3.9 distro-1.9.0 execnet-2.1.1 filelock-3.18.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 identify-2.6.12 idna-3.10 iniconfig-2.1.0 jiter-0.10.0 mypy-1.16.0 mypy-extensions-1.1.0 nodeenv-1.9.1 openai-1.84.0 packaging-25.0 pathspec-0.12.1 pdfminer.six-20250327 pdfplumber-0.11.6 platformdirs-4.3.8 pluggy-1.6.0 pre-commit-4.2.0 pycparser-2.22 pydantic-2.11.5 pydantic-core-2.33.2 pygments-2.19.1 pypdfium2-4.30.1 pytest-8.4.0 pytest-cov-6.1.1 pytest-xdist-3.7.0 pyyaml-6.0.2 ruff-0.11.13 sniffio-1.3.1 statement_refinery-0.1.0 tqdm-4.67.1 typing-extensions-4.14.0 typing-inspection-0.4.1 virtualenv-20.31.2

### 6_Run pre-commit

ï»¿2025-06-07T23:23:48.3317167Z ##[group]Run pre-commit run --all-files --show-diff-on-failure || echo "::warning::lint failed (ignored)"
2025-06-07T23:23:48.3317899Z [36;1mpre-commit run --all-files --show-diff-on-failure || echo "::warning::lint failed (ignored)"[0m
2025-06-07T23:23:48.3370350Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:48.3370612Z env:
2025-06-07T23:23:48.3370790Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:48.3371001Z   MAX_TOKENS: 5000000
2025-06-07T23:23:48.3371194Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:48.3371379Z   FORCE_EVOLVE: 0
2025-06-07T23:23:48.3371632Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3372058Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:48.3372460Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3372816Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3373177Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:48.3373534Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:48.3373885Z   GIT_ASKPASS: true
2025-06-07T23:23:48.3374072Z ##[endgroup]
2025-06-07T23:23:48.5051766Z [INFO] Initializing environment for https://github.com/astral-sh/ruff-pre-commit.
2025-06-07T23:23:48.6939603Z [INFO] Initializing environment for https://github.com/psf/black.
2025-06-07T23:23:48.9732057Z [INFO] Installing environment for https://github.com/astral-sh/ruff-pre-commit.
2025-06-07T23:23:48.9732876Z [INFO] Once installed this environment will be reused.
2025-06-07T23:23:48.9733380Z [INFO] This may take a few minutes...
2025-06-07T23:23:52.5257045Z [INFO] Installing environment for https://github.com/psf/black.
2025-06-07T23:23:52.5257656Z [INFO] Once installed this environment will be reused.
2025-06-07T23:23:52.5257995Z [INFO] This may take a few minutes...
2025-06-07T23:23:55.7315400Z ruff (auto-fix)..........................................................Failed
2025-06-07T23:23:55.7316032Z - hook id: ruff
2025-06-07T23:23:55.7316433Z - files were modified by this hook
2025-06-07T23:23:55.7316672Z 
2025-06-07T23:23:55.7317008Z scripts/comprehensive_analysis.py:21:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7317613Z    |
2025-06-07T23:23:55.7317888Z 19 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7318252Z 20 |
2025-06-07T23:23:55.7318779Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7319199Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7319711Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7320266Z    |
2025-06-07T23:23:55.7320419Z 
2025-06-07T23:23:55.7320778Z scripts/comprehensive_analysis.py:22:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7321424Z    |
2025-06-07T23:23:55.7321743Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7322331Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7322913Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7323338Z 23 |
2025-06-07T23:23:55.7323634Z 24 | logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:55.7324240Z    |
2025-06-07T23:23:55.7324359Z 
2025-06-07T23:23:55.7324717Z scripts/generate_golden_csvs.py:15:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7325345Z    |
2025-06-07T23:23:55.7325661Z 13 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7326144Z 14 |
2025-06-07T23:23:55.7326481Z 15 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7326954Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7327361Z 16 |
2025-06-07T23:23:55.7327827Z 17 | def generate_golden_csv(pdf_path: Path, output_dir: Path) -> Path:
2025-06-07T23:23:55.7328601Z    |
2025-06-07T23:23:55.7328767Z 
2025-06-07T23:23:55.7329193Z scripts/pattern_enhancer.py:35:13: F841 Local variable `count` is assigned to but never used
2025-06-07T23:23:55.7329875Z    |
2025-06-07T23:23:55.7330192Z 33 |         for pattern in discovered:
2025-06-07T23:23:55.7330953Z 34 |             structure = pattern["structure"]
2025-06-07T23:23:55.7331419Z 35 |             count = pattern["count"]
2025-06-07T23:23:55.7331831Z    |             ^^^^^ F841
2025-06-07T23:23:55.7332228Z 36 |             examples = pattern["examples"]
2025-06-07T23:23:55.7332660Z    |
2025-06-07T23:23:55.7333020Z    = help: Remove assignment to unused variable `count`
2025-06-07T23:23:55.7333376Z 
2025-06-07T23:23:55.7333739Z scripts/semantic_validator.py:19:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7334361Z    |
2025-06-07T23:23:55.7334681Z 17 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7335096Z 18 |
2025-06-07T23:23:55.7335431Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7335897Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7336496Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7337062Z    |
2025-06-07T23:23:55.7337229Z 
2025-06-07T23:23:55.7337587Z scripts/semantic_validator.py:20:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7338200Z    |
2025-06-07T23:23:55.7338773Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7339384Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7339927Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7340350Z 21 |
2025-06-07T23:23:55.7340657Z 22 | class SemanticValidator:
2025-06-07T23:23:55.7341035Z    |
2025-06-07T23:23:55.7341184Z 
2025-06-07T23:23:55.7341469Z scripts/semantic_validator.py:63:9: E722 Do not use bare `except`
2025-06-07T23:23:55.7341999Z    |
2025-06-07T23:23:55.7342281Z 61 |         try:
2025-06-07T23:23:55.7342709Z 62 |             pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:55.7343220Z 63 |         except:
2025-06-07T23:23:55.7343575Z    |         ^^^^^^ E722
2025-06-07T23:23:55.7343962Z 64 |             pass
2025-06-07T23:23:55.7344286Z    |
2025-06-07T23:23:55.7344445Z 
2025-06-07T23:23:55.7344825Z scripts/validate_real_accuracy.py:17:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7345469Z    |
2025-06-07T23:23:55.7345835Z 15 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:55.7346284Z 16 |
2025-06-07T23:23:55.7346730Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7347283Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7347957Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7348706Z    |
2025-06-07T23:23:55.7348859Z 
2025-06-07T23:23:55.7349225Z scripts/validate_real_accuracy.py:18:1: E402 Module level import not at top of file
2025-06-07T23:23:55.7349860Z    |
2025-06-07T23:23:55.7350184Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:55.7350796Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:55.7351389Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:55.7351836Z 19 |
2025-06-07T23:23:55.7352236Z 20 | def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:55.7352915Z    |
2025-06-07T23:23:55.7353060Z 
2025-06-07T23:23:55.7353218Z Found 12 errors (3 fixed, 9 remaining).
2025-06-07T23:23:55.7353832Z No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
2025-06-07T23:23:55.7354356Z 
2025-06-07T23:23:55.7790839Z ruff (format)............................................................Failed
2025-06-07T23:23:55.7791545Z - hook id: ruff-format
2025-06-07T23:23:55.7791924Z - files were modified by this hook
2025-06-07T23:23:55.7792176Z 
2025-06-07T23:23:55.7792340Z 9 files reformatted, 15 files left unchanged
2025-06-07T23:23:55.7792624Z 
2025-06-07T23:23:56.8457671Z black check..............................................................Failed
2025-06-07T23:23:56.8458497Z - hook id: black
2025-06-07T23:23:56.8458885Z - exit code: 1
2025-06-07T23:23:56.8459079Z 
2025-06-07T23:23:56.8459684Z would reformat scripts/pattern_enhancer.py
2025-06-07T23:23:56.8460226Z would reformat scripts/validate_real_accuracy.py
2025-06-07T23:23:56.8460792Z would reformat scripts/incremental_learner.py
2025-06-07T23:23:56.8461351Z would reformat tests/test_pre_commit_config.py
2025-06-07T23:23:56.8461880Z would reformat scripts/semantic_validator.py
2025-06-07T23:23:56.8462222Z 
2025-06-07T23:23:56.8462766Z Oh no! ðŸ’¥ ðŸ’” ðŸ’¥
2025-06-07T23:23:56.8463253Z 5 files would be reformatted, 19 files would be left unchanged.
2025-06-07T23:23:56.8463630Z 
2025-06-07T23:23:56.8823301Z Export AI Patch..........................................................Passed
2025-06-07T23:23:56.8823872Z - hook id: export-ai-patch
2025-06-07T23:23:56.8824116Z - duration: 0s
2025-06-07T23:23:56.8824240Z 
2025-06-07T23:23:56.8824478Z cp: cannot stat 'diagnostics/ai-patch-unapplied.patch': No such file or directory
2025-06-07T23:23:56.8824820Z 
2025-06-07T23:23:56.8824921Z pre-commit hook(s) made changes.
2025-06-07T23:23:56.8825480Z If you are seeing this message in CI, reproduce locally with: `pre-commit run --all-files`.
2025-06-07T23:23:56.8826030Z To run `pre-commit` as part of git workflow, use `pre-commit install`.
2025-06-07T23:23:56.8826496Z All changes made by hooks:
2025-06-07T23:23:56.9120725Z diff --git a/scripts/comprehensive_analysis.py b/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9121657Z index 2fb747f..5d85ede 100644
2025-06-07T23:23:56.9122146Z --- a/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9122663Z +++ b/scripts/comprehensive_analysis.py
2025-06-07T23:23:56.9123172Z @@ -24,9 +24,10 @@ from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9123691Z  logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:56.9124176Z  logger = logging.getLogger(__name__)
2025-06-07T23:23:56.9175224Z  
2025-06-07T23:23:56.9175507Z +
2025-06-07T23:23:56.9175794Z  class PatternAnalyzer:
2025-06-07T23:23:56.9176322Z      """Analyzes parsing patterns and failures across multiple PDFs."""
2025-06-07T23:23:56.9176893Z -    
2025-06-07T23:23:56.9177155Z +
2025-06-07T23:23:56.9177414Z      def __init__(self):
2025-06-07T23:23:56.9178090Z          self.parsed_lines = []
2025-06-07T23:23:56.9178638Z          self.failed_lines = []
2025-06-07T23:23:56.9179045Z @@ -36,15 +37,15 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9179465Z          self.merchant_patterns = set()
2025-06-07T23:23:56.9179855Z          self.totals_found = {}
2025-06-07T23:23:56.9180251Z          self.parsing_stats = defaultdict(int)
2025-06-07T23:23:56.9180667Z -        
2025-06-07T23:23:56.9180933Z +
2025-06-07T23:23:56.9181267Z      def analyze_pdf(self, pdf_path: Path) -> Dict:
2025-06-07T23:23:56.9181841Z          """Analyze a single PDF and extract parsing insights."""
2025-06-07T23:23:56.9182397Z          logger.info(f"Analyzing {pdf_path.name}")
2025-06-07T23:23:56.9182828Z -        
2025-06-07T23:23:56.9183084Z +
2025-06-07T23:23:56.9183328Z          try:
2025-06-07T23:23:56.9183626Z              # Extract lines from PDF
2025-06-07T23:23:56.9184108Z              lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9184555Z -            
2025-06-07T23:23:56.9185104Z +
2025-06-07T23:23:56.9185277Z              # Try to extract total
2025-06-07T23:23:56.9185522Z              pdf_total = None
2025-06-07T23:23:56.9185735Z              try:
2025-06-07T23:23:56.9185947Z @@ -52,15 +53,15 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9186249Z                  self.totals_found[pdf_path.name] = pdf_total
2025-06-07T23:23:56.9186542Z              except Exception as e:
2025-06-07T23:23:56.9186877Z                  logger.warning(f"Could not extract total from {pdf_path.name}: {e}")
2025-06-07T23:23:56.9187215Z -            
2025-06-07T23:23:56.9187384Z +
2025-06-07T23:23:56.9187557Z              # Parse lines and categorize
2025-06-07T23:23:56.9187815Z              parsed_transactions = []
2025-06-07T23:23:56.9188057Z              failed_lines = []
2025-06-07T23:23:56.9188461Z -            
2025-06-07T23:23:56.9188885Z +
2025-06-07T23:23:56.9189080Z              for line_num, line in enumerate(lines, 1):
2025-06-07T23:23:56.9189354Z                  if not line.strip():
2025-06-07T23:23:56.9189587Z                      continue
2025-06-07T23:23:56.9189788Z -                    
2025-06-07T23:23:56.9189968Z +
2025-06-07T23:23:56.9190181Z                  result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9190461Z                  if result:
2025-06-07T23:23:56.9190693Z                      parsed_transactions.append(result)
2025-06-07T23:23:56.9190976Z @@ -71,10 +72,12 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9191249Z                      if self._looks_like_transaction(line):
2025-06-07T23:23:56.9191540Z                          failed_lines.append((line_num, line))
2025-06-07T23:23:56.9191881Z                          self.failed_lines.append((pdf_path.name, line_num, line))
2025-06-07T23:23:56.9192182Z -            
2025-06-07T23:23:56.9192345Z +
2025-06-07T23:23:56.9192507Z              # Calculate CSV total
2025-06-07T23:23:56.9192855Z -            csv_total = sum(t.get("amount_brl", Decimal("0")) for t in parsed_transactions)
2025-06-07T23:23:56.9193192Z -            
2025-06-07T23:23:56.9193374Z +            csv_total = sum(
2025-06-07T23:23:56.9193687Z +                t.get("amount_brl", Decimal("0")) for t in parsed_transactions
2025-06-07T23:23:56.9193985Z +            )
2025-06-07T23:23:56.9194166Z +
2025-06-07T23:23:56.9194342Z              analysis = {
2025-06-07T23:23:56.9194562Z                  "pdf_name": pdf_path.name,
2025-06-07T23:23:56.9194810Z                  "total_lines": len(lines),
2025-06-07T23:23:56.9195062Z @@ -84,80 +87,89 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9195356Z                  "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9195742Z                  "total_delta": float(abs(csv_total - pdf_total)) if pdf_total else None,
2025-06-07T23:23:56.9196127Z                  "failed_lines": failed_lines[:10],  # First 10 for review
2025-06-07T23:23:56.9196601Z -                "success_rate": len(parsed_transactions) / max(1, len(parsed_transactions) + len(failed_lines))
2025-06-07T23:23:56.9197040Z +                "success_rate": len(parsed_transactions)
2025-06-07T23:23:56.9197361Z +                / max(1, len(parsed_transactions) + len(failed_lines)),
2025-06-07T23:23:56.9197637Z              }
2025-06-07T23:23:56.9197803Z -            
2025-06-07T23:23:56.9197962Z +
2025-06-07T23:23:56.9198138Z              self.parsing_stats["total_pdfs"] += 1
2025-06-07T23:23:56.9198593Z              self.parsing_stats["total_parsed"] += len(parsed_transactions)
2025-06-07T23:23:56.9198969Z              self.parsing_stats["total_failed"] += len(failed_lines)
2025-06-07T23:23:56.9199250Z -            
2025-06-07T23:23:56.9199407Z +
2025-06-07T23:23:56.9199567Z              return analysis
2025-06-07T23:23:56.9199764Z -            
2025-06-07T23:23:56.9199922Z +
2025-06-07T23:23:56.9200082Z          except Exception as e:
2025-06-07T23:23:56.9200369Z              logger.error(f"Error analyzing {pdf_path.name}: {e}")
2025-06-07T23:23:56.9200720Z              return {"pdf_name": pdf_path.name, "error": str(e)}
2025-06-07T23:23:56.9201114Z -    
2025-06-07T23:23:56.9201264Z +
2025-06-07T23:23:56.9201491Z      def _analyze_successful_parse(self, line: str, result: Dict):
2025-06-07T23:23:56.9201847Z          """Analyze successful parsing to understand patterns."""
2025-06-07T23:23:56.9202134Z          # Track amount formats
2025-06-07T23:23:56.9202422Z -        amount_match = re.search(r'-?\d{1,3}(?:\.\d{3})*,\d{2}', line)
2025-06-07T23:23:56.9202807Z +        amount_match = re.search(r"-?\d{1,3}(?:\.\d{3})*,\d{2}", line)
2025-06-07T23:23:56.9203105Z          if amount_match:
2025-06-07T23:23:56.9203351Z              self.amount_formats.add(amount_match.group())
2025-06-07T23:23:56.9203615Z -        
2025-06-07T23:23:56.9203787Z -        # Track date formats  
2025-06-07T23:23:56.9204036Z -        date_match = re.search(r'\d{1,2}/\d{1,2}', line)
2025-06-07T23:23:56.9204412Z +
2025-06-07T23:23:56.9204574Z +        # Track date formats
2025-06-07T23:23:56.9204813Z +        date_match = re.search(r"\d{1,2}/\d{1,2}", line)
2025-06-07T23:23:56.9205074Z          if date_match:
2025-06-07T23:23:56.9205308Z              self.date_formats.add(date_match.group())
2025-06-07T23:23:56.9205560Z -        
2025-06-07T23:23:56.9205716Z +
2025-06-07T23:23:56.9205882Z          # Track merchant patterns
2025-06-07T23:23:56.9206137Z          if result.get("desc_raw"):
2025-06-07T23:23:56.9206417Z              merchant = result["desc_raw"][:30]  # First 30 chars
2025-06-07T23:23:56.9206720Z              self.merchant_patterns.add(merchant)
2025-06-07T23:23:56.9206963Z -    
2025-06-07T23:23:56.9207111Z +
2025-06-07T23:23:56.9207317Z      def _looks_like_transaction(self, line: str) -> bool:
2025-06-07T23:23:56.9207677Z          """Heuristic to determine if a line might be a transaction."""
2025-06-07T23:23:56.9207992Z          line_upper = line.upper()
2025-06-07T23:23:56.9208205Z -        
2025-06-07T23:23:56.9208580Z +
2025-06-07T23:23:56.9208751Z          # Has amount pattern
2025-06-07T23:23:56.9209049Z -        has_amount = bool(re.search(r'\d{1,3}(?:\.\d{3})*,\d{2}', line))
2025-06-07T23:23:56.9209348Z -        
2025-06-07T23:23:56.9209576Z +        has_amount = bool(re.search(r"\d{1,3}(?:\.\d{3})*,\d{2}", line))
2025-06-07T23:23:56.9209859Z +
2025-06-07T23:23:56.9210013Z          # Has date pattern
2025-06-07T23:23:56.9210263Z -        has_date = bool(re.search(r'\d{1,2}/\d{1,2}', line))
2025-06-07T23:23:56.9210526Z -        
2025-06-07T23:23:56.9210735Z +        has_date = bool(re.search(r"\d{1,2}/\d{1,2}", line))
2025-06-07T23:23:56.9210996Z +
2025-06-07T23:23:56.9211164Z          # Skip obvious headers/footers
2025-06-07T23:23:56.9211404Z          skip_keywords = [
2025-06-07T23:23:56.9211686Z -            "FATURA", "VENCIMENTO", "LIMITE", "TOTAL", "PAGINA", "CARTAO",
2025-06-07T23:23:56.9212069Z -            "MASTERCARD", "VISA", "SAC", "OUVIDORIA", "TELEFONE", "EMAIL"
2025-06-07T23:23:56.9212370Z +            "FATURA",
2025-06-07T23:23:56.9212566Z +            "VENCIMENTO",
2025-06-07T23:23:56.9212764Z +            "LIMITE",
2025-06-07T23:23:56.9212949Z +            "TOTAL",
2025-06-07T23:23:56.9213133Z +            "PAGINA",
2025-06-07T23:23:56.9213318Z +            "CARTAO",
2025-06-07T23:23:56.9213502Z +            "MASTERCARD",
2025-06-07T23:23:56.9213697Z +            "VISA",
2025-06-07T23:23:56.9213871Z +            "SAC",
2025-06-07T23:23:56.9214051Z +            "OUVIDORIA",
2025-06-07T23:23:56.9214251Z +            "TELEFONE",
2025-06-07T23:23:56.9214438Z +            "EMAIL",
2025-06-07T23:23:56.9214612Z          ]
2025-06-07T23:23:56.9214771Z -        
2025-06-07T23:23:56.9214925Z +
2025-06-07T23:23:56.9215159Z          has_skip_keyword = any(kw in line_upper for kw in skip_keywords)
2025-06-07T23:23:56.9215463Z -        
2025-06-07T23:23:56.9215618Z +
2025-06-07T23:23:56.9215843Z          return (has_amount or has_date) and not has_skip_keyword
2025-06-07T23:23:56.9216132Z -    
2025-06-07T23:23:56.9216283Z +
2025-06-07T23:23:56.9216472Z      def discover_new_patterns(self) -> List[str]:
2025-06-07T23:23:56.9216785Z          """Analyze failed lines to discover new patterns."""
2025-06-07T23:23:56.9217193Z          patterns = []
2025-06-07T23:23:56.9217378Z -        
2025-06-07T23:23:56.9217529Z +
2025-06-07T23:23:56.9217704Z          # Group failed lines by similarity
2025-06-07T23:23:56.9217976Z          failed_by_structure = defaultdict(list)
2025-06-07T23:23:56.9218220Z -        
2025-06-07T23:23:56.9218482Z +
2025-06-07T23:23:56.9218684Z          for pdf_name, line_num, line in self.failed_lines:
2025-06-07T23:23:56.9218975Z              # Create structural signature
2025-06-07T23:23:56.9219294Z -            structure = re.sub(r'\d+', 'N', line)  # Replace numbers with N
2025-06-07T23:23:56.9219701Z -            structure = re.sub(r'[A-Za-z]+', 'W', structure)  # Replace words with W
2025-06-07T23:23:56.9220097Z +            structure = re.sub(r"\d+", "N", line)  # Replace numbers with N
2025-06-07T23:23:56.9220600Z +            structure = re.sub(r"[A-Za-z]+", "W", structure)  # Replace words with W
2025-06-07T23:23:56.9220959Z              failed_by_structure[structure].append(line)
2025-06-07T23:23:56.9221219Z -        
2025-06-07T23:23:56.9221375Z +
2025-06-07T23:23:56.9221532Z          # Find common structures
2025-06-07T23:23:56.9221806Z          for structure, lines in failed_by_structure.items():
2025-06-07T23:23:56.9222147Z              if len(lines) >= 2:  # Pattern appears in multiple lines
2025-06-07T23:23:56.9222450Z -                patterns.append({
2025-06-07T23:23:56.9222703Z -                    "structure": structure,
2025-06-07T23:23:56.9222952Z -                    "count": len(lines),
2025-06-07T23:23:56.9223193Z -                    "examples": lines[:3]
2025-06-07T23:23:56.9223425Z -                })
2025-06-07T23:23:56.9223599Z -        
2025-06-07T23:23:56.9223772Z +                patterns.append(
2025-06-07T23:23:56.9224087Z +                    {"structure": structure, "count": len(lines), "examples": lines[:3]}
2025-06-07T23:23:56.9224421Z +                )
2025-06-07T23:23:56.9224592Z +
2025-06-07T23:23:56.9224755Z          return patterns
2025-06-07T23:23:56.9224947Z -    
2025-06-07T23:23:56.9225100Z +
2025-06-07T23:23:56.9225275Z      def generate_report(self) -> Dict:
2025-06-07T23:23:56.9225556Z          """Generate comprehensive analysis report."""
2025-06-07T23:23:56.9225812Z          return {
2025-06-07T23:23:56.9226021Z @@ -165,82 +177,106 @@ class PatternAnalyzer:
2025-06-07T23:23:56.9226344Z                  "total_pdfs_analyzed": self.parsing_stats["total_pdfs"],
2025-06-07T23:23:56.9226739Z                  "total_transactions_parsed": self.parsing_stats["total_parsed"],
2025-06-07T23:23:56.9227133Z                  "total_failed_lines": self.parsing_stats["total_failed"],
2025-06-07T23:23:56.9227728Z -                "overall_success_rate": self.parsing_stats["total_parsed"] / max(1, self.parsing_stats["total_parsed"] + self.parsing_stats["total_failed"])
2025-06-07T23:23:56.9228432Z +                "overall_success_rate": self.parsing_stats["total_parsed"]
2025-06-07T23:23:56.9228867Z +                / max(
2025-06-07T23:23:56.9229064Z +                    1,
2025-06-07T23:23:56.9229274Z +                    self.parsing_stats["total_parsed"]
2025-06-07T23:23:56.9229565Z +                    + self.parsing_stats["total_failed"],
2025-06-07T23:23:56.9229814Z +                ),
2025-06-07T23:23:56.9229988Z              },
2025-06-07T23:23:56.9230174Z              "pattern_insights": {
2025-06-07T23:23:56.9230457Z                  "unique_amount_formats": len(self.amount_formats),
2025-06-07T23:23:56.9230786Z                  "unique_date_formats": len(self.date_formats),
2025-06-07T23:23:56.9231125Z                  "unique_merchant_patterns": len(self.merchant_patterns),
2025-06-07T23:23:56.9231491Z                  "amount_format_examples": list(self.amount_formats)[:10],
2025-06-07T23:23:56.9231846Z -                "date_format_examples": list(self.date_formats)[:10]
2025-06-07T23:23:56.9232195Z +                "date_format_examples": list(self.date_formats)[:10],
2025-06-07T23:23:56.9232470Z              },
2025-06-07T23:23:56.9232841Z              "discovered_patterns": self.discover_new_patterns(),
2025-06-07T23:23:56.9233137Z              "totals_extraction": {
2025-06-07T23:23:56.9233411Z                  "successful_extractions": len(self.totals_found),
2025-06-07T23:23:56.9233828Z -                "failed_extractions": self.parsing_stats["total_pdfs"] - len(self.totals_found),
2025-06-07T23:23:56.9234240Z -                "extracted_totals": self.totals_found
2025-06-07T23:23:56.9234496Z -            }
2025-06-07T23:23:56.9234744Z +                "failed_extractions": self.parsing_stats["total_pdfs"]
2025-06-07T23:23:56.9235068Z +                - len(self.totals_found),
2025-06-07T23:23:56.9235353Z +                "extracted_totals": self.totals_found,
2025-06-07T23:23:56.9235640Z +            },
2025-06-07T23:23:56.9235921Z          }
2025-06-07T23:23:56.9236075Z  
2025-06-07T23:23:56.9236221Z  
2025-06-07T23:23:56.9236369Z  def main():
2025-06-07T23:23:56.9236751Z -    parser = argparse.ArgumentParser(description="Comprehensive PDF analysis for pattern discovery")
2025-06-07T23:23:56.9237225Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9237568Z +        description="Comprehensive PDF analysis for pattern discovery"
2025-06-07T23:23:56.9237882Z +    )
2025-06-07T23:23:56.9238145Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9238752Z -    parser.add_argument("--output", "-o", default="diagnostics/comprehensive_analysis.json", 
2025-06-07T23:23:56.9239181Z -                       help="Output file for analysis report")
2025-06-07T23:23:56.9239462Z +    parser.add_argument(
2025-06-07T23:23:56.9239669Z +        "--output",
2025-06-07T23:23:56.9239856Z +        "-o",
2025-06-07T23:23:56.9240090Z +        default="diagnostics/comprehensive_analysis.json",
2025-06-07T23:23:56.9240413Z +        help="Output file for analysis report",
2025-06-07T23:23:56.9240654Z +    )
2025-06-07T23:23:56.9240832Z      args = parser.parse_args()
2025-06-07T23:23:56.9241049Z -    
2025-06-07T23:23:56.9241201Z +
2025-06-07T23:23:56.9241364Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9241602Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9241874Z          logger.error(f"Directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9242150Z          return 1
2025-06-07T23:23:56.9242317Z -    
2025-06-07T23:23:56.9242468Z +
2025-06-07T23:23:56.9242631Z      # Create output directory
2025-06-07T23:23:56.9242864Z      output_path = Path(args.output)
2025-06-07T23:23:56.9243169Z      output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9243448Z -    
2025-06-07T23:23:56.9243599Z +
2025-06-07T23:23:56.9243761Z      analyzer = PatternAnalyzer()
2025-06-07T23:23:56.9243990Z      pdf_analyses = []
2025-06-07T23:23:56.9244176Z -    
2025-06-07T23:23:56.9244323Z +
2025-06-07T23:23:56.9244484Z      # Analyze all PDFs
2025-06-07T23:23:56.9244722Z      for pdf_path in sorted(pdf_dir.glob("*.pdf")):
2025-06-07T23:23:56.9245032Z          analysis = analyzer.analyze_pdf(pdf_path)
2025-06-07T23:23:56.9245321Z          pdf_analyses.append(analysis)
2025-06-07T23:23:56.9245549Z -        
2025-06-07T23:23:56.9245704Z +
2025-06-07T23:23:56.9245865Z          # Print brief summary
2025-06-07T23:23:56.9246087Z          if "error" not in analysis:
2025-06-07T23:23:56.9246371Z              success_rate = analysis.get("success_rate", 0) * 100
2025-06-07T23:23:56.9246768Z -            logger.info(f"{pdf_path.name}: {analysis['parsed_transactions']} parsed, "
2025-06-07T23:23:56.9247277Z -                       f"{analysis['failed_potential_transactions']} failed ({success_rate:.1f}% success)")
2025-06-07T23:23:56.9247652Z -    
2025-06-07T23:23:56.9247816Z +            logger.info(
2025-06-07T23:23:56.9248095Z +                f"{pdf_path.name}: {analysis['parsed_transactions']} parsed, "
2025-06-07T23:23:56.9248755Z +                f"{analysis['failed_potential_transactions']} failed ({success_rate:.1f}% success)"
2025-06-07T23:23:56.9249131Z +            )
2025-06-07T23:23:56.9249429Z +
2025-06-07T23:23:56.9249602Z      # Generate comprehensive report
2025-06-07T23:23:56.9249865Z      report = analyzer.generate_report()
2025-06-07T23:23:56.9250138Z      report["individual_pdfs"] = pdf_analyses
2025-06-07T23:23:56.9250380Z -    
2025-06-07T23:23:56.9250525Z +
2025-06-07T23:23:56.9250677Z      # Save report
2025-06-07T23:23:56.9250882Z -    with open(output_path, 'w') as f:
2025-06-07T23:23:56.9251132Z +    with open(output_path, "w") as f:
2025-06-07T23:23:56.9251406Z          json.dump(report, f, indent=2, default=str)
2025-06-07T23:23:56.9251663Z -    
2025-06-07T23:23:56.9251811Z +
2025-06-07T23:23:56.9252067Z      logger.info(f"Analysis complete. Report saved to {output_path}")
2025-06-07T23:23:56.9252373Z -    
2025-06-07T23:23:56.9252522Z +
2025-06-07T23:23:56.9252675Z      # Print summary
2025-06-07T23:23:56.9252985Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9253190Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9253425Z      print("COMPREHENSIVE ANALYSIS SUMMARY")
2025-06-07T23:23:56.9253676Z -    print("="*60)
2025-06-07T23:23:56.9253858Z +    print("=" * 60)
2025-06-07T23:23:56.9254131Z      print(f"PDFs Analyzed: {report['summary']['total_pdfs_analyzed']}")
2025-06-07T23:23:56.9254582Z      print(f"Transactions Parsed: {report['summary']['total_transactions_parsed']}")
2025-06-07T23:23:56.9255021Z      print(f"Failed Lines: {report['summary']['total_failed_lines']}")
2025-06-07T23:23:56.9255444Z      print(f"Overall Success Rate: {report['summary']['overall_success_rate']:.1%}")
2025-06-07T23:23:56.9255940Z -    print(f"Unique Amount Formats: {report['pattern_insights']['unique_amount_formats']}")
2025-06-07T23:23:56.9256313Z +    print(
2025-06-07T23:23:56.9256608Z +        f"Unique Amount Formats: {report['pattern_insights']['unique_amount_formats']}"
2025-06-07T23:23:56.9256956Z +    )
2025-06-07T23:23:56.9257223Z      print(f"Discovered Patterns: {len(report['discovered_patterns'])}")
2025-06-07T23:23:56.9257867Z -    print(f"Total Extractions Successful: {report['totals_extraction']['successful_extractions']}/{report['summary']['total_pdfs_analyzed']}")
2025-06-07T23:23:56.9258507Z -    
2025-06-07T23:23:56.9258682Z -    if report['discovered_patterns']:
2025-06-07T23:23:56.9258915Z +    print(
2025-06-07T23:23:56.9259366Z +        f"Total Extractions Successful: {report['totals_extraction']['successful_extractions']}/{report['summary']['total_pdfs_analyzed']}"
2025-06-07T23:23:56.9259869Z +    )
2025-06-07T23:23:56.9260018Z +
2025-06-07T23:23:56.9260187Z +    if report["discovered_patterns"]:
2025-06-07T23:23:56.9260461Z          print("\nMOST COMMON FAILED PATTERNS:")
2025-06-07T23:23:56.9260942Z -        for i, pattern in enumerate(sorted(report['discovered_patterns'], key=lambda x: x['count'], reverse=True)[:5]):
2025-06-07T23:23:56.9261522Z -            print(f"{i+1}. Structure: {pattern['structure']} (appears {pattern['count']} times)")
2025-06-07T23:23:56.9261912Z +        for i, pattern in enumerate(
2025-06-07T23:23:56.9262142Z +            sorted(
2025-06-07T23:23:56.9262437Z +                report["discovered_patterns"], key=lambda x: x["count"], reverse=True
2025-06-07T23:23:56.9262763Z +            )[:5]
2025-06-07T23:23:56.9262934Z +        ):
2025-06-07T23:23:56.9263095Z +            print(
2025-06-07T23:23:56.9263396Z +                f"{i + 1}. Structure: {pattern['structure']} (appears {pattern['count']} times)"
2025-06-07T23:23:56.9263729Z +            )
2025-06-07T23:23:56.9263947Z              print(f"   Example: {pattern['examples'][0]}")
2025-06-07T23:23:56.9264213Z -    
2025-06-07T23:23:56.9264360Z +
2025-06-07T23:23:56.9264507Z      return 0
2025-06-07T23:23:56.9264671Z  
2025-06-07T23:23:56.9264814Z  
2025-06-07T23:23:56.9265105Z diff --git a/scripts/generate_golden_csvs.py b/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9265477Z index 5e375ac..22ac203 100644
2025-06-07T23:23:56.9265709Z --- a/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9265959Z +++ b/scripts/generate_golden_csvs.py
2025-06-07T23:23:56.9266347Z @@ -14,89 +14,94 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9266603Z  
2025-06-07T23:23:56.9266785Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9267022Z  
2025-06-07T23:23:56.9267167Z +
2025-06-07T23:23:56.9267411Z  def generate_golden_csv(pdf_path: Path, output_dir: Path) -> Path:
2025-06-07T23:23:56.9267757Z      """Generate golden CSV for a single PDF."""
2025-06-07T23:23:56.9268070Z      # Extract the date part from filename for golden CSV name
2025-06-07T23:23:56.9268517Z      pdf_name = pdf_path.stem
2025-06-07T23:23:56.9268822Z -    if '_' in pdf_name:
2025-06-07T23:23:56.9269057Z -        date_part = pdf_name.split('_')[-1]
2025-06-07T23:23:56.9269308Z +    if "_" in pdf_name:
2025-06-07T23:23:56.9269525Z +        date_part = pdf_name.split("_")[-1]
2025-06-07T23:23:56.9269762Z      else:
2025-06-07T23:23:56.9270143Z -        date_part = pdf_name.lower().replace('itau', '').replace('-', '')
2025-06-07T23:23:56.9270458Z -    
2025-06-07T23:23:56.9270700Z +        date_part = pdf_name.lower().replace("itau", "").replace("-", "")
2025-06-07T23:23:56.9271021Z +
2025-06-07T23:23:56.9271202Z      golden_name = f"golden_{date_part}.csv"
2025-06-07T23:23:56.9271464Z      golden_path = output_dir / golden_name
2025-06-07T23:23:56.9271699Z -    
2025-06-07T23:23:56.9271845Z +
2025-06-07T23:23:56.9272064Z      print(f"Generating {golden_name} from {pdf_path.name}")
2025-06-07T23:23:56.9272341Z -    
2025-06-07T23:23:56.9272490Z +
2025-06-07T23:23:56.9272757Z      # Generate CSV using current parser - call directly without file conflicts
2025-06-07T23:23:56.9273093Z      import io
2025-06-07T23:23:56.9273277Z      import contextlib
2025-06-07T23:23:56.9273491Z -    
2025-06-07T23:23:56.9273634Z +
2025-06-07T23:23:56.9273790Z      # Capture output
2025-06-07T23:23:56.9273992Z      buffer = io.StringIO()
2025-06-07T23:23:56.9274234Z      with contextlib.redirect_stdout(buffer):
2025-06-07T23:23:56.9274508Z          pdf_to_csv.main([str(pdf_path)])
2025-06-07T23:23:56.9274767Z -    
2025-06-07T23:23:56.9274922Z +
2025-06-07T23:23:56.9275077Z      # Write to golden file
2025-06-07T23:23:56.9275299Z -    with open(golden_path, 'w') as f:
2025-06-07T23:23:56.9275550Z +    with open(golden_path, "w") as f:
2025-06-07T23:23:56.9275796Z          f.write(buffer.getvalue())
2025-06-07T23:23:56.9276016Z -    
2025-06-07T23:23:56.9276168Z +
2025-06-07T23:23:56.9276552Z      print(f"  â†’ Generated {golden_path.name}")
2025-06-07T23:23:56.9276821Z      return golden_path
2025-06-07T23:23:56.9277004Z  
2025-06-07T23:23:56.9277147Z +
2025-06-07T23:23:56.9277298Z  def main():
2025-06-07T23:23:56.9277596Z      parser = argparse.ArgumentParser(description="Generate golden CSV files")
2025-06-07T23:23:56.9278054Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9278577Z -    parser.add_argument("--output-dir", default="tests/data", 
2025-06-07T23:23:56.9278927Z -                       help="Directory to write golden CSV files")
2025-06-07T23:23:56.9279264Z -    parser.add_argument("--force", action="store_true",
2025-06-07T23:23:56.9279592Z -                       help="Overwrite existing golden files")
2025-06-07T23:23:56.9279856Z +    parser.add_argument(
2025-06-07T23:23:56.9280196Z +        "--output-dir", default="tests/data", help="Directory to write golden CSV files"
2025-06-07T23:23:56.9280551Z +    )
2025-06-07T23:23:56.9280724Z +    parser.add_argument(
2025-06-07T23:23:56.9281022Z +        "--force", action="store_true", help="Overwrite existing golden files"
2025-06-07T23:23:56.9281345Z +    )
2025-06-07T23:23:56.9281522Z      args = parser.parse_args()
2025-06-07T23:23:56.9281731Z -    
2025-06-07T23:23:56.9281883Z +
2025-06-07T23:23:56.9282042Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9282292Z      output_dir = Path(args.output_dir)
2025-06-07T23:23:56.9282527Z -    
2025-06-07T23:23:56.9282678Z +
2025-06-07T23:23:56.9282841Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9283123Z          print(f"Error: PDF directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9283529Z          return 1
2025-06-07T23:23:56.9283698Z -    
2025-06-07T23:23:56.9283844Z +
2025-06-07T23:23:56.9284033Z      output_dir.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9284294Z -    
2025-06-07T23:23:56.9284443Z +
2025-06-07T23:23:56.9284597Z      # Find all PDFs
2025-06-07T23:23:56.9284811Z      pdf_files = list(pdf_dir.glob("*.pdf"))
2025-06-07T23:23:56.9285089Z      print(f"Found {len(pdf_files)} PDF files")
2025-06-07T23:23:56.9285331Z -    
2025-06-07T23:23:56.9285482Z +
2025-06-07T23:23:56.9285631Z      generated = 0
2025-06-07T23:23:56.9285813Z      skipped = 0
2025-06-07T23:23:56.9285987Z -    
2025-06-07T23:23:56.9286132Z +
2025-06-07T23:23:56.9286302Z      for pdf_path in sorted(pdf_files):
2025-06-07T23:23:56.9286563Z          # Check if golden CSV already exists
2025-06-07T23:23:56.9286924Z          pdf_name = pdf_path.stem
2025-06-07T23:23:56.9287154Z -        if '_' in pdf_name:
2025-06-07T23:23:56.9287397Z -            date_part = pdf_name.split('_')[-1]
2025-06-07T23:23:56.9287656Z +        if "_" in pdf_name:
2025-06-07T23:23:56.9287886Z +            date_part = pdf_name.split("_")[-1]
2025-06-07T23:23:56.9288124Z          else:
2025-06-07T23:23:56.9288581Z -            date_part = pdf_name.lower().replace('itau', '').replace('-', '')
2025-06-07T23:23:56.9288898Z -        
2025-06-07T23:23:56.9289139Z +            date_part = pdf_name.lower().replace("itau", "").replace("-", "")
2025-06-07T23:23:56.9289439Z +
2025-06-07T23:23:56.9289619Z          golden_name = f"golden_{date_part}.csv"
2025-06-07T23:23:56.9289893Z          golden_path = output_dir / golden_name
2025-06-07T23:23:56.9290134Z -        
2025-06-07T23:23:56.9290292Z +
2025-06-07T23:23:56.9290482Z          if golden_path.exists() and not args.force:
2025-06-07T23:23:56.9290839Z              print(f"Skipping {pdf_path.name} - {golden_name} already exists")
2025-06-07T23:23:56.9291168Z              skipped += 1
2025-06-07T23:23:56.9291363Z              continue
2025-06-07T23:23:56.9291551Z -        
2025-06-07T23:23:56.9291704Z +
2025-06-07T23:23:56.9291851Z          try:
2025-06-07T23:23:56.9292064Z              generate_golden_csv(pdf_path, output_dir)
2025-06-07T23:23:56.9292328Z              generated += 1
2025-06-07T23:23:56.9292545Z          except Exception as e:
2025-06-07T23:23:56.9292824Z              print(f"Error generating CSV for {pdf_path.name}: {e}")
2025-06-07T23:23:56.9293112Z -    
2025-06-07T23:23:56.9293264Z +
2025-06-07T23:23:56.9293420Z      print("\nSummary:")
2025-06-07T23:23:56.9293641Z      print(f"  Generated: {generated}")
2025-06-07T23:23:56.9293896Z      print(f"  Skipped: {skipped}")
2025-06-07T23:23:56.9294155Z      print(f"  Total PDFs: {len(pdf_files)}")
2025-06-07T23:23:56.9294389Z -    
2025-06-07T23:23:56.9294533Z +
2025-06-07T23:23:56.9294681Z      return 0
2025-06-07T23:23:56.9294847Z  
2025-06-07T23:23:56.9294988Z +
2025-06-07T23:23:56.9295153Z  if __name__ == "__main__":
2025-06-07T23:23:56.9295356Z      sys.exit(main())
2025-06-07T23:23:56.9295685Z diff --git a/scripts/incremental_learner.py b/scripts/incremental_learner.py
2025-06-07T23:23:56.9296050Z index a335e17..9e85598 100644
2025-06-07T23:23:56.9296277Z --- a/scripts/incremental_learner.py
2025-06-07T23:23:56.9296531Z +++ b/scripts/incremental_learner.py
2025-06-07T23:23:56.9296805Z @@ -19,7 +19,7 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9297063Z  
2025-06-07T23:23:56.9297233Z  class IncrementalLearner:
2025-06-07T23:23:56.9297535Z      """Learns from validation feedback to improve parsing patterns."""
2025-06-07T23:23:56.9297844Z -    
2025-06-07T23:23:56.9297995Z +
2025-06-07T23:23:56.9298145Z      def __init__(self):
2025-06-07T23:23:56.9298460Z          self.learned_patterns = []
2025-06-07T23:23:56.9298705Z          self.pattern_confidence = {}
2025-06-07T23:23:56.9298963Z @@ -28,77 +28,81 @@ class IncrementalLearner:
2025-06-07T23:23:56.9299232Z              "initial_success_rate": 0.0,
2025-06-07T23:23:56.9299487Z              "current_success_rate": 0.0,
2025-06-07T23:23:56.9299856Z              "patterns_added": 0,
2025-06-07T23:23:56.9300092Z -            "transactions_recovered": 0
2025-06-07T23:23:56.9300342Z +            "transactions_recovered": 0,
2025-06-07T23:23:56.9300569Z          }
2025-06-07T23:23:56.9300730Z -    
2025-06-07T23:23:56.9301066Z -    def analyze_missing_transactions(self, pdf_path: Path, validation_results: Dict) -> List[Dict]:
2025-06-07T23:23:56.9301465Z +
2025-06-07T23:23:56.9301638Z +    def analyze_missing_transactions(
2025-06-07T23:23:56.9301918Z +        self, pdf_path: Path, validation_results: Dict
2025-06-07T23:23:56.9302186Z +    ) -> List[Dict]:
2025-06-07T23:23:56.9302455Z          """Analyze missing transactions to discover new patterns."""
2025-06-07T23:23:56.9302746Z -        
2025-06-07T23:23:56.9302907Z +
2025-06-07T23:23:56.9303191Z          missing_lines = validation_results["missing_transactions"]["missing_lines"]
2025-06-07T23:23:56.9303713Z          new_patterns = []
2025-06-07T23:23:56.9303914Z -        
2025-06-07T23:23:56.9304074Z +
2025-06-07T23:23:56.9304246Z          # Group similar missing lines
2025-06-07T23:23:56.9304507Z          pattern_groups = defaultdict(list)
2025-06-07T23:23:56.9304741Z -        
2025-06-07T23:23:56.9304893Z +
2025-06-07T23:23:56.9305060Z          for missing in missing_lines:
2025-06-07T23:23:56.9305318Z              if missing["confidence"] == "high":
2025-06-07T23:23:56.9305594Z                  line = missing["line_content"]
2025-06-07T23:23:56.9305834Z -                
2025-06-07T23:23:56.9306005Z +
2025-06-07T23:23:56.9306184Z                  # Create structural signature
2025-06-07T23:23:56.9306479Z                  structure = self._create_structure_signature(line)
2025-06-07T23:23:56.9306805Z                  pattern_groups[structure].append(line)
2025-06-07T23:23:56.9307058Z -        
2025-06-07T23:23:56.9307218Z +
2025-06-07T23:23:56.9307430Z          # Generate patterns for groups with multiple examples
2025-06-07T23:23:56.9307771Z          for structure, examples in pattern_groups.items():
2025-06-07T23:23:56.9308107Z              if len(examples) >= 2:  # Need at least 2 examples
2025-06-07T23:23:56.9308634Z                  pattern = self._generate_pattern_from_examples(structure, examples)
2025-06-07T23:23:56.9309054Z                  if pattern:
2025-06-07T23:23:56.9309294Z                      new_patterns.append(pattern)
2025-06-07T23:23:56.9309540Z -        
2025-06-07T23:23:56.9309698Z +
2025-06-07T23:23:56.9309859Z          return new_patterns
2025-06-07T23:23:56.9310062Z -    
2025-06-07T23:23:56.9310217Z +
2025-06-07T23:23:56.9310443Z      def _create_structure_signature(self, line: str) -> str:
2025-06-07T23:23:56.9310801Z          """Create a structural signature for pattern matching."""
2025-06-07T23:23:56.9311131Z          # Replace specific patterns with placeholders
2025-06-07T23:23:56.9311399Z          sig = line
2025-06-07T23:23:56.9311587Z -        
2025-06-07T23:23:56.9311742Z +
2025-06-07T23:23:56.9311900Z          # Replace amounts
2025-06-07T23:23:56.9312168Z -        sig = re.sub(r'\d{1,3}(?:\.\d{3})*,\d{2}', 'AMOUNT', sig)
2025-06-07T23:23:56.9312440Z -        
2025-06-07T23:23:56.9312648Z +        sig = re.sub(r"\d{1,3}(?:\.\d{3})*,\d{2}", "AMOUNT", sig)
2025-06-07T23:23:56.9312907Z +
2025-06-07T23:23:56.9313067Z          # Replace dates
2025-06-07T23:23:56.9313300Z -        sig = re.sub(r'\d{1,2}/\d{1,2}', 'DATE', sig)
2025-06-07T23:23:56.9313549Z -        
2025-06-07T23:23:56.9313736Z +        sig = re.sub(r"\d{1,2}/\d{1,2}", "DATE", sig)
2025-06-07T23:23:56.9313980Z +
2025-06-07T23:23:56.9314143Z          # Replace card numbers
2025-06-07T23:23:56.9314378Z -        sig = re.sub(r'\d{4}', 'CARD', sig)
2025-06-07T23:23:56.9314610Z -        
2025-06-07T23:23:56.9314788Z +        sig = re.sub(r"\d{4}", "CARD", sig)
2025-06-07T23:23:56.9315020Z +
2025-06-07T23:23:56.9315193Z          # Replace long number sequences
2025-06-07T23:23:56.9315464Z -        sig = re.sub(r'\d{4,}', 'LONGNUM', sig)
2025-06-07T23:23:56.9315705Z -        
2025-06-07T23:23:56.9316023Z +        sig = re.sub(r"\d{4,}", "LONGNUM", sig)
2025-06-07T23:23:56.9316257Z +
2025-06-07T23:23:56.9316419Z          # Replace remaining numbers
2025-06-07T23:23:56.9316661Z -        sig = re.sub(r'\d+', 'NUM', sig)
2025-06-07T23:23:56.9316889Z -        
2025-06-07T23:23:56.9317063Z +        sig = re.sub(r"\d+", "NUM", sig)
2025-06-07T23:23:56.9317289Z +
2025-06-07T23:23:56.9317454Z          # Normalize whitespace
2025-06-07T23:23:56.9317691Z -        sig = re.sub(r'\s+', ' ', sig).strip()
2025-06-07T23:23:56.9317933Z -        
2025-06-07T23:23:56.9318105Z +        sig = re.sub(r"\s+", " ", sig).strip()
2025-06-07T23:23:56.9318571Z +
2025-06-07T23:23:56.9318728Z          return sig
2025-06-07T23:23:56.9318906Z -    
2025-06-07T23:23:56.9319256Z -    def _generate_pattern_from_examples(self, structure: str, examples: List[str]) -> Optional[Dict]:
2025-06-07T23:23:56.9319780Z +
2025-06-07T23:23:56.9319953Z +    def _generate_pattern_from_examples(
2025-06-07T23:23:56.9320225Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9320497Z +    ) -> Optional[Dict]:
2025-06-07T23:23:56.9320776Z          """Generate regex pattern from structure and examples."""
2025-06-07T23:23:56.9321061Z -        
2025-06-07T23:23:56.9321216Z +
2025-06-07T23:23:56.9321418Z          # Analyze the examples to understand the pattern
2025-06-07T23:23:56.9321698Z          if not examples:
2025-06-07T23:23:56.9321897Z              return None
2025-06-07T23:23:56.9322090Z -        
2025-06-07T23:23:56.9322242Z +
2025-06-07T23:23:56.9322427Z          # Common pattern types we can recognize
2025-06-07T23:23:56.9322769Z          pattern_info = self._classify_pattern_type(structure, examples)
2025-06-07T23:23:56.9323094Z          if not pattern_info:
2025-06-07T23:23:56.9323314Z              return None
2025-06-07T23:23:56.9323504Z -        
2025-06-07T23:23:56.9323665Z +
2025-06-07T23:23:56.9323874Z          # Generate appropriate regex based on pattern type
2025-06-07T23:23:56.9324240Z          regex_pattern = self._build_regex_pattern(pattern_info, examples)
2025-06-07T23:23:56.9324569Z          if not regex_pattern:
2025-06-07T23:23:56.9324786Z              return None
2025-06-07T23:23:56.9324974Z -        
2025-06-07T23:23:56.9325125Z +
2025-06-07T23:23:56.9325273Z          return {
2025-06-07T23:23:56.9325472Z              "name": pattern_info["name"],
2025-06-07T23:23:56.9325718Z              "regex": regex_pattern,
2025-06-07T23:23:56.9325978Z @@ -106,141 +110,155 @@ class IncrementalLearner:
2025-06-07T23:23:56.9326253Z              "examples": examples[:3],
2025-06-07T23:23:56.9326561Z              "confidence": self._calculate_pattern_confidence(examples),
2025-06-07T23:23:56.9326892Z              "handler": pattern_info["handler"],
2025-06-07T23:23:56.9327177Z -            "description": pattern_info["description"]
2025-06-07T23:23:56.9327474Z +            "description": pattern_info["description"],
2025-06-07T23:23:56.9327734Z          }
2025-06-07T23:23:56.9327890Z -    
2025-06-07T23:23:56.9328207Z -    def _classify_pattern_type(self, structure: str, examples: List[str]) -> Optional[Dict]:
2025-06-07T23:23:56.9328984Z +
2025-06-07T23:23:56.9329183Z +    def _classify_pattern_type(
2025-06-07T23:23:56.9329454Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9329726Z +    ) -> Optional[Dict]:
2025-06-07T23:23:56.9330029Z          """Classify the type of pattern based on structure and content."""
2025-06-07T23:23:56.9330348Z -        
2025-06-07T23:23:56.9330508Z +
2025-06-07T23:23:56.9330690Z          first_example = examples[0].upper()
2025-06-07T23:23:56.9330920Z -        
2025-06-07T23:23:56.9331074Z +
2025-06-07T23:23:56.9331265Z          # Transaction with embedded date and amount
2025-06-07T23:23:56.9331574Z          if "DATE" in structure and "AMOUNT" in structure:
2025-06-07T23:23:56.9331957Z              if any(word in first_example for word in ["COMPRA", "VENDA", "PAGAMENTO"]):
2025-06-07T23:23:56.9332306Z                  return {
2025-06-07T23:23:56.9332537Z                      "name": "transaction_with_date",
2025-06-07T23:23:56.9332982Z                      "handler": "parse_transaction",
2025-06-07T23:23:56.9333290Z -                    "description": "Transaction with date and amount"
2025-06-07T23:23:56.9333628Z +                    "description": "Transaction with date and amount",
2025-06-07T23:23:56.9333908Z                  }
2025-06-07T23:23:56.9334084Z -        
2025-06-07T23:23:56.9334244Z +
2025-06-07T23:23:56.9334410Z          # Fee or charge line
2025-06-07T23:23:56.9334807Z -        if "AMOUNT" in structure and any(word in first_example for word in ["TAXA", "TARIFA", "JUROS", "MULTA"]):
2025-06-07T23:23:56.9335244Z +        if "AMOUNT" in structure and any(
2025-06-07T23:23:56.9335624Z +            word in first_example for word in ["TAXA", "TARIFA", "JUROS", "MULTA"]
2025-06-07T23:23:56.9335951Z +        ):
2025-06-07T23:23:56.9336227Z              return {
2025-06-07T23:23:56.9336431Z                  "name": "fee_charge",
2025-06-07T23:23:56.9336674Z                  "handler": "parse_fee",
2025-06-07T23:23:56.9336936Z -                "description": "Fee or charge line"
2025-06-07T23:23:56.9337211Z +                "description": "Fee or charge line",
2025-06-07T23:23:56.9337453Z              }
2025-06-07T23:23:56.9337618Z -        
2025-06-07T23:23:56.9337770Z +
2025-06-07T23:23:56.9337931Z          # Installment information
2025-06-07T23:23:56.9338199Z          if "/" in structure and "AMOUNT" in structure:
2025-06-07T23:23:56.9338755Z              if any(word in first_example for word in ["PARCELA", "PARC"]):
2025-06-07T23:23:56.9339062Z                  return {
2025-06-07T23:23:56.9339279Z                      "name": "installment_info",
2025-06-07T23:23:56.9339546Z                      "handler": "parse_installment",
2025-06-07T23:23:56.9339850Z -                    "description": "Installment payment information"
2025-06-07T23:23:56.9340189Z +                    "description": "Installment payment information",
2025-06-07T23:23:56.9340460Z                  }
2025-06-07T23:23:56.9340631Z -        
2025-06-07T23:23:56.9340787Z +
2025-06-07T23:23:56.9340965Z          # International transaction details
2025-06-07T23:23:56.9341356Z -        if "AMOUNT" in structure and any(word in first_example for word in ["USD", "EUR", "DOLAR"]):
2025-06-07T23:23:56.9341752Z +        if "AMOUNT" in structure and any(
2025-06-07T23:23:56.9342050Z +            word in first_example for word in ["USD", "EUR", "DOLAR"]
2025-06-07T23:23:56.9342335Z +        ):
2025-06-07T23:23:56.9342503Z              return {
2025-06-07T23:23:56.9342717Z                  "name": "international_detail",
2025-06-07T23:23:56.9342988Z                  "handler": "parse_international",
2025-06-07T23:23:56.9343304Z -                "description": "International transaction details"
2025-06-07T23:23:56.9343655Z +                "description": "International transaction details",
2025-06-07T23:23:56.9343938Z              }
2025-06-07T23:23:56.9344106Z -        
2025-06-07T23:23:56.9344263Z +
2025-06-07T23:23:56.9344441Z          # Generic transaction with amount
2025-06-07T23:23:56.9344751Z          if "AMOUNT" in structure and len(structure.split()) >= 3:
2025-06-07T23:23:56.9345033Z              return {
2025-06-07T23:23:56.9345248Z                  "name": "generic_transaction",
2025-06-07T23:23:56.9345514Z                  "handler": "parse_generic",
2025-06-07T23:23:56.9345805Z -                "description": "Generic transaction pattern"
2025-06-07T23:23:56.9346124Z +                "description": "Generic transaction pattern",
2025-06-07T23:23:56.9346387Z              }
2025-06-07T23:23:56.9346552Z -        
2025-06-07T23:23:56.9346713Z +
2025-06-07T23:23:56.9346866Z          return None
2025-06-07T23:23:56.9347046Z -    
2025-06-07T23:23:56.9347359Z -    def _build_regex_pattern(self, pattern_info: Dict, examples: List[str]) -> Optional[str]:
2025-06-07T23:23:56.9347747Z +
2025-06-07T23:23:56.9347914Z +    def _build_regex_pattern(
2025-06-07T23:23:56.9348174Z +        self, pattern_info: Dict, examples: List[str]
2025-06-07T23:23:56.9348750Z +    ) -> Optional[str]:
2025-06-07T23:23:56.9349021Z          """Build regex pattern from classified pattern type."""
2025-06-07T23:23:56.9349300Z -        
2025-06-07T23:23:56.9349448Z +
2025-06-07T23:23:56.9349624Z          pattern_type = pattern_info["name"]
2025-06-07T23:23:56.9349859Z -        
2025-06-07T23:23:56.9350010Z +
2025-06-07T23:23:56.9350200Z          if pattern_type == "transaction_with_date":
2025-06-07T23:23:56.9350484Z              # Pattern: DATE DESCRIPTION AMOUNT
2025-06-07T23:23:56.9350985Z              return r"^(?P<date>\d{1,2}/\d{1,2})\s+(?P<desc>.+?)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+.*)?$"
2025-06-07T23:23:56.9351529Z -        
2025-06-07T23:23:56.9351787Z +
2025-06-07T23:23:56.9352079Z          elif pattern_type == "fee_charge":
2025-06-07T23:23:56.9352515Z              # Pattern: DESCRIPTION AMOUNT
2025-06-07T23:23:56.9353350Z              return r"^(?P<desc>(?i)(?:taxa|tarifa|juros|multa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9353962Z -        
2025-06-07T23:23:56.9354221Z +
2025-06-07T23:23:56.9354521Z          elif pattern_type == "installment_info":
2025-06-07T23:23:56.9355012Z              # Pattern: DESCRIPTION XX/YY AMOUNT
2025-06-07T23:23:56.9355902Z              return r"^(?P<desc>.+?)\s+(?P<installment>\d{1,2}/\d{1,2})\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9356521Z -        
2025-06-07T23:23:56.9356691Z +
2025-06-07T23:23:56.9356899Z          elif pattern_type == "international_detail":
2025-06-07T23:23:56.9357311Z              # Pattern: DESCRIPTION CURRENCY AMOUNT
2025-06-07T23:23:56.9357759Z              return r"^(?P<desc>.+?)\s+(?P<currency>USD|EUR|GBP)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9358205Z -        
2025-06-07T23:23:56.9358548Z +
2025-06-07T23:23:56.9358758Z          elif pattern_type == "generic_transaction":
2025-06-07T23:23:56.9359120Z              # Pattern: Any line with amount that looks like a transaction
2025-06-07T23:23:56.9359512Z              return r"^(?P<desc>.+?)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+.*)?$"
2025-06-07T23:23:56.9360060Z -        
2025-06-07T23:23:56.9376275Z +
2025-06-07T23:23:56.9376472Z          return None
2025-06-07T23:23:56.9376674Z -    
2025-06-07T23:23:56.9376833Z +
2025-06-07T23:23:56.9377109Z      def _calculate_pattern_confidence(self, examples: List[str]) -> float:
2025-06-07T23:23:56.9377545Z          """Calculate confidence score for a pattern based on examples."""
2025-06-07T23:23:56.9377939Z          # Base confidence on number of examples and consistency
2025-06-07T23:23:56.9378504Z          base_confidence = min(0.9, 0.3 + 0.1 * len(examples))
2025-06-07T23:23:56.9378807Z -        
2025-06-07T23:23:56.9378975Z +
2025-06-07T23:23:56.9379155Z          # Check consistency in structure
2025-06-07T23:23:56.9379509Z          structures = [self._create_structure_signature(ex) for ex in examples]
2025-06-07T23:23:56.9379914Z          if len(set(structures)) == 1:  # All have same structure
2025-06-07T23:23:56.9380211Z              base_confidence += 0.1
2025-06-07T23:23:56.9380432Z -        
2025-06-07T23:23:56.9380588Z +
2025-06-07T23:23:56.9380764Z          # Check for transaction indicators
2025-06-07T23:23:56.9381109Z          transaction_keywords = ["COMPRA", "VENDA", "PAGAMENTO", "PARCELA"]
2025-06-07T23:23:56.9381541Z          if any(kw in " ".join(examples).upper() for kw in transaction_keywords):
2025-06-07T23:23:56.9381872Z              base_confidence += 0.1
2025-06-07T23:23:56.9382096Z -        
2025-06-07T23:23:56.9382255Z +
2025-06-07T23:23:56.9382425Z          return min(1.0, base_confidence)
2025-06-07T23:23:56.9382661Z -    
2025-06-07T23:23:56.9382819Z +
2025-06-07T23:23:56.9383099Z      def generate_enhanced_patterns(self, pdf_paths: List[Path]) -> List[Dict]:
2025-06-07T23:23:56.9383505Z          """Generate enhanced patterns from multiple PDFs."""
2025-06-07T23:23:56.9383785Z -        
2025-06-07T23:23:56.9383940Z +
2025-06-07T23:23:56.9384101Z          all_patterns = []
2025-06-07T23:23:56.9384483Z -        
2025-06-07T23:23:56.9384638Z +
2025-06-07T23:23:56.9384809Z          for pdf_path in pdf_paths:
2025-06-07T23:23:56.9385083Z              print(f"Learning from {pdf_path.name}...")
2025-06-07T23:23:56.9385342Z -            
2025-06-07T23:23:56.9385506Z +
2025-06-07T23:23:56.9385702Z              # Run validation to get missing transactions
2025-06-07T23:23:56.9385981Z              import importlib.util
2025-06-07T23:23:56.9386321Z -            spec = importlib.util.spec_from_file_location("semantic_validator", 
2025-06-07T23:23:56.9386715Z -                                                         ROOT / "scripts" / "semantic_validator.py")
2025-06-07T23:23:56.9387003Z +
2025-06-07T23:23:56.9387210Z +            spec = importlib.util.spec_from_file_location(
2025-06-07T23:23:56.9387580Z +                "semantic_validator", ROOT / "scripts" / "semantic_validator.py"
2025-06-07T23:23:56.9388004Z +            )
2025-06-07T23:23:56.9388450Z              semantic_validator = importlib.util.module_from_spec(spec)
2025-06-07T23:23:56.9388822Z              spec.loader.exec_module(semantic_validator)
2025-06-07T23:23:56.9389079Z -            
2025-06-07T23:23:56.9389248Z +
2025-06-07T23:23:56.9389465Z              validator = semantic_validator.SemanticValidator()
2025-06-07T23:23:56.9389838Z              validation_results = validator.validate_pdf_parsing(pdf_path)
2025-06-07T23:23:56.9390148Z -            
2025-06-07T23:23:56.9390310Z +
2025-06-07T23:23:56.9390485Z              # Analyze missing transactions
2025-06-07T23:23:56.9390848Z              patterns = self.analyze_missing_transactions(pdf_path, validation_results)
2025-06-07T23:23:56.9391224Z              all_patterns.extend(patterns)
2025-06-07T23:23:56.9391461Z -            
2025-06-07T23:23:56.9391615Z +
2025-06-07T23:23:56.9391775Z              # Track metrics
2025-06-07T23:23:56.9392025Z              file_info = validation_results["file_info"]
2025-06-07T23:23:56.9392423Z -            success_rate = file_info["parsed_transactions"] / max(1, file_info["total_lines"])
2025-06-07T23:23:56.9392864Z +            success_rate = file_info["parsed_transactions"] / max(
2025-06-07T23:23:56.9393167Z +                1, file_info["total_lines"]
2025-06-07T23:23:56.9393400Z +            )
2025-06-07T23:23:56.9393626Z              print(f"  Current success rate: {success_rate:.1%}")
2025-06-07T23:23:56.9393950Z              print(f"  Found {len(patterns)} new patterns")
2025-06-07T23:23:56.9394205Z -        
2025-06-07T23:23:56.9394359Z +
2025-06-07T23:23:56.9394536Z          # Deduplicate and rank patterns
2025-06-07T23:23:56.9394848Z          unique_patterns = self._deduplicate_patterns(all_patterns)
2025-06-07T23:23:56.9395307Z -        ranked_patterns = sorted(unique_patterns, key=lambda p: p["confidence"], reverse=True)
2025-06-07T23:23:56.9395691Z -        
2025-06-07T23:23:56.9395875Z +        ranked_patterns = sorted(
2025-06-07T23:23:56.9396182Z +            unique_patterns, key=lambda p: p["confidence"], reverse=True
2025-06-07T23:23:56.9396494Z +        )
2025-06-07T23:23:56.9396646Z +
2025-06-07T23:23:56.9396810Z          return ranked_patterns
2025-06-07T23:23:56.9397019Z -    
2025-06-07T23:23:56.9397171Z +
2025-06-07T23:23:56.9397423Z      def _deduplicate_patterns(self, patterns: List[Dict]) -> List[Dict]:
2025-06-07T23:23:56.9397811Z          """Remove duplicate patterns and merge similar ones."""
2025-06-07T23:23:56.9398112Z          unique_patterns = []
2025-06-07T23:23:56.9398492Z          seen_structures = set()
2025-06-07T23:23:56.9398707Z -        
2025-06-07T23:23:56.9398861Z +
2025-06-07T23:23:56.9399026Z          for pattern in patterns:
2025-06-07T23:23:56.9399275Z              structure = pattern["structure"]
2025-06-07T23:23:56.9399548Z              if structure not in seen_structures:
2025-06-07T23:23:56.9399831Z @@ -251,19 +269,23 @@ class IncrementalLearner:
2025-06-07T23:23:56.9400114Z                  for existing in unique_patterns:
2025-06-07T23:23:56.9400395Z                      if existing["structure"] == structure:
2025-06-07T23:23:56.9400833Z                          existing["examples"].extend(pattern["examples"])
2025-06-07T23:23:56.9401209Z -                        existing["examples"] = existing["examples"][:5]  # Keep only top 5
2025-06-07T23:23:56.9401582Z +                        existing["examples"] = existing["examples"][
2025-06-07T23:23:56.9401853Z +                            :5
2025-06-07T23:23:56.9402074Z +                        ]  # Keep only top 5
2025-06-07T23:23:56.9402350Z                          # Update confidence based on more examples
2025-06-07T23:23:56.9402740Z -                        existing["confidence"] = max(existing["confidence"], pattern["confidence"])
2025-06-07T23:23:56.9403134Z +                        existing["confidence"] = max(
2025-06-07T23:23:56.9403437Z +                            existing["confidence"], pattern["confidence"]
2025-06-07T23:23:56.9403829Z +                        )
2025-06-07T23:23:56.9404024Z                          break
2025-06-07T23:23:56.9404226Z -        
2025-06-07T23:23:56.9404382Z +
2025-06-07T23:23:56.9404550Z          return unique_patterns
2025-06-07T23:23:56.9404755Z -    
2025-06-07T23:23:56.9404908Z +
2025-06-07T23:23:56.9405174Z      def generate_pattern_implementation(self, patterns: List[Dict]) -> str:
2025-06-07T23:23:56.9405608Z          """Generate Python code to implement the learned patterns."""
2025-06-07T23:23:56.9405898Z -        
2025-06-07T23:23:56.9406054Z +
2025-06-07T23:23:56.9406239Z          # Filter high-confidence patterns
2025-06-07T23:23:56.9406609Z          high_confidence_patterns = [p for p in patterns if p["confidence"] >= 0.6]
2025-06-07T23:23:56.9406958Z -        
2025-06-07T23:23:56.9407115Z +
2025-06-07T23:23:56.9407265Z          code = '''
2025-06-07T23:23:56.9407483Z  # ===== LEARNED PATTERNS (Auto-generated) =====
2025-06-07T23:23:56.9407744Z  
2025-06-07T23:23:56.9407935Z @@ -278,16 +300,16 @@ from decimal import Decimal
2025-06-07T23:23:56.9408193Z  import hashlib
2025-06-07T23:23:56.9408543Z  
2025-06-07T23:23:56.9408705Z  '''
2025-06-07T23:23:56.9408863Z -        
2025-06-07T23:23:56.9409027Z +
2025-06-07T23:23:56.9409194Z          # Generate regex constants
2025-06-07T23:23:56.9409511Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9409882Z              const_name = f"RE_LEARNED_{pattern['name'].upper()}_{i}"
2025-06-07T23:23:56.9410185Z              code += f'''
2025-06-07T23:23:56.9410490Z -# {pattern['description']} (confidence: {pattern['confidence']:.1%})
2025-06-07T23:23:56.9410913Z -# Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}
2025-06-07T23:23:56.9411300Z -{const_name}: Final = re.compile(r"{pattern['regex']}")
2025-06-07T23:23:56.9411676Z +# {pattern["description"]} (confidence: {pattern["confidence"]:.1%})
2025-06-07T23:23:56.9412084Z +# Example: {pattern["examples"][0] if pattern["examples"] else "N/A"}
2025-06-07T23:23:56.9412462Z +{const_name}: Final = re.compile(r"{pattern["regex"]}")
2025-06-07T23:23:56.9412731Z  '''
2025-06-07T23:23:56.9412892Z -        
2025-06-07T23:23:56.9413052Z +
2025-06-07T23:23:56.9413210Z          code += '''
2025-06-07T23:23:56.9413394Z  
2025-06-07T23:23:56.9413669Z  def parse_with_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9414168Z @@ -298,28 +320,28 @@ def parse_with_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9414543Z      if not line:
2025-06-07T23:23:56.9414722Z          return None
2025-06-07T23:23:56.9414919Z  '''
2025-06-07T23:23:56.9415072Z -        
2025-06-07T23:23:56.9415228Z +
2025-06-07T23:23:56.9415403Z          # Generate pattern matching code
2025-06-07T23:23:56.9415720Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9416077Z              const_name = f"RE_LEARNED_{pattern['name'].upper()}_{i}"
2025-06-07T23:23:56.9416447Z              handler_name = f"_handle_learned_{pattern['handler']}_{i}"
2025-06-07T23:23:56.9416736Z -            
2025-06-07T23:23:56.9416912Z -            code += f'''
2025-06-07T23:23:56.9417237Z +
2025-06-07T23:23:56.9417393Z +            code += f"""
2025-06-07T23:23:56.9417583Z      
2025-06-07T23:23:56.9417762Z -    # {pattern['description']}
2025-06-07T23:23:56.9417998Z +    # {pattern["description"]}
2025-06-07T23:23:56.9418221Z      m = {const_name}.match(line)
2025-06-07T23:23:56.9418614Z      if m:
2025-06-07T23:23:56.9418830Z          return {handler_name}(m, original_line, year)
2025-06-07T23:23:56.9419090Z -'''
2025-06-07T23:23:56.9419243Z -        
2025-06-07T23:23:56.9419399Z +"""
2025-06-07T23:23:56.9419544Z +
2025-06-07T23:23:56.9419710Z          # Generate handler functions
2025-06-07T23:23:56.9420009Z          for i, pattern in enumerate(high_confidence_patterns):
2025-06-07T23:23:56.9420366Z              handler_name = f"_handle_learned_{pattern['handler']}_{i}"
2025-06-07T23:23:56.9420788Z -            
2025-06-07T23:23:56.9420956Z +
2025-06-07T23:23:56.9421118Z              code += f'''
2025-06-07T23:23:56.9421315Z  
2025-06-07T23:23:56.9421564Z  def {handler_name}(m, original_line: str, year: int = None) -> dict:
2025-06-07T23:23:56.9421905Z -    """Handle {pattern['description']}"""
2025-06-07T23:23:56.9422175Z +    """Handle {pattern["description"]}"""
2025-06-07T23:23:56.9422427Z      from datetime import date
2025-06-07T23:23:56.9422640Z      
2025-06-07T23:23:56.9422833Z      # Extract common fields with error handling
2025-06-07T23:23:56.9423204Z @@ -364,7 +386,7 @@ def {handler_name}(m, original_line: str, year: int = None) -> dict:
2025-06-07T23:23:56.9423595Z          # If parsing fails, return None to skip this line
2025-06-07T23:23:56.9423863Z          return None
2025-06-07T23:23:56.9424042Z  '''
2025-06-07T23:23:56.9424189Z -        
2025-06-07T23:23:56.9424346Z +
2025-06-07T23:23:56.9424496Z          code += '''
2025-06-07T23:23:56.9424673Z  
2025-06-07T23:23:56.9424853Z  # Integration function for main parser
2025-06-07T23:23:56.9425279Z @@ -372,76 +394,86 @@ def try_learned_patterns(line: str, year: int = None) -> dict | None:
2025-06-07T23:23:56.9425691Z      """Try all learned patterns in order of confidence."""
2025-06-07T23:23:56.9426011Z      return parse_with_learned_patterns(line, year)
2025-06-07T23:23:56.9426291Z  '''
2025-06-07T23:23:56.9426453Z -        
2025-06-07T23:23:56.9426603Z +
2025-06-07T23:23:56.9426756Z          return code
2025-06-07T23:23:56.9426931Z  
2025-06-07T23:23:56.9427076Z  
2025-06-07T23:23:56.9427224Z  def main():
2025-06-07T23:23:56.9427581Z -    parser = argparse.ArgumentParser(description="Incremental learning for parser improvement")
2025-06-07T23:23:56.9428023Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9428495Z +        description="Incremental learning for parser improvement"
2025-06-07T23:23:56.9428801Z +    )
2025-06-07T23:23:56.9429099Z      parser.add_argument("pdf_dir", help="Directory containing PDF files to learn from")
2025-06-07T23:23:56.9429541Z -    parser.add_argument("--output-dir", default="diagnostics", 
2025-06-07T23:23:56.9429881Z -                       help="Directory to save learning results")
2025-06-07T23:23:56.9430208Z -    parser.add_argument("--limit", type=int, default=5,
2025-06-07T23:23:56.9430521Z -                       help="Limit number of PDFs to process")
2025-06-07T23:23:56.9430795Z +    parser.add_argument(
2025-06-07T23:23:56.9431133Z +        "--output-dir", default="diagnostics", help="Directory to save learning results"
2025-06-07T23:23:56.9431482Z +    )
2025-06-07T23:23:56.9431649Z +    parser.add_argument(
2025-06-07T23:23:56.9431941Z +        "--limit", type=int, default=5, help="Limit number of PDFs to process"
2025-06-07T23:23:56.9432256Z +    )
2025-06-07T23:23:56.9432431Z      args = parser.parse_args()
2025-06-07T23:23:56.9432643Z -    
2025-06-07T23:23:56.9432794Z +
2025-06-07T23:23:56.9432963Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9433209Z      output_dir = Path(args.output_dir)
2025-06-07T23:23:56.9433450Z -    
2025-06-07T23:23:56.9433597Z +
2025-06-07T23:23:56.9433764Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9434170Z          print(f"Error: PDF directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9434456Z          return 1
2025-06-07T23:23:56.9434627Z -    
2025-06-07T23:23:56.9434776Z +
2025-06-07T23:23:56.9434967Z      output_dir.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9435220Z -    
2025-06-07T23:23:56.9435371Z +
2025-06-07T23:23:56.9435540Z      # Get PDF files to learn from
2025-06-07T23:23:56.9435850Z -    pdf_files = list(pdf_dir.glob("*.pdf"))[:args.limit]
2025-06-07T23:23:56.9436179Z +    pdf_files = list(pdf_dir.glob("*.pdf"))[: args.limit]
2025-06-07T23:23:56.9436455Z      if not pdf_files:
2025-06-07T23:23:56.9436661Z          print("No PDF files found")
2025-06-07T23:23:56.9436883Z          return 1
2025-06-07T23:23:56.9437046Z -    
2025-06-07T23:23:56.9437195Z +
2025-06-07T23:23:56.9437400Z      print(f"Learning from {len(pdf_files)} PDF files...")
2025-06-07T23:23:56.9437819Z -    
2025-06-07T23:23:56.9437964Z +
2025-06-07T23:23:56.9438132Z      learner = IncrementalLearner()
2025-06-07T23:23:56.9438596Z      patterns = learner.generate_enhanced_patterns(pdf_files)
2025-06-07T23:23:56.9438887Z -    
2025-06-07T23:23:56.9439031Z +
2025-06-07T23:23:56.9439193Z      # Save learning results
2025-06-07T23:23:56.9439403Z      results = {
2025-06-07T23:23:56.9439610Z          "timestamp": str(Path().absolute()),
2025-06-07T23:23:56.9439899Z          "pdfs_processed": [p.name for p in pdf_files],
2025-06-07T23:23:56.9440187Z          "patterns_discovered": len(patterns),
2025-06-07T23:23:56.9440568Z -        "high_confidence_patterns": len([p for p in patterns if p["confidence"] >= 0.6]),
2025-06-07T23:23:56.9440951Z +        "high_confidence_patterns": len(
2025-06-07T23:23:56.9441235Z +            [p for p in patterns if p["confidence"] >= 0.6]
2025-06-07T23:23:56.9441497Z +        ),
2025-06-07T23:23:56.9441678Z          "patterns": patterns,
2025-06-07T23:23:56.9442007Z -        "implementation": learner.generate_pattern_implementation(patterns)
2025-06-07T23:23:56.9442447Z +        "implementation": learner.generate_pattern_implementation(patterns),
2025-06-07T23:23:56.9442777Z      }
2025-06-07T23:23:56.9442931Z -    
2025-06-07T23:23:56.9443081Z +
2025-06-07T23:23:56.9443243Z      # Save JSON report
2025-06-07T23:23:56.9443484Z      report_file = output_dir / "learning_results.json"
2025-06-07T23:23:56.9443768Z -    with open(report_file, 'w') as f:
2025-06-07T23:23:56.9444022Z +    with open(report_file, "w") as f:
2025-06-07T23:23:56.9444290Z          json.dump(results, f, indent=2, default=str)
2025-06-07T23:23:56.9444549Z -    
2025-06-07T23:23:56.9444699Z +
2025-06-07T23:23:56.9444868Z      # Save Python implementation
2025-06-07T23:23:56.9445137Z      impl_file = output_dir / "learned_patterns.py"
2025-06-07T23:23:56.9445410Z -    with open(impl_file, 'w') as f:
2025-06-07T23:23:56.9445655Z +    with open(impl_file, "w") as f:
2025-06-07T23:23:56.9445908Z          f.write(results["implementation"])
2025-06-07T23:23:56.9446147Z -    
2025-06-07T23:23:56.9446315Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9446515Z +
2025-06-07T23:23:56.9446680Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9446911Z      print("INCREMENTAL LEARNING RESULTS")
2025-06-07T23:23:56.9447154Z -    print("="*60)
2025-06-07T23:23:56.9447341Z +    print("=" * 60)
2025-06-07T23:23:56.9447561Z      print(f"PDFs processed: {len(pdf_files)}")
2025-06-07T23:23:56.9447862Z      print(f"Patterns discovered: {len(patterns)}")
2025-06-07T23:23:56.9448464Z -    print(f"High-confidence patterns: {len([p for p in patterns if p['confidence'] >= 0.6])}")
2025-06-07T23:23:56.9448862Z -    
2025-06-07T23:23:56.9449019Z +    print(
2025-06-07T23:23:56.9449330Z +        f"High-confidence patterns: {len([p for p in patterns if p['confidence'] >= 0.6])}"
2025-06-07T23:23:56.9449696Z +    )
2025-06-07T23:23:56.9449842Z +
2025-06-07T23:23:56.9449998Z      if patterns:
2025-06-07T23:23:56.9450209Z          print("\nTOP 5 LEARNED PATTERNS:")
2025-06-07T23:23:56.9450495Z          for i, pattern in enumerate(patterns[:5], 1):
2025-06-07T23:23:56.9450989Z              print(f"{i}. {pattern['name']} (confidence: {pattern['confidence']:.1%})")
2025-06-07T23:23:56.9451444Z -            print(f"   Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}")
2025-06-07T23:23:56.9451789Z -    
2025-06-07T23:23:56.9451946Z +            print(
2025-06-07T23:23:56.9452221Z +                f"   Example: {pattern['examples'][0] if pattern['examples'] else 'N/A'}"
2025-06-07T23:23:56.9452549Z +            )
2025-06-07T23:23:56.9452714Z +
2025-06-07T23:23:56.9452877Z      print("\nResults saved to:")
2025-06-07T23:23:56.9453118Z      print(f"  Report: {report_file}")
2025-06-07T23:23:56.9453383Z      print(f"  Implementation: {impl_file}")
2025-06-07T23:23:56.9453621Z -    
2025-06-07T23:23:56.9453769Z +
2025-06-07T23:23:56.9453910Z      return 0
2025-06-07T23:23:56.9454184Z  
2025-06-07T23:23:56.9454327Z  
2025-06-07T23:23:56.9454594Z diff --git a/scripts/pattern_enhancer.py b/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9454948Z index 83b4126..5a2c312 100644
2025-06-07T23:23:56.9455185Z --- a/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9455426Z +++ b/scripts/pattern_enhancer.py
2025-06-07T23:23:56.9455693Z @@ -17,24 +17,24 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9455952Z  
2025-06-07T23:23:56.9456114Z  class PatternEnhancer:
2025-06-07T23:23:56.9456406Z      """Analyzes failed patterns and generates new regex patterns."""
2025-06-07T23:23:56.9456710Z -    
2025-06-07T23:23:56.9456860Z +
2025-06-07T23:23:56.9457036Z      def __init__(self, analysis_file: Path):
2025-06-07T23:23:56.9457306Z          with open(analysis_file) as f:
2025-06-07T23:23:56.9457563Z              self.analysis = json.load(f)
2025-06-07T23:23:56.9457629Z -        
2025-06-07T23:23:56.9457697Z +
2025-06-07T23:23:56.9457779Z          self.new_patterns = []
2025-06-07T23:23:56.9457871Z          self.enhanced_patterns = {}
2025-06-07T23:23:56.9457940Z -        
2025-06-07T23:23:56.9458003Z +
2025-06-07T23:23:56.9458124Z      def analyze_failed_patterns(self) -> List[Dict]:
2025-06-07T23:23:56.9458448Z          """Analyze the most common failed patterns and generate solutions."""
2025-06-07T23:23:56.9458619Z          discovered = self.analysis.get("discovered_patterns", [])
2025-06-07T23:23:56.9458695Z          solutions = []
2025-06-07T23:23:56.9458766Z -        
2025-06-07T23:23:56.9458827Z +
2025-06-07T23:23:56.9458915Z          for pattern in discovered:
2025-06-07T23:23:56.9459009Z              structure = pattern["structure"]
2025-06-07T23:23:56.9459092Z              count = pattern["count"]
2025-06-07T23:23:56.9459185Z              examples = pattern["examples"]
2025-06-07T23:23:56.9459249Z -            
2025-06-07T23:23:56.9459316Z +
2025-06-07T23:23:56.9459432Z              # Generate solutions based on pattern analysis
2025-06-07T23:23:56.9459585Z              if self._is_currency_conversion_pattern(structure, examples):
2025-06-07T23:23:56.9459773Z                  solutions.append(self._create_currency_conversion_pattern(pattern))
2025-06-07T23:23:56.9459878Z @@ -46,109 +46,119 @@ class PatternEnhancer:
2025-06-07T23:23:56.9460013Z                  solutions.append(self._create_fee_pattern(pattern))
2025-06-07T23:23:56.9460171Z              elif self._is_embedded_transaction_pattern(structure, examples):
2025-06-07T23:23:56.9460354Z                  solutions.append(self._create_embedded_transaction_pattern(pattern))
2025-06-07T23:23:56.9460421Z -        
2025-06-07T23:23:56.9460483Z +
2025-06-07T23:23:56.9460559Z          return solutions
2025-06-07T23:23:56.9460627Z -    
2025-06-07T23:23:56.9460853Z -    def _is_currency_conversion_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9460921Z +
2025-06-07T23:23:56.9461015Z +    def _is_currency_conversion_pattern(
2025-06-07T23:23:56.9461123Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9461196Z +    ) -> bool:
2025-06-07T23:23:56.9461320Z          """Check if this is a currency conversion line."""
2025-06-07T23:23:56.9461676Z          indicators = ["dÃ³lar", "conversÃ£o", "BRL", "USD", "EUR"]
2025-06-07T23:23:56.9462036Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9462102Z -    
2025-06-07T23:23:56.9462173Z +        return any(
2025-06-07T23:23:56.9462363Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9462428Z +        )
2025-06-07T23:23:56.9462494Z +
2025-06-07T23:23:56.9462700Z      def _is_payment_summary_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9462814Z          """Check if this is a payment summary line."""
2025-06-07T23:23:56.9463009Z          indicators = ["pagamentos efetuados", "saldo financiado", "total desta fatura"]
2025-06-07T23:23:56.9463225Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9463499Z -    
2025-06-07T23:23:56.9463574Z +        return any(
2025-06-07T23:23:56.9463756Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9463827Z +        )
2025-06-07T23:23:56.9463889Z +
2025-06-07T23:23:56.9464096Z      def _is_transaction_code_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9464211Z          """Check if this is a transaction code line."""
2025-06-07T23:23:56.9464365Z -        return any(re.search(r'[A-Z]{2,3} - \d+', ex) for ex in examples)
2025-06-07T23:23:56.9464432Z -    
2025-06-07T23:23:56.9464579Z +        return any(re.search(r"[A-Z]{2,3} - \d+", ex) for ex in examples)
2025-06-07T23:23:56.9464645Z +
2025-06-07T23:23:56.9464826Z      def _is_fee_info_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9464936Z          """Check if this is a fee information line."""
2025-06-07T23:23:56.9465078Z          indicators = ["valor juros", "multa", "encargo", "tarifa"]
2025-06-07T23:23:56.9465287Z -        return any(indicator.lower() in " ".join(examples).lower() for indicator in indicators)
2025-06-07T23:23:56.9465354Z -    
2025-06-07T23:23:56.9465583Z -    def _is_embedded_transaction_pattern(self, structure: str, examples: List[str]) -> bool:
2025-06-07T23:23:56.9465654Z +        return any(
2025-06-07T23:23:56.9465835Z +            indicator.lower() in " ".join(examples).lower() for indicator in indicators
2025-06-07T23:23:56.9465899Z +        )
2025-06-07T23:23:56.9465961Z +
2025-06-07T23:23:56.9466062Z +    def _is_embedded_transaction_pattern(
2025-06-07T23:23:56.9466168Z +        self, structure: str, examples: List[str]
2025-06-07T23:23:56.9466243Z +    ) -> bool:
2025-06-07T23:23:56.9466370Z          """Check if this contains embedded transaction data."""
2025-06-07T23:23:56.9466542Z -        return any(re.search(r'\d{1,2}/\d{1,2}.*\d+,\d{2}', ex) for ex in examples)
2025-06-07T23:23:56.9466609Z -    
2025-06-07T23:23:56.9466769Z +        return any(re.search(r"\d{1,2}/\d{1,2}.*\d+,\d{2}", ex) for ex in examples)
2025-06-07T23:23:56.9466830Z +
2025-06-07T23:23:56.9467011Z      def _create_currency_conversion_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9467133Z          """Create pattern for currency conversion lines."""
2025-06-07T23:23:56.9467436Z          # Pattern: "DÃ³lar de ConversÃ£o R$ 5,71 DÃ³lar de ConversÃ£o R$ 5,77"
2025-06-07T23:23:56.9467810Z          regex = r"(?i)DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate1>\d+,\d{2})(?:\s+DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate2>\d+,\d{2}))?"
2025-06-07T23:23:56.9467886Z -        
2025-06-07T23:23:56.9467949Z +
2025-06-07T23:23:56.9468017Z          return {
2025-06-07T23:23:56.9468115Z              "name": "currency_conversion",
2025-06-07T23:23:56.9468198Z              "pattern": regex,
2025-06-07T23:23:56.9468616Z              "description": "Currency conversion rate information",
2025-06-07T23:23:56.9468781Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9468932Z              "count": pattern["count"],
2025-06-07T23:23:56.9469074Z -            "action": "extract_fx_rate"
2025-06-07T23:23:56.9469372Z +            "action": "extract_fx_rate",
2025-06-07T23:23:56.9469442Z          }
2025-06-07T23:23:56.9469514Z -    
2025-06-07T23:23:56.9469577Z +
2025-06-07T23:23:56.9469751Z      def _create_payment_summary_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9469875Z          """Create pattern for payment summary lines."""
2025-06-07T23:23:56.9469992Z          # Pattern: "P Pagamentos efetuados - 16.744,62"
2025-06-07T23:23:56.9470185Z          regex = r"^(?P<type>[A-Z])\s+(?P<desc>[\w\s]+)\s+-\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9470252Z -        
2025-06-07T23:23:56.9470319Z +
2025-06-07T23:23:56.9470388Z          return {
2025-06-07T23:23:56.9470481Z              "name": "payment_summary",
2025-06-07T23:23:56.9470561Z              "pattern": regex,
2025-06-07T23:23:56.9470697Z              "description": "Payment summary lines with amounts",
2025-06-07T23:23:56.9470905Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9470993Z              "count": pattern["count"],
2025-06-07T23:23:56.9471085Z -            "action": "parse_as_summary"
2025-06-07T23:23:56.9471172Z +            "action": "parse_as_summary",
2025-06-07T23:23:56.9471242Z          }
2025-06-07T23:23:56.9471306Z -    
2025-06-07T23:23:56.9471376Z +
2025-06-07T23:23:56.9471546Z      def _create_transaction_code_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9471667Z          """Create pattern for transaction code lines."""
2025-06-07T23:23:56.9471826Z          # Pattern: "PC - 00 01290 VK045 03/05/2024 VKRPOF01 G4082 0622596"
2025-06-07T23:23:56.9472070Z          regex = r"^(?P<code>[A-Z]{2,3})\s+-\s+(?P<ref>\d+\s+\d+\s+[A-Z0-9]+)\s+(?P<date>\d{2}/\d{2}/\d{4})\s+(?P<details>[\w\s]+)$"
2025-06-07T23:23:56.9472136Z -        
2025-06-07T23:23:56.9472204Z +
2025-06-07T23:23:56.9472270Z          return {
2025-06-07T23:23:56.9472362Z              "name": "transaction_code",
2025-06-07T23:23:56.9472448Z              "pattern": regex,
2025-06-07T23:23:56.9472587Z              "description": "Transaction reference codes with dates",
2025-06-07T23:23:56.9472689Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9472772Z              "count": pattern["count"],
2025-06-07T23:23:56.9472868Z -            "action": "parse_as_reference"
2025-06-07T23:23:56.9472961Z +            "action": "parse_as_reference",
2025-06-07T23:23:56.9473030Z          }
2025-06-07T23:23:56.9473096Z -    
2025-06-07T23:23:56.9473162Z +
2025-06-07T23:23:56.9473292Z      def _create_fee_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9473404Z          """Create pattern for fee information lines."""
2025-06-07T23:23:56.9473496Z          # Pattern: "Valor juros 477,06"
2025-06-07T23:23:56.9473748Z          regex = r"^(?P<desc>(?i)(?:valor\s+)?(?:juros|multa|encargo|tarifa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$"
2025-06-07T23:23:56.9473821Z -        
2025-06-07T23:23:56.9473881Z +
2025-06-07T23:23:56.9473956Z          return {
2025-06-07T23:23:56.9474039Z              "name": "fee_information",
2025-06-07T23:23:56.9474126Z              "pattern": regex,
2025-06-07T23:23:56.9474242Z              "description": "Fee and interest information",
2025-06-07T23:23:56.9474343Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9474424Z              "count": pattern["count"],
2025-06-07T23:23:56.9474513Z -            "action": "parse_as_fee"
2025-06-07T23:23:56.9474598Z +            "action": "parse_as_fee",
2025-06-07T23:23:56.9474663Z          }
2025-06-07T23:23:56.9474731Z -    
2025-06-07T23:23:56.9474794Z +
2025-06-07T23:23:56.9474987Z      def _create_embedded_transaction_pattern(self, pattern: Dict) -> Dict:
2025-06-07T23:23:56.9475115Z          """Create pattern for embedded transaction data."""
2025-06-07T23:23:56.9475268Z          # Pattern: Lines with date and amount but different structure
2025-06-07T23:23:56.9475570Z          regex = r"(?P<date>\d{1,2}/\d{1,2})(?:\s+(?P<desc1>[\w\s]+?))?\s+(?P<amount1>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+(?P<currency>[A-Z]{3}))?\s+(?P<amount2>\d{1,3}(?:\.\d{3})*,\d{2})"
2025-06-07T23:23:56.9475729Z -        
2025-06-07T23:23:56.9475793Z +
2025-06-07T23:23:56.9475864Z          return {
2025-06-07T23:23:56.9475959Z              "name": "embedded_transaction",
2025-06-07T23:23:56.9476042Z              "pattern": regex,
2025-06-07T23:23:56.9476196Z              "description": "Embedded transaction with multiple amounts",
2025-06-07T23:23:56.9476290Z              "example": pattern["examples"][0],
2025-06-07T23:23:56.9476378Z              "count": pattern["count"],
2025-06-07T23:23:56.9476474Z -            "action": "parse_as_transaction"
2025-06-07T23:23:56.9476575Z +            "action": "parse_as_transaction",
2025-06-07T23:23:56.9476641Z          }
2025-06-07T23:23:56.9476710Z -    
2025-06-07T23:23:56.9476772Z +
2025-06-07T23:23:56.9476879Z      def generate_enhanced_parser(self) -> str:
2025-06-07T23:23:56.9477086Z          """Generate enhanced parser code with new patterns."""
2025-06-07T23:23:56.9477197Z          solutions = self.analyze_failed_patterns()
2025-06-07T23:23:56.9477264Z -        
2025-06-07T23:23:56.9477327Z +
2025-06-07T23:23:56.9477414Z          # Sort by impact (count)
2025-06-07T23:23:56.9477546Z          solutions.sort(key=lambda x: x["count"], reverse=True)
2025-06-07T23:23:56.9477617Z -        
2025-06-07T23:23:56.9477679Z +
2025-06-07T23:23:56.9477766Z          parser_code = '''
2025-06-07T23:23:56.9477980Z  def parse_statement_line_enhanced(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9478155Z      """Enhanced parser with additional patterns for better coverage."""
2025-06-07T23:23:56.9478647Z @@ -164,41 +174,41 @@ def parse_statement_line_enhanced(line: str, year: int | None = None) -> dict |
2025-06-07T23:23:56.9478773Z      
2025-06-07T23:23:56.9479002Z      # Enhanced patterns (generated from failed line analysis)
2025-06-07T23:23:56.9479082Z  '''
2025-06-07T23:23:56.9479150Z -        
2025-06-07T23:23:56.9479214Z +
2025-06-07T23:23:56.9479378Z          for i, solution in enumerate(solutions[:10]):  # Top 10 patterns
2025-06-07T23:23:56.9479526Z              pattern_var = f"RE_ENHANCED_{solution['name'].upper()}"
2025-06-07T23:23:56.9479616Z              parser_code += f'''
2025-06-07T23:23:56.9479762Z -    {pattern_var}: Final = re.compile(r"{solution['pattern']}")
2025-06-07T23:23:56.9479906Z +    {pattern_var}: Final = re.compile(r"{solution["pattern"]}")
2025-06-07T23:23:56.9479973Z  '''
2025-06-07T23:23:56.9480043Z -        
2025-06-07T23:23:56.9480125Z -        parser_code += '''
2025-06-07T23:23:56.9480192Z +
2025-06-07T23:23:56.9480270Z +        parser_code += """
2025-06-07T23:23:56.9480335Z      
2025-06-07T23:23:56.9480431Z      # Try enhanced patterns first
2025-06-07T23:23:56.9480493Z -'''
2025-06-07T23:23:56.9480563Z -        
2025-06-07T23:23:56.9480624Z +"""
2025-06-07T23:23:56.9480691Z +
2025-06-07T23:23:56.9480786Z          for solution in solutions[:10]:
2025-06-07T23:23:56.9480921Z              pattern_var = f"RE_ENHANCED_{solution['name'].upper()}"
2025-06-07T23:23:56.9481005Z -            parser_code += f'''
2025-06-07T23:23:56.9481176Z -    # {solution['description']} (covers {solution['count']} failed lines)
2025-06-07T23:23:56.9481253Z +            parser_code += f"""
2025-06-07T23:23:56.9481411Z +    # {solution["description"]} (covers {solution["count"]} failed lines)
2025-06-07T23:23:56.9481501Z      m = {pattern_var}.match(line)
2025-06-07T23:23:56.9481566Z      if m:
2025-06-07T23:23:56.9481714Z -        return _handle_{solution['action']}(m, original_line, year)
2025-06-07T23:23:56.9481777Z -'''
2025-06-07T23:23:56.9481846Z -        
2025-06-07T23:23:56.9481923Z -        parser_code += '''
2025-06-07T23:23:56.9482064Z +        return _handle_{solution["action"]}(m, original_line, year)
2025-06-07T23:23:56.9482127Z +"""
2025-06-07T23:23:56.9482194Z +
2025-06-07T23:23:56.9482269Z +        parser_code += """
2025-06-07T23:23:56.9482335Z      
2025-06-07T23:23:56.9482433Z      # Fall back to original parsing logic
2025-06-07T23:23:56.9482552Z      return parse_statement_line_original(line, year)
2025-06-07T23:23:56.9482769Z -'''
2025-06-07T23:23:56.9482836Z -        
2025-06-07T23:23:56.9482904Z +"""
2025-06-07T23:23:56.9482966Z +
2025-06-07T23:23:56.9483060Z          # Generate handler functions
2025-06-07T23:23:56.9483150Z          for solution in solutions[:10]:
2025-06-07T23:23:56.9483231Z              parser_code += f'''
2025-06-07T23:23:56.9483298Z  
2025-06-07T23:23:56.9483514Z -def _handle_{solution['action']}(m, original_line: str, year: int | None = None) -> dict:
2025-06-07T23:23:56.9483617Z -    """Handle {solution['description']}."""
2025-06-07T23:23:56.9483724Z -    # Custom logic for {solution['name']} pattern
2025-06-07T23:23:56.9483824Z -    # Example line: {solution['example']}
2025-06-07T23:23:56.9484029Z +def _handle_{solution["action"]}(m, original_line: str, year: int | None = None) -> dict:
2025-06-07T23:23:56.9484234Z +    """Handle {solution["description"]}."""
2025-06-07T23:23:56.9484335Z +    # Custom logic for {solution["name"]} pattern
2025-06-07T23:23:56.9484434Z +    # Example line: {solution["example"]}
2025-06-07T23:23:56.9484498Z      
2025-06-07T23:23:56.9484585Z      # Extract common fields
2025-06-07T23:23:56.9484733Z      card_last4 = "0000"  # Default since these may not have card info
2025-06-07T23:23:56.9484952Z @@ -226,72 +236,82 @@ def _handle_{solution['action']}(m, original_line: str, year: int | None = None)
2025-06-07T23:23:56.9485044Z          "amount_usd": Decimal("0.00"),
2025-06-07T23:23:56.9485109Z      }}
2025-06-07T23:23:56.9485181Z  '''
2025-06-07T23:23:56.9485245Z -        
2025-06-07T23:23:56.9485313Z +
2025-06-07T23:23:56.9485392Z          return parser_code
2025-06-07T23:23:56.9485462Z -    
2025-06-07T23:23:56.9485524Z +
2025-06-07T23:23:56.9485636Z      def generate_pattern_report(self) -> Dict:
2025-06-07T23:23:56.9485783Z          """Generate a comprehensive pattern enhancement report."""
2025-06-07T23:23:56.9485893Z          solutions = self.analyze_failed_patterns()
2025-06-07T23:23:56.9486018Z          total_covered = sum(s["count"] for s in solutions)
2025-06-07T23:23:56.9486168Z          total_failed = self.analysis["summary"]["total_failed_lines"]
2025-06-07T23:23:56.9486239Z -        
2025-06-07T23:23:56.9486305Z +
2025-06-07T23:23:56.9486376Z          return {
2025-06-07T23:23:56.9486462Z              "enhancement_summary": {
2025-06-07T23:23:56.9486577Z                  "new_patterns_generated": len(solutions),
2025-06-07T23:23:56.9486688Z                  "lines_potentially_covered": total_covered,
2025-06-07T23:23:56.9486791Z                  "current_failed_lines": total_failed,
2025-06-07T23:23:56.9486995Z -                "potential_success_improvement": f"{(total_covered / total_failed) * 100:.1f}%"
2025-06-07T23:23:56.9487204Z +                "potential_success_improvement": f"{(total_covered / total_failed) * 100:.1f}%",
2025-06-07T23:23:56.9487274Z              },
2025-06-07T23:23:56.9487374Z              "generated_patterns": solutions,
2025-06-07T23:23:56.9487611Z -            "implementation_priority": sorted(solutions, key=lambda x: x["count"], reverse=True)[:5],
2025-06-07T23:23:56.9487711Z +            "implementation_priority": sorted(
2025-06-07T23:23:56.9487841Z +                solutions, key=lambda x: x["count"], reverse=True
2025-06-07T23:23:56.9487909Z +            )[:5],
2025-06-07T23:23:56.9487992Z              "next_steps": [
2025-06-07T23:23:56.9488125Z                  "Implement handler functions for each pattern type",
2025-06-07T23:23:56.9488227Z                  "Add pattern validation tests",
2025-06-07T23:23:56.9488558Z                  "Integrate with main parser in prioritized order",
2025-06-07T23:23:56.9488694Z -                "Create golden CSV updates for improved parsing"
2025-06-07T23:23:56.9488760Z -            ]
2025-06-07T23:23:56.9488882Z +                "Create golden CSV updates for improved parsing",
2025-06-07T23:23:56.9488952Z +            ],
2025-06-07T23:23:56.9489020Z          }
2025-06-07T23:23:56.9489082Z  
2025-06-07T23:23:56.9489144Z  
2025-06-07T23:23:56.9489338Z  def main():
2025-06-07T23:23:56.9489501Z      analysis_file = Path("diagnostics/comprehensive_analysis.json")
2025-06-07T23:23:56.9489594Z      if not analysis_file.exists():
2025-06-07T23:23:56.9489821Z -        print(f"Analysis file {analysis_file} not found. Run comprehensive_analysis.py first.")
2025-06-07T23:23:56.9489895Z +        print(
2025-06-07T23:23:56.9490097Z +            f"Analysis file {analysis_file} not found. Run comprehensive_analysis.py first."
2025-06-07T23:23:56.9490166Z +        )
2025-06-07T23:23:56.9490233Z          return 1
2025-06-07T23:23:56.9490303Z -    
2025-06-07T23:23:56.9490364Z +
2025-06-07T23:23:56.9490467Z      enhancer = PatternEnhancer(analysis_file)
2025-06-07T23:23:56.9490535Z -    
2025-06-07T23:23:56.9490600Z +
2025-06-07T23:23:56.9490689Z      # Generate pattern report
2025-06-07T23:23:56.9490901Z      report = enhancer.generate_pattern_report()
2025-06-07T23:23:56.9490972Z -    
2025-06-07T23:23:56.9491033Z +
2025-06-07T23:23:56.9491118Z      # Save enhancement report
2025-06-07T23:23:56.9491361Z      enhancement_file = Path("diagnostics/pattern_enhancement.json")
2025-06-07T23:23:56.9491781Z -    with open(enhancement_file, 'w') as f:
2025-06-07T23:23:56.9492059Z +    with open(enhancement_file, "w") as f:
2025-06-07T23:23:56.9492342Z          json.dump(report, f, indent=2, default=str)
2025-06-07T23:23:56.9492603Z -    
2025-06-07T23:23:56.9492754Z +
2025-06-07T23:23:56.9492925Z      # Generate enhanced parser code
2025-06-07T23:23:56.9493219Z      enhanced_code = enhancer.generate_enhanced_parser()
2025-06-07T23:23:56.9493493Z -    
2025-06-07T23:23:56.9493648Z +
2025-06-07T23:23:56.9493815Z      # Save enhanced parser
2025-06-07T23:23:56.9494086Z      parser_file = Path("diagnostics/enhanced_parser.py")
2025-06-07T23:23:56.9494386Z -    with open(parser_file, 'w') as f:
2025-06-07T23:23:56.9494639Z +    with open(parser_file, "w") as f:
2025-06-07T23:23:56.9494877Z          f.write(enhanced_code)
2025-06-07T23:23:56.9495083Z -    
2025-06-07T23:23:56.9495249Z -    print("="*60)
2025-06-07T23:23:56.9495424Z +
2025-06-07T23:23:56.9495579Z +    print("=" * 60)
2025-06-07T23:23:56.9495789Z      print("PATTERN ENHANCEMENT REPORT")
2025-06-07T23:23:56.9496034Z -    print("="*60)
2025-06-07T23:23:56.9496381Z -    print(f"New patterns generated: {report['enhancement_summary']['new_patterns_generated']}")
2025-06-07T23:23:56.9496970Z -    print(f"Lines potentially covered: {report['enhancement_summary']['lines_potentially_covered']}")
2025-06-07T23:23:56.9497606Z -    print(f"Potential success improvement: {report['enhancement_summary']['potential_success_improvement']}")
2025-06-07T23:23:56.9498155Z -    
2025-06-07T23:23:56.9498500Z +    print("=" * 60)
2025-06-07T23:23:56.9498696Z +    print(
2025-06-07T23:23:56.9499011Z +        f"New patterns generated: {report['enhancement_summary']['new_patterns_generated']}"
2025-06-07T23:23:56.9499388Z +    )
2025-06-07T23:23:56.9499544Z +    print(
2025-06-07T23:23:56.9499877Z +        f"Lines potentially covered: {report['enhancement_summary']['lines_potentially_covered']}"
2025-06-07T23:23:56.9500266Z +    )
2025-06-07T23:23:56.9500420Z +    print(
2025-06-07T23:23:56.9500786Z +        f"Potential success improvement: {report['enhancement_summary']['potential_success_improvement']}"
2025-06-07T23:23:56.9501212Z +    )
2025-06-07T23:23:56.9501363Z +
2025-06-07T23:23:56.9501558Z      print("\nTOP 5 IMPLEMENTATION PRIORITIES:")
2025-06-07T23:23:56.9501923Z -    for i, pattern in enumerate(report['implementation_priority'][:5], 1):
2025-06-07T23:23:56.9502348Z +    for i, pattern in enumerate(report["implementation_priority"][:5], 1):
2025-06-07T23:23:56.9502740Z          print(f"{i}. {pattern['name']} - covers {pattern['count']} lines")
2025-06-07T23:23:56.9503073Z          print(f"   Example: {pattern['example']}")
2025-06-07T23:23:56.9503330Z -    
2025-06-07T23:23:56.9503485Z +
2025-06-07T23:23:56.9503704Z      print(f"\nEnhanced parser code saved to: {parser_file}")
2025-06-07T23:23:56.9504062Z      print(f"Enhancement report saved to: {enhancement_file}")
2025-06-07T23:23:56.9504488Z -    
2025-06-07T23:23:56.9504638Z +
2025-06-07T23:23:56.9504786Z      return 0
2025-06-07T23:23:56.9504947Z  
2025-06-07T23:23:56.9505088Z  
2025-06-07T23:23:56.9505369Z diff --git a/scripts/semantic_validator.py b/scripts/semantic_validator.py
2025-06-07T23:23:56.9505731Z index 9a9804a..38af08b 100644
2025-06-07T23:23:56.9505965Z --- a/scripts/semantic_validator.py
2025-06-07T23:23:56.9506215Z +++ b/scripts/semantic_validator.py
2025-06-07T23:23:56.9506487Z @@ -19,53 +19,66 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9506790Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9507129Z  from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9507442Z  
2025-06-07T23:23:56.9507594Z +
2025-06-07T23:23:56.9507752Z  class SemanticValidator:
2025-06-07T23:23:56.9508175Z      """Validates parsed data against business logic and semantic rules."""
2025-06-07T23:23:56.9508684Z -    
2025-06-07T23:23:56.9508841Z +
2025-06-07T23:23:56.9509001Z      def __init__(self):
2025-06-07T23:23:56.9509217Z          self.validation_rules = {
2025-06-07T23:23:56.9509476Z              "min_transaction_amount": Decimal("0.01"),
2025-06-07T23:23:56.9509776Z              "max_transaction_amount": Decimal("100000.00"),
2025-06-07T23:23:56.9510046Z              "valid_categories": {
2025-06-07T23:23:56.9510347Z -                "DIVERSOS", "INTERNACIONAL", "PAGAMENTO", "ENCARGO", "AJUSTE",
2025-06-07T23:23:56.9511142Z -                "ALIMENTACAO", "TRANSPORTE", "SAUDE", "EDUCACAO", "LAZER"
2025-06-07T23:23:56.9511603Z +                "DIVERSOS",
2025-06-07T23:23:56.9511822Z +                "INTERNACIONAL",
2025-06-07T23:23:56.9512046Z +                "PAGAMENTO",
2025-06-07T23:23:56.9512423Z +                "ENCARGO",
2025-06-07T23:23:56.9512628Z +                "AJUSTE",
2025-06-07T23:23:56.9512822Z +                "ALIMENTACAO",
2025-06-07T23:23:56.9513036Z +                "TRANSPORTE",
2025-06-07T23:23:56.9513240Z +                "SAUDE",
2025-06-07T23:23:56.9513532Z +                "EDUCACAO",
2025-06-07T23:23:56.9513727Z +                "LAZER",
2025-06-07T23:23:56.9513907Z              },
2025-06-07T23:23:56.9514094Z              "required_fields": {
2025-06-07T23:23:56.9514371Z -                "card_last4", "post_date", "desc_raw", "amount_brl", 
2025-06-07T23:23:56.9514674Z -                "category", "ledger_hash"
2025-06-07T23:23:56.9514906Z -            }
2025-06-07T23:23:56.9515086Z +                "card_last4",
2025-06-07T23:23:56.9515298Z +                "post_date",
2025-06-07T23:23:56.9515504Z +                "desc_raw",
2025-06-07T23:23:56.9515708Z +                "amount_brl",
2025-06-07T23:23:56.9515915Z +                "category",
2025-06-07T23:23:56.9516118Z +                "ledger_hash",
2025-06-07T23:23:56.9516326Z +            },
2025-06-07T23:23:56.9516493Z          }
2025-06-07T23:23:56.9516652Z -        
2025-06-07T23:23:56.9516808Z +
2025-06-07T23:23:56.9516975Z          self.business_rules = {
2025-06-07T23:23:56.9517220Z              "payment_must_be_negative": True,
2025-06-07T23:23:56.9517491Z              "charges_must_be_positive": True,
2025-06-07T23:23:56.9517764Z              "international_needs_currency": True,
2025-06-07T23:23:56.9518051Z -            "installments_need_sequence": True
2025-06-07T23:23:56.9518519Z +            "installments_need_sequence": True,
2025-06-07T23:23:56.9518768Z          }
2025-06-07T23:23:56.9518929Z -    
2025-06-07T23:23:56.9519086Z +
2025-06-07T23:23:56.9519319Z      def validate_pdf_parsing(self, pdf_path: Path) -> Dict:
2025-06-07T23:23:56.9519669Z          """Comprehensive validation of PDF parsing quality."""
2025-06-07T23:23:56.9519952Z -        
2025-06-07T23:23:56.9520108Z +
2025-06-07T23:23:56.9520272Z          # Extract all lines from PDF
2025-06-07T23:23:56.9520569Z          all_lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9520843Z -        
2025-06-07T23:23:56.9520996Z +
2025-06-07T23:23:56.9521314Z          # Parse with current system
2025-06-07T23:23:56.9521556Z          parsed_transactions = []
2025-06-07T23:23:56.9521783Z          for line in all_lines:
2025-06-07T23:23:56.9522040Z              result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9522307Z              if result:
2025-06-07T23:23:56.9522532Z                  parsed_transactions.append(result)
2025-06-07T23:23:56.9522783Z -        
2025-06-07T23:23:56.9522937Z +
2025-06-07T23:23:56.9523109Z          # Get PDF total for validation
2025-06-07T23:23:56.9523350Z          pdf_total = None
2025-06-07T23:23:56.9523543Z          try:
2025-06-07T23:23:56.9523752Z              pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9524007Z          except:
2025-06-07T23:23:56.9524181Z              pass
2025-06-07T23:23:56.9524350Z -        
2025-06-07T23:23:56.9524654Z +
2025-06-07T23:23:56.9524818Z          # Calculate parsed total
2025-06-07T23:23:56.9525129Z          parsed_total = sum(t["amount_brl"] for t in parsed_transactions)
2025-06-07T23:23:56.9525440Z -        
2025-06-07T23:23:56.9525592Z +
2025-06-07T23:23:56.9525754Z          # Comprehensive validation
2025-06-07T23:23:56.9525993Z          validation_results = {
2025-06-07T23:23:56.9526215Z              "file_info": {
2025-06-07T23:23:56.9526444Z @@ -74,33 +87,39 @@ class SemanticValidator:
2025-06-07T23:23:56.9526743Z                  "parsed_transactions": len(parsed_transactions),
2025-06-07T23:23:56.9527050Z                  "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9527358Z                  "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9527851Z -                "coverage_rate": len(parsed_transactions) / max(1, len(all_lines))
2025-06-07T23:23:56.9528434Z +                "coverage_rate": len(parsed_transactions) / max(1, len(all_lines)),
2025-06-07T23:23:56.9528784Z              },
2025-06-07T23:23:56.9529276Z              "data_quality": self._validate_data_quality(parsed_transactions),
2025-06-07T23:23:56.9529707Z              "business_logic": self._validate_business_logic(parsed_transactions),
2025-06-07T23:23:56.9530204Z -            "missing_transactions": self._detect_missing_transactions(all_lines, parsed_transactions),
2025-06-07T23:23:56.9530751Z -            "total_reconciliation": self._validate_total_reconciliation(parsed_total, pdf_total),
2025-06-07T23:23:56.9531211Z +            "missing_transactions": self._detect_missing_transactions(
2025-06-07T23:23:56.9531533Z +                all_lines, parsed_transactions
2025-06-07T23:23:56.9531775Z +            ),
2025-06-07T23:23:56.9532030Z +            "total_reconciliation": self._validate_total_reconciliation(
2025-06-07T23:23:56.9532354Z +                parsed_total, pdf_total
2025-06-07T23:23:56.9532580Z +            ),
2025-06-07T23:23:56.9532860Z              "categorization": self._validate_categorization(parsed_transactions),
2025-06-07T23:23:56.9533215Z -            "recommendations": []
2025-06-07T23:23:56.9533457Z +            "recommendations": [],
2025-06-07T23:23:56.9533683Z          }
2025-06-07T23:23:56.9533840Z -        
2025-06-07T23:23:56.9533999Z +
2025-06-07T23:23:56.9534170Z          # Generate recommendations
2025-06-07T23:23:56.9534560Z -        validation_results["recommendations"] = self._generate_recommendations(validation_results)
2025-06-07T23:23:56.9534958Z -        
2025-06-07T23:23:56.9535233Z +        validation_results["recommendations"] = self._generate_recommendations(
2025-06-07T23:23:56.9535581Z +            validation_results
2025-06-07T23:23:56.9535819Z +        )
2025-06-07T23:23:56.9535974Z +
2025-06-07T23:23:56.9536141Z          return validation_results
2025-06-07T23:23:56.9536360Z -    
2025-06-07T23:23:56.9536508Z +
2025-06-07T23:23:56.9536757Z      def _validate_data_quality(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9537112Z          """Validate basic data quality issues."""
2025-06-07T23:23:56.9537367Z          issues = []
2025-06-07T23:23:56.9537561Z          stats = defaultdict(int)
2025-06-07T23:23:56.9537915Z -        
2025-06-07T23:23:56.9538070Z +
2025-06-07T23:23:56.9538250Z          for i, txn in enumerate(transactions):
2025-06-07T23:23:56.9538702Z              # Check required fields
2025-06-07T23:23:56.9539059Z              missing_fields = self.validation_rules["required_fields"] - set(txn.keys())
2025-06-07T23:23:56.9539422Z              if missing_fields:
2025-06-07T23:23:56.9539734Z                  issues.append(f"Transaction {i}: Missing fields {missing_fields}")
2025-06-07T23:23:56.9540080Z                  stats["missing_fields"] += 1
2025-06-07T23:23:56.9540316Z -            
2025-06-07T23:23:56.9540477Z +
2025-06-07T23:23:56.9540642Z              # Check amount ranges
2025-06-07T23:23:56.9540904Z              amount = txn.get("amount_brl", Decimal("0"))
2025-06-07T23:23:56.9541245Z              if abs(amount) < self.validation_rules["min_transaction_amount"]:
2025-06-07T23:23:56.9541716Z @@ -109,114 +128,153 @@ class SemanticValidator:
2025-06-07T23:23:56.9542057Z              elif abs(amount) > self.validation_rules["max_transaction_amount"]:
2025-06-07T23:23:56.9542467Z                  issues.append(f"Transaction {i}: Amount too large ({amount})")
2025-06-07T23:23:56.9542803Z                  stats["amount_too_large"] += 1
2025-06-07T23:23:56.9543036Z -            
2025-06-07T23:23:56.9543201Z +
2025-06-07T23:23:56.9543368Z              # Check category validity
2025-06-07T23:23:56.9543620Z              category = txn.get("category", "")
2025-06-07T23:23:56.9543937Z              if category not in self.validation_rules["valid_categories"]:
2025-06-07T23:23:56.9544342Z                  issues.append(f"Transaction {i}: Invalid category '{category}'")
2025-06-07T23:23:56.9544687Z                  stats["invalid_category"] += 1
2025-06-07T23:23:56.9544921Z -            
2025-06-07T23:23:56.9545084Z +
2025-06-07T23:23:56.9545253Z              # Check date format
2025-06-07T23:23:56.9545504Z              post_date = txn.get("post_date", "")
2025-06-07T23:23:56.9545845Z              if not post_date or len(post_date) != 10 or post_date.count("-") != 2:
2025-06-07T23:23:56.9546280Z                  issues.append(f"Transaction {i}: Invalid date format '{post_date}'")
2025-06-07T23:23:56.9546627Z                  stats["invalid_date"] += 1
2025-06-07T23:23:56.9546864Z -        
2025-06-07T23:23:56.9547023Z +
2025-06-07T23:23:56.9547169Z          return {
2025-06-07T23:23:56.9547361Z              "total_issues": len(issues),
2025-06-07T23:23:56.9547629Z              "issues": issues[:20],  # First 20 issues
2025-06-07T23:23:56.9547898Z              "issue_statistics": dict(stats),
2025-06-07T23:23:56.9548237Z -            "data_quality_score": max(0, 1 - len(issues) / max(1, len(transactions)))
2025-06-07T23:23:56.9548836Z +            "data_quality_score": max(0, 1 - len(issues) / max(1, len(transactions))),
2025-06-07T23:23:56.9549160Z          }
2025-06-07T23:23:56.9549319Z -    
2025-06-07T23:23:56.9549473Z +
2025-06-07T23:23:56.9549725Z      def _validate_business_logic(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9550079Z          """Validate business logic rules."""
2025-06-07T23:23:56.9550325Z          violations = []
2025-06-07T23:23:56.9550538Z          stats = defaultdict(int)
2025-06-07T23:23:56.9550752Z -        
2025-06-07T23:23:56.9550900Z +
2025-06-07T23:23:56.9551079Z          for i, txn in enumerate(transactions):
2025-06-07T23:23:56.9551349Z              category = txn.get("category", "")
2025-06-07T23:23:56.9551629Z              amount = txn.get("amount_brl", Decimal("0"))
2025-06-07T23:23:56.9551891Z -            
2025-06-07T23:23:56.9552055Z +
2025-06-07T23:23:56.9552230Z              # Payments should be negative
2025-06-07T23:23:56.9552504Z              if category == "PAGAMENTO" and amount >= 0:
2025-06-07T23:23:56.9552906Z -                violations.append(f"Transaction {i}: Payment should be negative, got {amount}")
2025-06-07T23:23:56.9553297Z +                violations.append(
2025-06-07T23:23:56.9553605Z +                    f"Transaction {i}: Payment should be negative, got {amount}"
2025-06-07T23:23:56.9554024Z +                )
2025-06-07T23:23:56.9554225Z                  stats["positive_payment"] += 1
2025-06-07T23:23:56.9554463Z -            
2025-06-07T23:23:56.9554623Z +
2025-06-07T23:23:56.9554793Z              # Charges should be positive
2025-06-07T23:23:56.9559887Z              if category == "ENCARGO" and amount <= 0:
2025-06-07T23:23:56.9560346Z -                violations.append(f"Transaction {i}: Charge should be positive, got {amount}")
2025-06-07T23:23:56.9560740Z +                violations.append(
2025-06-07T23:23:56.9561073Z +                    f"Transaction {i}: Charge should be positive, got {amount}"
2025-06-07T23:23:56.9561386Z +                )
2025-06-07T23:23:56.9561591Z                  stats["negative_charge"] += 1
2025-06-07T23:23:56.9561836Z -            
2025-06-07T23:23:56.9562180Z +
2025-06-07T23:23:56.9562408Z              # International transactions should have currency info
2025-06-07T23:23:56.9562720Z              if category == "INTERNACIONAL":
2025-06-07T23:23:56.9562997Z                  if not txn.get("currency_orig"):
2025-06-07T23:23:56.9563415Z -                    violations.append(f"Transaction {i}: International transaction missing currency")
2025-06-07T23:23:56.9563820Z +                    violations.append(
2025-06-07T23:23:56.9564143Z +                        f"Transaction {i}: International transaction missing currency"
2025-06-07T23:23:56.9564456Z +                    )
2025-06-07T23:23:56.9564669Z                      stats["missing_currency"] += 1
2025-06-07T23:23:56.9564959Z                  if txn.get("amount_orig", Decimal("0")) == 0:
2025-06-07T23:23:56.9565389Z -                    violations.append(f"Transaction {i}: International transaction missing original amount")
2025-06-07T23:23:56.9565799Z +                    violations.append(
2025-06-07T23:23:56.9566136Z +                        f"Transaction {i}: International transaction missing original amount"
2025-06-07T23:23:56.9566469Z +                    )
2025-06-07T23:23:56.9566686Z                      stats["missing_orig_amount"] += 1
2025-06-07T23:23:56.9566933Z -            
2025-06-07T23:23:56.9567099Z +
2025-06-07T23:23:56.9567295Z              # Installments should have proper sequence
2025-06-07T23:23:56.9567588Z              inst_seq = txn.get("installment_seq", 0)
2025-06-07T23:23:56.9567871Z              inst_tot = txn.get("installment_tot", 0)
2025-06-07T23:23:56.9568185Z              if inst_seq > 0 and (inst_tot == 0 or inst_seq > inst_tot):
2025-06-07T23:23:56.9568832Z -                violations.append(f"Transaction {i}: Invalid installment {inst_seq}/{inst_tot}")
2025-06-07T23:23:56.9569218Z +                violations.append(
2025-06-07T23:23:56.9569532Z +                    f"Transaction {i}: Invalid installment {inst_seq}/{inst_tot}"
2025-06-07T23:23:56.9569843Z +                )
2025-06-07T23:23:56.9570048Z                  stats["invalid_installment"] += 1
2025-06-07T23:23:56.9570292Z -        
2025-06-07T23:23:56.9570455Z +
2025-06-07T23:23:56.9570607Z          return {
2025-06-07T23:23:56.9570804Z              "total_violations": len(violations),
2025-06-07T23:23:56.9571069Z              "violations": violations[:20],
2025-06-07T23:23:56.9571342Z              "violation_statistics": dict(stats),
2025-06-07T23:23:56.9571717Z -            "business_logic_score": max(0, 1 - len(violations) / max(1, len(transactions)))
2025-06-07T23:23:56.9572084Z +            "business_logic_score": max(
2025-06-07T23:23:56.9572371Z +                0, 1 - len(violations) / max(1, len(transactions))
2025-06-07T23:23:56.9572644Z +            ),
2025-06-07T23:23:56.9572816Z          }
2025-06-07T23:23:56.9572976Z -    
2025-06-07T23:23:56.9573334Z -    def _detect_missing_transactions(self, all_lines: List[str], parsed_transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9573765Z +
2025-06-07T23:23:56.9573939Z +    def _detect_missing_transactions(
2025-06-07T23:23:56.9574255Z +        self, all_lines: List[str], parsed_transactions: List[Dict]
2025-06-07T23:23:56.9574680Z +    ) -> Dict:
2025-06-07T23:23:56.9574902Z          """Detect potentially missing transactions."""
2025-06-07T23:23:56.9575263Z          parsed_hashes = {txn["ledger_hash"] for txn in parsed_transactions}
2025-06-07T23:23:56.9575577Z -        
2025-06-07T23:23:56.9575730Z +
2025-06-07T23:23:56.9575890Z          potentially_missing = []
2025-06-07T23:23:56.9576157Z          for line_num, line in enumerate(all_lines, 1):
2025-06-07T23:23:56.9576427Z              # Skip empty lines
2025-06-07T23:23:56.9576671Z              if not line.strip():
2025-06-07T23:23:56.9576891Z                  continue
2025-06-07T23:23:56.9577081Z -            
2025-06-07T23:23:56.9577248Z +
2025-06-07T23:23:56.9577483Z              # Check if line has transaction-like patterns but wasn't parsed
2025-06-07T23:23:56.9577865Z              line_hash = pdf_to_csv.hashlib.sha1(line.encode()).hexdigest()
2025-06-07T23:23:56.9578484Z              if line_hash not in parsed_hashes:
2025-06-07T23:23:56.9578788Z                  # Look for transaction indicators
2025-06-07T23:23:56.9579150Z -                has_amount = bool(pdf_to_csv.re.search(r'\d{1,3}(?:\.\d{3})*,\d{2}', line))
2025-06-07T23:23:56.9579558Z -                has_date = bool(pdf_to_csv.re.search(r'\d{1,2}/\d{1,2}', line))
2025-06-07T23:23:56.9579851Z -                
2025-06-07T23:23:56.9580038Z +                has_amount = bool(
2025-06-07T23:23:56.9580322Z +                    pdf_to_csv.re.search(r"\d{1,3}(?:\.\d{3})*,\d{2}", line)
2025-06-07T23:23:56.9580598Z +                )
2025-06-07T23:23:56.9580841Z +                has_date = bool(pdf_to_csv.re.search(r"\d{1,2}/\d{1,2}", line))
2025-06-07T23:23:56.9581128Z +
2025-06-07T23:23:56.9581304Z                  # Skip obvious headers/footers
2025-06-07T23:23:56.9581556Z                  skip_keywords = [
2025-06-07T23:23:56.9581861Z -                    "FATURA", "VENCIMENTO", "LIMITE", "TOTAL", "PAGINA", "CARTAO",
2025-06-07T23:23:56.9582243Z -                    "MASTERCARD", "VISA", "SAC", "OUVIDORIA", "TELEFONE", "EMAIL",
2025-06-07T23:23:56.9582574Z -                    "EXTRATO", "RESUMO", "PERIODO"
2025-06-07T23:23:56.9582826Z +                    "FATURA",
2025-06-07T23:23:56.9583040Z +                    "VENCIMENTO",
2025-06-07T23:23:56.9583260Z +                    "LIMITE",
2025-06-07T23:23:56.9583461Z +                    "TOTAL",
2025-06-07T23:23:56.9583666Z +                    "PAGINA",
2025-06-07T23:23:56.9583869Z +                    "CARTAO",
2025-06-07T23:23:56.9584070Z +                    "MASTERCARD",
2025-06-07T23:23:56.9584282Z +                    "VISA",
2025-06-07T23:23:56.9584485Z +                    "SAC",
2025-06-07T23:23:56.9584688Z +                    "OUVIDORIA",
2025-06-07T23:23:56.9584905Z +                    "TELEFONE",
2025-06-07T23:23:56.9585109Z +                    "EMAIL",
2025-06-07T23:23:56.9585316Z +                    "EXTRATO",
2025-06-07T23:23:56.9585521Z +                    "RESUMO",
2025-06-07T23:23:56.9585728Z +                    "PERIODO",
2025-06-07T23:23:56.9585960Z                  ]
2025-06-07T23:23:56.9586138Z -                
2025-06-07T23:23:56.9586309Z +
2025-06-07T23:23:56.9586553Z                  has_skip_keyword = any(kw in line.upper() for kw in skip_keywords)
2025-06-07T23:23:56.9586865Z -                
2025-06-07T23:23:56.9587033Z +
2025-06-07T23:23:56.9587241Z                  if (has_amount or has_date) and not has_skip_keyword:
2025-06-07T23:23:56.9587548Z -                    potentially_missing.append({
2025-06-07T23:23:56.9587815Z -                        "line_number": line_num,
2025-06-07T23:23:56.9588098Z -                        "line_content": line[:100],  # First 100 chars
2025-06-07T23:23:56.9588551Z -                        "has_amount": has_amount,
2025-06-07T23:23:56.9588812Z -                        "has_date": has_date,
2025-06-07T23:23:56.9589151Z -                        "confidence": "high" if (has_amount and has_date) else "medium"
2025-06-07T23:23:56.9589468Z -                    })
2025-06-07T23:23:56.9589775Z -        
2025-06-07T23:23:56.9589962Z +                    potentially_missing.append(
2025-06-07T23:23:56.9590207Z +                        {
2025-06-07T23:23:56.9590423Z +                            "line_number": line_num,
2025-06-07T23:23:56.9590709Z +                            "line_content": line[:100],  # First 100 chars
2025-06-07T23:23:56.9591001Z +                            "has_amount": has_amount,
2025-06-07T23:23:56.9591259Z +                            "has_date": has_date,
2025-06-07T23:23:56.9591512Z +                            "confidence": "high"
2025-06-07T23:23:56.9591769Z +                            if (has_amount and has_date)
2025-06-07T23:23:56.9592029Z +                            else "medium",
2025-06-07T23:23:56.9592258Z +                        }
2025-06-07T23:23:56.9592450Z +                    )
2025-06-07T23:23:56.9592735Z +
2025-06-07T23:23:56.9592894Z          # Sort by confidence
2025-06-07T23:23:56.9593330Z -        potentially_missing.sort(key=lambda x: (x["confidence"] == "high", x["has_amount"], x["has_date"]), reverse=True)
2025-06-07T23:23:56.9593770Z -        
2025-06-07T23:23:56.9593947Z +        potentially_missing.sort(
2025-06-07T23:23:56.9594274Z +            key=lambda x: (x["confidence"] == "high", x["has_amount"], x["has_date"]),
2025-06-07T23:23:56.9594608Z +            reverse=True,
2025-06-07T23:23:56.9594802Z +        )
2025-06-07T23:23:56.9594956Z +
2025-06-07T23:23:56.9595104Z          return {
2025-06-07T23:23:56.9595346Z              "total_potentially_missing": len(potentially_missing),
2025-06-07T23:23:56.9595798Z -            "high_confidence_missing": len([m for m in potentially_missing if m["confidence"] == "high"]),
2025-06-07T23:23:56.9596210Z +            "high_confidence_missing": len(
2025-06-07T23:23:56.9596518Z +                [m for m in potentially_missing if m["confidence"] == "high"]
2025-06-07T23:23:56.9596811Z +            ),
2025-06-07T23:23:56.9597067Z              "missing_lines": potentially_missing[:30],  # Top 30 candidates
2025-06-07T23:23:56.9597460Z -            "missing_rate": len(potentially_missing) / max(1, len(all_lines))
2025-06-07T23:23:56.9597855Z +            "missing_rate": len(potentially_missing) / max(1, len(all_lines)),
2025-06-07T23:23:56.9598158Z          }
2025-06-07T23:23:56.9598543Z -    
2025-06-07T23:23:56.9598920Z -    def _validate_total_reconciliation(self, parsed_total: Decimal, pdf_total: Optional[Decimal]) -> Dict:
2025-06-07T23:23:56.9599341Z +
2025-06-07T23:23:56.9599512Z +    def _validate_total_reconciliation(
2025-06-07T23:23:56.9599828Z +        self, parsed_total: Decimal, pdf_total: Optional[Decimal]
2025-06-07T23:23:56.9600123Z +    ) -> Dict:
2025-06-07T23:23:56.9600335Z          """Validate total amount reconciliation."""
2025-06-07T23:23:56.9600602Z          if pdf_total is None:
2025-06-07T23:23:56.9600815Z              return {
2025-06-07T23:23:56.9601037Z @@ -224,12 +282,12 @@ class SemanticValidator:
2025-06-07T23:23:56.9601330Z                  "message": "PDF total could not be extracted",
2025-06-07T23:23:56.9601632Z                  "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9601886Z                  "pdf_total": None,
2025-06-07T23:23:56.9602110Z -                "delta": None
2025-06-07T23:23:56.9602323Z +                "delta": None,
2025-06-07T23:23:56.9602526Z              }
2025-06-07T23:23:56.9602691Z -        
2025-06-07T23:23:56.9602845Z +
2025-06-07T23:23:56.9603022Z          delta = abs(parsed_total - pdf_total)
2025-06-07T23:23:56.9603278Z          tolerance = Decimal("0.01")
2025-06-07T23:23:56.9603495Z -        
2025-06-07T23:23:56.9603651Z +
2025-06-07T23:23:56.9603808Z          if delta <= tolerance:
2025-06-07T23:23:56.9604021Z              status = "match"
2025-06-07T23:23:56.9604263Z              message = "Totals match within tolerance"
2025-06-07T23:23:56.9604545Z @@ -239,54 +297,60 @@ class SemanticValidator:
2025-06-07T23:23:56.9604789Z          else:
2025-06-07T23:23:56.9604973Z              status = "major_mismatch"
2025-06-07T23:23:56.9605358Z              message = f"Major total mismatch: {delta}"
2025-06-07T23:23:56.9605610Z -        
2025-06-07T23:23:56.9605764Z +
2025-06-07T23:23:56.9605915Z          return {
2025-06-07T23:23:56.9606097Z              "status": status,
2025-06-07T23:23:56.9606316Z              "message": message,
2025-06-07T23:23:56.9606559Z              "parsed_total": float(parsed_total),
2025-06-07T23:23:56.9606833Z              "pdf_total": float(pdf_total),
2025-06-07T23:23:56.9607073Z              "delta": float(delta),
2025-06-07T23:23:56.9607404Z -            "delta_percentage": float(delta / pdf_total * 100) if pdf_total else None
2025-06-07T23:23:56.9607853Z +            "delta_percentage": float(delta / pdf_total * 100) if pdf_total else None,
2025-06-07T23:23:56.9608186Z          }
2025-06-07T23:23:56.9608542Z -    
2025-06-07T23:23:56.9608823Z +
2025-06-07T23:23:56.9609085Z      def _validate_categorization(self, transactions: List[Dict]) -> Dict:
2025-06-07T23:23:56.9609464Z          """Validate transaction categorization quality."""
2025-06-07T23:23:56.9609869Z -        category_counts = Counter(txn.get("category", "UNKNOWN") for txn in transactions)
2025-06-07T23:23:56.9610218Z -        
2025-06-07T23:23:56.9610385Z +        category_counts = Counter(
2025-06-07T23:23:56.9610661Z +            txn.get("category", "UNKNOWN") for txn in transactions
2025-06-07T23:23:56.9610933Z +        )
2025-06-07T23:23:56.9611081Z +
2025-06-07T23:23:56.9611260Z          # Detect potential categorization issues
2025-06-07T23:23:56.9611507Z          issues = []
2025-06-07T23:23:56.9611778Z          if category_counts.get("DIVERSOS", 0) > len(transactions) * 0.8:
2025-06-07T23:23:56.9612169Z              issues.append("Too many transactions categorized as DIVERSOS")
2025-06-07T23:23:56.9612466Z -        
2025-06-07T23:23:56.9612616Z +
2025-06-07T23:23:56.9612797Z          if category_counts.get("UNKNOWN", 0) > 0:
2025-06-07T23:23:56.9613182Z -            issues.append(f"{category_counts['UNKNOWN']} transactions with unknown category")
2025-06-07T23:23:56.9613538Z -        
2025-06-07T23:23:56.9613700Z +            issues.append(
2025-06-07T23:23:56.9613998Z +                f"{category_counts['UNKNOWN']} transactions with unknown category"
2025-06-07T23:23:56.9614308Z +            )
2025-06-07T23:23:56.9614474Z +
2025-06-07T23:23:56.9614642Z          # Check for missing common categories
2025-06-07T23:23:56.9614894Z          common_patterns = {
2025-06-07T23:23:56.9615184Z              "ALIMENTACAO": ["IFOOD", "RESTAURANTE", "PADARIA", "MERCADO"],
2025-06-07T23:23:56.9615545Z              "TRANSPORTE": ["UBER", "99", "POSTO", "COMBUSTIVEL"],
2025-06-07T23:23:56.9615870Z -            "SAUDE": ["FARMACIA", "HOSPITAL", "CLINICA", "MEDICO"]
2025-06-07T23:23:56.9616195Z +            "SAUDE": ["FARMACIA", "HOSPITAL", "CLINICA", "MEDICO"],
2025-06-07T23:23:56.9616459Z          }
2025-06-07T23:23:56.9616615Z -        
2025-06-07T23:23:56.9616761Z +
2025-06-07T23:23:56.9616965Z          for category, patterns in common_patterns.items():
2025-06-07T23:23:56.9617276Z              if category_counts.get(category, 0) == 0:
2025-06-07T23:23:56.9617605Z                  # Check if we have transactions that should be in this category
2025-06-07T23:23:56.9617919Z                  for txn in transactions:
2025-06-07T23:23:56.9618180Z                      desc = txn.get("desc_raw", "").upper()
2025-06-07T23:23:56.9618617Z                      if any(pattern in desc for pattern in patterns):
2025-06-07T23:23:56.9619011Z -                        issues.append(f"Found {category} transactions not properly categorized")
2025-06-07T23:23:56.9619374Z +                        issues.append(
2025-06-07T23:23:56.9619681Z +                            f"Found {category} transactions not properly categorized"
2025-06-07T23:23:56.9619981Z +                        )
2025-06-07T23:23:56.9620176Z                          break
2025-06-07T23:23:56.9620377Z -        
2025-06-07T23:23:56.9620527Z +
2025-06-07T23:23:56.9620672Z          return {
2025-06-07T23:23:56.9621014Z              "category_distribution": dict(category_counts),
2025-06-07T23:23:56.9621302Z              "categorization_issues": issues,
2025-06-07T23:23:56.9621632Z -            "categorization_score": 1 - len(issues) / 10  # Normalize to 0-1
2025-06-07T23:23:56.9622029Z +            "categorization_score": 1 - len(issues) / 10,  # Normalize to 0-1
2025-06-07T23:23:56.9622331Z          }
2025-06-07T23:23:56.9622482Z -    
2025-06-07T23:23:56.9622627Z +
2025-06-07T23:23:56.9622896Z      def _generate_recommendations(self, validation_results: Dict) -> List[str]:
2025-06-07T23:23:56.9623338Z          """Generate actionable recommendations based on validation results."""
2025-06-07T23:23:56.9623676Z          recommendations = []
2025-06-07T23:23:56.9623877Z -        
2025-06-07T23:23:56.9624023Z +
2025-06-07T23:23:56.9624177Z          # Missing transactions
2025-06-07T23:23:56.9624551Z          missing = validation_results["missing_transactions"]
2025-06-07T23:23:56.9624865Z          if missing["high_confidence_missing"] > 0:
2025-06-07T23:23:56.9625149Z @@ -294,7 +358,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9625495Z                  f"HIGH PRIORITY: {missing['high_confidence_missing']} high-confidence "
2025-06-07T23:23:56.9625919Z                  f"transactions appear to be missing. Review parsing patterns."
2025-06-07T23:23:56.9626231Z              )
2025-06-07T23:23:56.9626393Z -        
2025-06-07T23:23:56.9626539Z +
2025-06-07T23:23:56.9626693Z          # Total reconciliation
2025-06-07T23:23:56.9626958Z          total_val = validation_results["total_reconciliation"]
2025-06-07T23:23:56.9627270Z          if total_val["status"] == "major_mismatch":
2025-06-07T23:23:56.9627543Z @@ -302,7 +366,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9627922Z                  f"CRITICAL: Major total mismatch ({total_val['delta_percentage']:.1f}% difference). "
2025-06-07T23:23:56.9628436Z                  f"Significant transactions are being missed."
2025-06-07T23:23:56.9628717Z              )
2025-06-07T23:23:56.9628895Z -        
2025-06-07T23:23:56.9629039Z +
2025-06-07T23:23:56.9629188Z          # Data quality
2025-06-07T23:23:56.9629421Z          quality = validation_results["data_quality"]
2025-06-07T23:23:56.9629709Z          if quality["data_quality_score"] < 0.9:
2025-06-07T23:23:56.9629979Z @@ -310,7 +374,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9630317Z                  f"Data quality issues detected ({quality['total_issues']} issues). "
2025-06-07T23:23:56.9630685Z                  f"Review field validation and parsing logic."
2025-06-07T23:23:56.9630948Z              )
2025-06-07T23:23:56.9631108Z -        
2025-06-07T23:23:56.9631254Z +
2025-06-07T23:23:56.9631405Z          # Business logic
2025-06-07T23:23:56.9631648Z          business = validation_results["business_logic"]
2025-06-07T23:23:56.9631940Z          if business["business_logic_score"] < 0.95:
2025-06-07T23:23:56.9632218Z @@ -318,7 +382,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9632425Z                  f"Business logic violations found ({business['total_violations']} violations). "
2025-06-07T23:23:56.9632547Z                  f"Review categorization and amount parsing."
2025-06-07T23:23:56.9632611Z              )
2025-06-07T23:23:56.9632677Z -        
2025-06-07T23:23:56.9632738Z +
2025-06-07T23:23:56.9632815Z          # Coverage rate
2025-06-07T23:23:56.9632961Z          coverage = validation_results["file_info"]["coverage_rate"]
2025-06-07T23:23:56.9633078Z          if coverage < 0.3:  # Less than 30% of lines parsed
2025-06-07T23:23:56.9633169Z @@ -326,7 +390,7 @@ class SemanticValidator:
2025-06-07T23:23:56.9633357Z                  f"LOW COVERAGE: Only {coverage:.1%} of lines were parsed as transactions. "
2025-06-07T23:23:56.9633465Z                  f"Consider adding more parsing patterns."
2025-06-07T23:23:56.9633528Z              )
2025-06-07T23:23:56.9633596Z -        
2025-06-07T23:23:56.9633657Z +
2025-06-07T23:23:56.9633740Z          return recommendations
2025-06-07T23:23:56.9633802Z  
2025-06-07T23:23:56.9633985Z  
2025-06-07T23:23:56.9634060Z @@ -335,59 +399,63 @@ def main():
2025-06-07T23:23:56.9634236Z      parser.add_argument("pdf_path", help="Path to PDF file to validate")
2025-06-07T23:23:56.9634425Z      parser.add_argument("--output", "-o", help="Output file for validation report")
2025-06-07T23:23:56.9634511Z      args = parser.parse_args()
2025-06-07T23:23:56.9634574Z -    
2025-06-07T23:23:56.9634634Z +
2025-06-07T23:23:56.9634724Z      pdf_path = Path(args.pdf_path)
2025-06-07T23:23:56.9634808Z      if not pdf_path.exists():
2025-06-07T23:23:56.9634930Z          print(f"Error: PDF file {pdf_path} does not exist")
2025-06-07T23:23:56.9634995Z          return 1
2025-06-07T23:23:56.9635060Z -    
2025-06-07T23:23:56.9635120Z +
2025-06-07T23:23:56.9635211Z      validator = SemanticValidator()
2025-06-07T23:23:56.9635272Z -    
2025-06-07T23:23:56.9635438Z +
2025-06-07T23:23:56.9635534Z      print(f"Validating {pdf_path.name}...")
2025-06-07T23:23:56.9635724Z      validation_results = validator.validate_pdf_parsing(pdf_path)
2025-06-07T23:23:56.9635794Z -    
2025-06-07T23:23:56.9635854Z +
2025-06-07T23:23:56.9635935Z      # Save report if requested
2025-06-07T23:23:56.9636008Z      if args.output:
2025-06-07T23:23:56.9636100Z          output_path = Path(args.output)
2025-06-07T23:23:56.9636239Z          output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9636342Z -        with open(output_path, 'w') as f:
2025-06-07T23:23:56.9636427Z +        with open(output_path, "w") as f:
2025-06-07T23:23:56.9636563Z              json.dump(validation_results, f, indent=2, default=str)
2025-06-07T23:23:56.9636685Z          print(f"Validation report saved to {output_path}")
2025-06-07T23:23:56.9636747Z -    
2025-06-07T23:23:56.9636809Z +
2025-06-07T23:23:56.9636879Z      # Print summary
2025-06-07T23:23:56.9636957Z -    print("\n" + "="*60)
2025-06-07T23:23:56.9637035Z +    print("\n" + "=" * 60)
2025-06-07T23:23:56.9637128Z      print("SEMANTIC VALIDATION SUMMARY")
2025-06-07T23:23:56.9637198Z -    print("="*60)
2025-06-07T23:23:56.9637267Z -    
2025-06-07T23:23:56.9637336Z +    print("=" * 60)
2025-06-07T23:23:56.9637400Z +
2025-06-07T23:23:56.9637508Z      file_info = validation_results["file_info"]
2025-06-07T23:23:56.9637601Z      print(f"File: {file_info['pdf_name']}")
2025-06-07T23:23:56.9637733Z      print(f"Lines processed: {file_info['total_lines']}")
2025-06-07T23:23:56.9637902Z      print(f"Transactions parsed: {file_info['parsed_transactions']}")
2025-06-07T23:23:56.9638037Z      print(f"Coverage rate: {file_info['coverage_rate']:.1%}")
2025-06-07T23:23:56.9638100Z -    
2025-06-07T23:23:56.9638162Z +
2025-06-07T23:23:56.9638403Z      total_val = validation_results["total_reconciliation"]
2025-06-07T23:23:56.9638559Z      print(f"Total reconciliation: {total_val['status'].upper()}")
2025-06-07T23:23:56.9638698Z      if total_val["delta"]:
2025-06-07T23:23:56.9638833Z          print(f"  Parsed: R$ {total_val['parsed_total']:.2f}")
2025-06-07T23:23:56.9638947Z          print(f"  PDF: R$ {total_val['pdf_total']:.2f}")
2025-06-07T23:23:56.9639142Z -        print(f"  Delta: R$ {total_val['delta']:.2f} ({total_val['delta_percentage']:.1f}%)")
2025-06-07T23:23:56.9639205Z -    
2025-06-07T23:23:56.9639270Z +        print(
2025-06-07T23:23:56.9639445Z +            f"  Delta: R$ {total_val['delta']:.2f} ({total_val['delta_percentage']:.1f}%)"
2025-06-07T23:23:56.9639507Z +        )
2025-06-07T23:23:56.9639570Z +
2025-06-07T23:23:56.9639681Z      quality = validation_results["data_quality"]
2025-06-07T23:23:56.9639844Z      print(f"Data quality score: {quality['data_quality_score']:.1%}")
2025-06-07T23:23:56.9639905Z -    
2025-06-07T23:23:56.9639967Z +
2025-06-07T23:23:56.9640080Z      business = validation_results["business_logic"]
2025-06-07T23:23:56.9640252Z      print(f"Business logic score: {business['business_logic_score']:.1%}")
2025-06-07T23:23:56.9640318Z -    
2025-06-07T23:23:56.9640378Z +
2025-06-07T23:23:56.9640506Z      missing = validation_results["missing_transactions"]
2025-06-07T23:23:56.9640886Z -    print(f"Potentially missing transactions: {missing['total_potentially_missing']} "
2025-06-07T23:23:56.9641028Z -          f"({missing['high_confidence_missing']} high confidence)")
2025-06-07T23:23:56.9641091Z -    
2025-06-07T23:23:56.9641159Z +    print(
2025-06-07T23:23:56.9641360Z +        f"Potentially missing transactions: {missing['total_potentially_missing']} "
2025-06-07T23:23:56.9641496Z +        f"({missing['high_confidence_missing']} high confidence)"
2025-06-07T23:23:56.9641558Z +    )
2025-06-07T23:23:56.9641621Z +
2025-06-07T23:23:56.9641763Z      recommendations = validation_results["recommendations"]
2025-06-07T23:23:56.9641845Z      if recommendations:
2025-06-07T23:23:56.9641935Z          print("\nRECOMMENDATIONS:")
2025-06-07T23:23:56.9642045Z          for i, rec in enumerate(recommendations, 1):
2025-06-07T23:23:56.9642232Z              print(f"{i}. {rec}")
2025-06-07T23:23:56.9642293Z -    
2025-06-07T23:23:56.9642359Z +
2025-06-07T23:23:56.9642423Z      return 0
2025-06-07T23:23:56.9642490Z  
2025-06-07T23:23:56.9642550Z  
2025-06-07T23:23:56.9642778Z diff --git a/scripts/validate_real_accuracy.py b/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9642856Z index 6f522d2..84bb478 100644
2025-06-07T23:23:56.9642953Z --- a/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9643042Z +++ b/scripts/validate_real_accuracy.py
2025-06-07T23:23:56.9643151Z @@ -17,35 +17,38 @@ sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9643256Z  from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9643420Z  from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9643484Z  
2025-06-07T23:23:56.9643544Z +
2025-06-07T23:23:56.9643669Z  def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9643821Z      """Validate parsing accuracy using PDF total as ground truth."""
2025-06-07T23:23:56.9643888Z -    
2025-06-07T23:23:56.9643947Z +
2025-06-07T23:23:56.9644022Z      # Extract all lines
2025-06-07T23:23:56.9644145Z      all_lines = list(pdf_to_csv.iter_pdf_lines(pdf_path))
2025-06-07T23:23:56.9644212Z -    
2025-06-07T23:23:56.9644276Z +
2025-06-07T23:23:56.9644353Z      # Parse transactions
2025-06-07T23:23:56.9644440Z      parsed_transactions = []
2025-06-07T23:23:56.9644518Z      for line in all_lines:
2025-06-07T23:23:56.9644635Z          result = pdf_to_csv.parse_statement_line(line)
2025-06-07T23:23:56.9644701Z          if result:
2025-06-07T23:23:56.9644804Z              parsed_transactions.append(result)
2025-06-07T23:23:56.9644866Z -    
2025-06-07T23:23:56.9644929Z +
2025-06-07T23:23:56.9645002Z      # Calculate totals
2025-06-07T23:23:56.9645153Z      parsed_total = sum(t["amount_brl"] for t in parsed_transactions)
2025-06-07T23:23:56.9645217Z -    
2025-06-07T23:23:56.9645276Z +
2025-06-07T23:23:56.9645343Z      try:
2025-06-07T23:23:56.9645449Z          pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9645536Z          total_available = True
2025-06-07T23:23:56.9645616Z -    except Exception as e:
2025-06-07T23:23:56.9645696Z +    except Exception:
2025-06-07T23:23:56.9645770Z          pdf_total = None
2025-06-07T23:23:56.9645852Z          total_available = False
2025-06-07T23:23:56.9645912Z -    
2025-06-07T23:23:56.9645972Z +
2025-06-07T23:23:56.9646055Z      # Calculate accuracy metrics
2025-06-07T23:23:56.9646210Z      coverage_rate = len(parsed_transactions) / max(1, len(all_lines))
2025-06-07T23:23:56.9646274Z -    
2025-06-07T23:23:56.9646334Z +
2025-06-07T23:23:56.9646426Z      if total_available and pdf_total:
2025-06-07T23:23:56.9646530Z          total_delta = abs(parsed_total - pdf_total)
2025-06-07T23:23:56.9646727Z -        total_accuracy = max(0, 1 - (total_delta / abs(pdf_total))) if pdf_total != 0 else 0
2025-06-07T23:23:56.9646802Z +        total_accuracy = (
2025-06-07T23:23:56.9646948Z +            max(0, 1 - (total_delta / abs(pdf_total))) if pdf_total != 0 else 0
2025-06-07T23:23:56.9647016Z +        )
2025-06-07T23:23:56.9647122Z          missing_amount = pdf_total - parsed_total
2025-06-07T23:23:56.9647410Z          missing_percentage = (missing_amount / pdf_total * 100) if pdf_total != 0 else 0
2025-06-07T23:23:56.9647475Z      else:
2025-06-07T23:23:56.9647622Z @@ -53,13 +56,13 @@ def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9647703Z          total_accuracy = None
2025-06-07T23:23:56.9647782Z          missing_amount = None
2025-06-07T23:23:56.9647863Z          missing_percentage = None
2025-06-07T23:23:56.9647927Z -    
2025-06-07T23:23:56.9647990Z +
2025-06-07T23:23:56.9648056Z      return {
2025-06-07T23:23:56.9648139Z          "pdf_name": pdf_path.name,
2025-06-07T23:23:56.9648213Z          "line_coverage": {
2025-06-07T23:23:56.9648400Z              "total_lines": len(all_lines),
2025-06-07T23:23:56.9648510Z              "parsed_lines": len(parsed_transactions),
2025-06-07T23:23:56.9648716Z -            "coverage_rate": coverage_rate
2025-06-07T23:23:56.9648807Z +            "coverage_rate": coverage_rate,
2025-06-07T23:23:56.9648874Z          },
2025-06-07T23:23:56.9648956Z          "financial_accuracy": {
2025-06-07T23:23:56.9649085Z              "pdf_total": float(pdf_total) if pdf_total else None,
2025-06-07T23:23:56.9649225Z @@ -68,14 +71,15 @@ def validate_real_accuracy(pdf_path: Path) -> dict:
2025-06-07T23:23:56.9649320Z              "total_accuracy": total_accuracy,
2025-06-07T23:23:56.9649484Z              "missing_amount": float(missing_amount) if missing_amount else None,
2025-06-07T23:23:56.9649588Z              "missing_percentage": missing_percentage,
2025-06-07T23:23:56.9649680Z -            "total_available": total_available
2025-06-07T23:23:56.9649775Z +            "total_available": total_available,
2025-06-07T23:23:56.9649841Z          },
2025-06-07T23:23:56.9650010Z -        "quality_assessment": _assess_quality(coverage_rate, total_accuracy)
2025-06-07T23:23:56.9650182Z +        "quality_assessment": _assess_quality(coverage_rate, total_accuracy),
2025-06-07T23:23:56.9650249Z      }
2025-06-07T23:23:56.9650316Z  
2025-06-07T23:23:56.9650381Z +
2025-06-07T23:23:56.9650565Z  def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9650660Z      """Assess overall parsing quality."""
2025-06-07T23:23:56.9650727Z -    
2025-06-07T23:23:56.9650789Z +
2025-06-07T23:23:56.9650865Z      # Coverage assessment
2025-06-07T23:23:56.9650949Z      if coverage_rate >= 0.8:
2025-06-07T23:23:56.9651033Z          coverage_grade = "A"
2025-06-07T23:23:56.9651238Z @@ -85,7 +89,7 @@ def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9651315Z          coverage_grade = "C"
2025-06-07T23:23:56.9651385Z      else:
2025-06-07T23:23:56.9651459Z          coverage_grade = "F"
2025-06-07T23:23:56.9651524Z -    
2025-06-07T23:23:56.9651587Z +
2025-06-07T23:23:56.9651691Z      # Total accuracy assessment (if available)
2025-06-07T23:23:56.9651779Z      if total_accuracy is not None:
2025-06-07T23:23:56.9651862Z          if total_accuracy >= 0.99:
2025-06-07T23:23:56.9652077Z @@ -100,111 +104,136 @@ def _assess_quality(coverage_rate: float, total_accuracy: float) -> dict:
2025-06-07T23:23:56.9652160Z              accuracy_grade = "F"
2025-06-07T23:23:56.9652227Z      else:
2025-06-07T23:23:56.9652305Z          accuracy_grade = "Unknown"
2025-06-07T23:23:56.9652369Z -    
2025-06-07T23:23:56.9652429Z +
2025-06-07T23:23:56.9652497Z      return {
2025-06-07T23:23:56.9652587Z          "coverage_grade": coverage_grade,
2025-06-07T23:23:56.9652676Z          "accuracy_grade": accuracy_grade,
2025-06-07T23:23:56.9652851Z -        "overall_assessment": _get_overall_grade(coverage_grade, accuracy_grade)
2025-06-07T23:23:56.9653028Z +        "overall_assessment": _get_overall_grade(coverage_grade, accuracy_grade),
2025-06-07T23:23:56.9653092Z      }
2025-06-07T23:23:56.9653152Z  
2025-06-07T23:23:56.9653216Z +
2025-06-07T23:23:56.9653390Z  def _get_overall_grade(coverage_grade: str, accuracy_grade: str) -> str:
2025-06-07T23:23:56.9653484Z      """Get overall quality grade."""
2025-06-07T23:23:56.9653566Z      if accuracy_grade == "Unknown":
2025-06-07T23:23:56.9653846Z          return f"Coverage: {coverage_grade} (Financial accuracy unknown)"
2025-06-07T23:23:56.9653908Z -    
2025-06-07T23:23:56.9653971Z +
2025-06-07T23:23:56.9654093Z      grades = {"A+": 4.3, "A": 4.0, "B": 3.0, "C": 2.0, "F": 0.0}
2025-06-07T23:23:56.9654269Z      avg = (grades.get(coverage_grade, 0) + grades.get(accuracy_grade, 0)) / 2
2025-06-07T23:23:56.9654331Z -    
2025-06-07T23:23:56.9654392Z +
2025-06-07T23:23:56.9654468Z      if avg >= 4.0:
2025-06-07T23:23:56.9654544Z          return "EXCELLENT"
2025-06-07T23:23:56.9654619Z      elif avg >= 3.0:
2025-06-07T23:23:56.9654693Z -        return "GOOD" 
2025-06-07T23:23:56.9654764Z +        return "GOOD"
2025-06-07T23:23:56.9654834Z      elif avg >= 2.0:
2025-06-07T23:23:56.9654910Z          return "FAIR"
2025-06-07T23:23:56.9655050Z      else:
2025-06-07T23:23:56.9655127Z          return "POOR"
2025-06-07T23:23:56.9655188Z  
2025-06-07T23:23:56.9655248Z +
2025-06-07T23:23:56.9655318Z  def main():
2025-06-07T23:23:56.9655570Z -    parser = argparse.ArgumentParser(description="Real accuracy validation using PDF totals")
2025-06-07T23:23:56.9655671Z +    parser = argparse.ArgumentParser(
2025-06-07T23:23:56.9655810Z +        description="Real accuracy validation using PDF totals"
2025-06-07T23:23:56.9655876Z +    )
2025-06-07T23:23:56.9656042Z      parser.add_argument("pdf_dir", help="Directory containing PDF files")
2025-06-07T23:23:56.9656228Z -    parser.add_argument("--output", default="diagnostics/real_accuracy.json", 
2025-06-07T23:23:56.9656329Z -                       help="Output file for results")
2025-06-07T23:23:56.9656411Z +    parser.add_argument(
2025-06-07T23:23:56.9656483Z +        "--output",
2025-06-07T23:23:56.9656589Z +        default="diagnostics/real_accuracy.json",
2025-06-07T23:23:56.9656682Z +        help="Output file for results",
2025-06-07T23:23:56.9656748Z +    )
2025-06-07T23:23:56.9656838Z      args = parser.parse_args()
2025-06-07T23:23:56.9656899Z -    
2025-06-07T23:23:56.9656968Z +
2025-06-07T23:23:56.9657053Z      pdf_dir = Path(args.pdf_dir)
2025-06-07T23:23:56.9657138Z      if not pdf_dir.exists():
2025-06-07T23:23:56.9657259Z          print(f"Error: Directory {pdf_dir} does not exist")
2025-06-07T23:23:56.9657330Z          return 1
2025-06-07T23:23:56.9657393Z -    
2025-06-07T23:23:56.9657453Z +
2025-06-07T23:23:56.9657534Z      # Validate all PDFs
2025-06-07T23:23:56.9657601Z      results = []
2025-06-07T23:23:56.9657695Z      total_missing_amount = Decimal("0")
2025-06-07T23:23:56.9657779Z      total_pdf_amount = Decimal("0")
2025-06-07T23:23:56.9657864Z      validatable_pdfs = 0
2025-06-07T23:23:56.9657927Z -    
2025-06-07T23:23:56.9657993Z +
2025-06-07T23:23:56.9658081Z      print("REAL ACCURACY VALIDATION")
2025-06-07T23:23:56.9658156Z      print("=" * 50)
2025-06-07T23:23:56.9658218Z -    
2025-06-07T23:23:56.9658379Z +
2025-06-07T23:23:56.9658500Z      for pdf_path in sorted(pdf_dir.glob("*.pdf")):
2025-06-07T23:23:56.9658604Z          result = validate_real_accuracy(pdf_path)
2025-06-07T23:23:56.9658697Z          results.append(result)
2025-06-07T23:23:56.9658761Z -        
2025-06-07T23:23:56.9658828Z +
2025-06-07T23:23:56.9658928Z          financial = result["financial_accuracy"]
2025-06-07T23:23:56.9659028Z          quality = result["quality_assessment"]
2025-06-07T23:23:56.9659092Z -        
2025-06-07T23:23:56.9659154Z +
2025-06-07T23:23:56.9659379Z          print(f"\nðŸ“„ {result['pdf_name']}")
2025-06-07T23:23:56.9659632Z -        print(f"   Coverage: {result['line_coverage']['coverage_rate']:.1%} ({quality['coverage_grade']})")
2025-06-07T23:23:56.9659700Z -        
2025-06-07T23:23:56.9659768Z +        print(
2025-06-07T23:23:56.9659990Z +            f"   Coverage: {result['line_coverage']['coverage_rate']:.1%} ({quality['coverage_grade']})"
2025-06-07T23:23:56.9660054Z +        )
2025-06-07T23:23:56.9660129Z +
2025-06-07T23:23:56.9660222Z          if financial["total_available"]:
2025-06-07T23:23:56.9660312Z              validatable_pdfs += 1
2025-06-07T23:23:56.9660559Z              pdf_total = Decimal(str(financial["pdf_total"]))
2025-06-07T23:23:56.9660686Z              missing = Decimal(str(financial["missing_amount"]))
2025-06-07T23:23:56.9660773Z              total_pdf_amount += pdf_total
2025-06-07T23:23:56.9660861Z              total_missing_amount += missing
2025-06-07T23:23:56.9660928Z -            
2025-06-07T23:23:56.9661181Z -            print(f"   Financial: {financial['missing_percentage']:.1f}% missing ({quality['accuracy_grade']})")
2025-06-07T23:23:56.9661393Z -            print(f"   Total: R$ {financial['parsed_total']:.2f} / R$ {financial['pdf_total']:.2f}")
2025-06-07T23:23:56.9661455Z +
2025-06-07T23:23:56.9661528Z +            print(
2025-06-07T23:23:56.9661759Z +                f"   Financial: {financial['missing_percentage']:.1f}% missing ({quality['accuracy_grade']})"
2025-06-07T23:23:56.9661929Z +            )
2025-06-07T23:23:56.9661996Z +            print(
2025-06-07T23:23:56.9662185Z +                f"   Total: R$ {financial['parsed_total']:.2f} / R$ {financial['pdf_total']:.2f}"
2025-06-07T23:23:56.9662253Z +            )
2025-06-07T23:23:56.9662320Z          else:
2025-06-07T23:23:56.9662485Z -            print(f"   Financial: Cannot validate (PDF total not extractable)")
2025-06-07T23:23:56.9662549Z -        
2025-06-07T23:23:56.9662710Z +            print("   Financial: Cannot validate (PDF total not extractable)")
2025-06-07T23:23:56.9662771Z +
2025-06-07T23:23:56.9662901Z          print(f"   Overall: {quality['overall_assessment']}")
2025-06-07T23:23:56.9662963Z -    
2025-06-07T23:23:56.9663028Z +
2025-06-07T23:23:56.9663100Z      # Overall summary
2025-06-07T23:23:56.9663185Z      if validatable_pdfs > 0:
2025-06-07T23:23:56.9663432Z -        overall_missing_pct = (total_missing_amount / total_pdf_amount * 100) if total_pdf_amount > 0 else 0
2025-06-07T23:23:56.9663692Z -        overall_accuracy = max(0, 1 - (total_missing_amount / total_pdf_amount)) if total_pdf_amount > 0 else 0
2025-06-07T23:23:56.9663776Z +        overall_missing_pct = (
2025-06-07T23:23:56.9663899Z +            (total_missing_amount / total_pdf_amount * 100)
2025-06-07T23:23:56.9663980Z +            if total_pdf_amount > 0
2025-06-07T23:23:56.9664046Z +            else 0
2025-06-07T23:23:56.9664114Z +        )
2025-06-07T23:23:56.9664191Z +        overall_accuracy = (
2025-06-07T23:23:56.9664318Z +            max(0, 1 - (total_missing_amount / total_pdf_amount))
2025-06-07T23:23:56.9664397Z +            if total_pdf_amount > 0
2025-06-07T23:23:56.9664468Z +            else 0
2025-06-07T23:23:56.9664529Z +        )
2025-06-07T23:23:56.9664595Z      else:
2025-06-07T23:23:56.9664679Z          overall_missing_pct = None
2025-06-07T23:23:56.9664765Z          overall_accuracy = None
2025-06-07T23:23:56.9664829Z -    
2025-06-07T23:23:56.9664889Z +
2025-06-07T23:23:56.9664963Z      summary = {
2025-06-07T23:23:56.9665087Z          "validation_timestamp": str(Path().absolute()),
2025-06-07T23:23:56.9665175Z          "total_pdfs": len(results),
2025-06-07T23:23:56.9665277Z          "validatable_pdfs": validatable_pdfs,
2025-06-07T23:23:56.9665396Z          "overall_financial_accuracy": overall_accuracy,
2025-06-07T23:23:56.9665633Z -        "overall_missing_percentage": float(overall_missing_pct) if overall_missing_pct else None,
2025-06-07T23:23:56.9665775Z +        "overall_missing_percentage": float(overall_missing_pct)
2025-06-07T23:23:56.9665856Z +        if overall_missing_pct
2025-06-07T23:23:56.9665927Z +        else None,
2025-06-07T23:23:56.9666046Z          "total_missing_amount": float(total_missing_amount),
2025-06-07T23:23:56.9666154Z          "total_pdf_amount": float(total_pdf_amount),
2025-06-07T23:23:56.9666241Z -        "individual_results": results
2025-06-07T23:23:56.9666328Z +        "individual_results": results,
2025-06-07T23:23:56.9666397Z      }
2025-06-07T23:23:56.9666462Z -    
2025-06-07T23:23:56.9666527Z +
2025-06-07T23:23:56.9666596Z      # Save results
2025-06-07T23:23:56.9666686Z      output_path = Path(args.output)
2025-06-07T23:23:56.9666909Z      output_path.parent.mkdir(parents=True, exist_ok=True)
2025-06-07T23:23:56.9667004Z -    with open(output_path, 'w') as f:
2025-06-07T23:23:56.9667087Z +    with open(output_path, "w") as f:
2025-06-07T23:23:56.9667198Z          json.dump(summary, f, indent=2, default=str)
2025-06-07T23:23:56.9667260Z -    
2025-06-07T23:23:56.9667336Z -    print(f"\n" + "=" * 50)
2025-06-07T23:23:56.9667401Z +
2025-06-07T23:23:56.9667473Z +    print("\n" + "=" * 50)
2025-06-07T23:23:56.9667577Z      print("OVERALL REAL ACCURACY ASSESSMENT")
2025-06-07T23:23:56.9667647Z      print("=" * 50)
2025-06-07T23:23:56.9667752Z      print(f"PDFs processed: {len(results)}")
2025-06-07T23:23:56.9667883Z      print(f"Financially validatable: {validatable_pdfs}")
2025-06-07T23:23:56.9667950Z -    
2025-06-07T23:23:56.9668015Z +
2025-06-07T23:23:56.9668187Z      if overall_accuracy is not None:
2025-06-07T23:23:56.9668427Z          print(f"REAL FINANCIAL ACCURACY: {overall_accuracy:.1%}")
2025-06-07T23:23:56.9668646Z -        print(f"Missing amount: R$ {total_missing_amount:.2f} of R$ {total_pdf_amount:.2f}")
2025-06-07T23:23:56.9668722Z +        print(
2025-06-07T23:23:56.9668907Z +            f"Missing amount: R$ {total_missing_amount:.2f} of R$ {total_pdf_amount:.2f}"
2025-06-07T23:23:56.9668973Z +        )
2025-06-07T23:23:56.9669110Z          print(f"Missing percentage: {overall_missing_pct:.1f}%")
2025-06-07T23:23:56.9669178Z -        
2025-06-07T23:23:56.9669238Z +
2025-06-07T23:23:56.9669324Z          if overall_accuracy >= 0.99:
2025-06-07T23:23:56.9669478Z              print("ðŸŽ¯ STATUS: PRODUCTION READY")
2025-06-07T23:23:56.9669568Z          elif overall_accuracy >= 0.95:
2025-06-07T23:23:56.9669644Z @@ -215,10 +244,11 @@ def main():
2025-06-07T23:23:56.9669834Z              print("âŒ STATUS: POOR - Major improvements required")
2025-06-07T23:23:56.9669910Z      else:
2025-06-07T23:23:56.9670117Z          print("â“ STATUS: UNKNOWN - Cannot validate without PDF totals")
2025-06-07T23:23:56.9670184Z -    
2025-06-07T23:23:56.9670253Z +
2025-06-07T23:23:56.9670359Z      print(f"\nResults saved to: {output_path}")
2025-06-07T23:23:56.9670424Z -    
2025-06-07T23:23:56.9670488Z +
2025-06-07T23:23:56.9670553Z      return 0
2025-06-07T23:23:56.9670616Z  
2025-06-07T23:23:56.9670677Z +
2025-06-07T23:23:56.9670751Z  if __name__ == "__main__":
2025-06-07T23:23:56.9670827Z      sys.exit(main())
2025-06-07T23:23:56.9671067Z diff --git a/src/statement_refinery/pdf_to_csv.py b/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671151Z index d9bf442..2d587fc 100644
2025-06-07T23:23:56.9671249Z --- a/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671351Z +++ b/src/statement_refinery/pdf_to_csv.py
2025-06-07T23:23:56.9671455Z @@ -54,10 +54,10 @@ RE_FX_LINE2: Final = re.compile(
2025-06-07T23:23:56.9671542Z  # Currency conversion rate lines
2025-06-07T23:23:56.9671650Z  RE_CURRENCY_CONVERSION: Final = re.compile(
2025-06-07T23:23:56.9672032Z      r"DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate1>\d+,\d{2})(?:\s+DÃ³lar\s+de\s+ConversÃ£o\s+R\$\s+(?P<rate2>\d+,\d{2}))?",
2025-06-07T23:23:56.9672105Z -    re.I
2025-06-07T23:23:56.9672172Z +    re.I,
2025-06-07T23:23:56.9672233Z  )
2025-06-07T23:23:56.9672294Z  
2025-06-07T23:23:56.9672421Z -# International transaction with city and amounts  
2025-06-07T23:23:56.9672535Z +# International transaction with city and amounts
2025-06-07T23:23:56.9672634Z  RE_INTL_TRANSACTION: Final = re.compile(
2025-06-07T23:23:56.9672887Z      r"^(?P<city>\w+)\s+(?P<orig_amt>\d{1,3}(?:\.\d{3})*,\d{2})\s+(?P<currency>[A-Z]{3})\s+(?P<brl_amt>\d{1,3}(?:\.\d{3})*,\d{2})(?:\s+(?P<desc>.+))?$"
2025-06-07T23:23:56.9672953Z  )
2025-06-07T23:23:56.9673071Z @@ -75,7 +75,7 @@ RE_TRANSACTION_CODE: Final = re.compile(
2025-06-07T23:23:56.9673152Z  # Fee information lines
2025-06-07T23:23:56.9673234Z  RE_FEE_INFO: Final = re.compile(
2025-06-07T23:23:56.9673474Z      r"^(?P<desc>(?:valor\s+)?(?:juros|multa|encargo|tarifa)[\w\s]*)\s+(?P<amount>\d{1,3}(?:\.\d{3})*,\d{2})$",
2025-06-07T23:23:56.9673538Z -    re.I
2025-06-07T23:23:56.9673730Z +    re.I,
2025-06-07T23:23:56.9673794Z  )
2025-06-07T23:23:56.9673853Z  
2025-06-07T23:23:56.9674025Z  # Learned generic transaction pattern (high-confidence catch-all)
2025-06-07T23:23:56.9674242Z @@ -391,14 +391,14 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9674309Z          }
2025-06-07T23:23:56.9674370Z  
2025-06-07T23:23:56.9674472Z      # ===== ENHANCED PATTERN MATCHING =====
2025-06-07T23:23:56.9674535Z -    
2025-06-07T23:23:56.9674598Z +
2025-06-07T23:23:56.9674693Z      # Currency conversion rate information
2025-06-07T23:23:56.9674800Z      m = RE_CURRENCY_CONVERSION.match(line_no_card)
2025-06-07T23:23:56.9674870Z      if m:
2025-06-07T23:23:56.9674996Z          # Extract conversion rates for future FX calculations
2025-06-07T23:23:56.9675114Z          # These are informational lines, not transactions
2025-06-07T23:23:56.9675335Z          return None  # Skip but log for FX rate tracking
2025-06-07T23:23:56.9675401Z -    
2025-06-07T23:23:56.9675466Z +
2025-06-07T23:23:56.9675566Z      # International transaction with city
2025-06-07T23:23:56.9675666Z      m = RE_INTL_TRANSACTION.match(line_no_card)
2025-06-07T23:23:56.9675733Z      if m:
2025-06-07T23:23:56.9675941Z @@ -407,7 +407,7 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9676031Z          currency = m.group("currency")
2025-06-07T23:23:56.9676132Z          brl_amt = parse_amount(m.group("brl_amt"))
2025-06-07T23:23:56.9676247Z          desc = m.group("desc") or f"{city} Transaction"
2025-06-07T23:23:56.9676315Z -        
2025-06-07T23:23:56.9676375Z +
2025-06-07T23:23:56.9676447Z          return {
2025-06-07T23:23:56.9676529Z              "card_last4": card_last4,
2025-06-07T23:23:56.9676683Z              "post_date": f"{year or date.today().year}-01-01",  # Default date
2025-06-07T23:23:56.9676895Z @@ -426,13 +426,13 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9676984Z              "currency_orig": currency,
2025-06-07T23:23:56.9677134Z              "amount_usd": orig_amt if currency == "USD" else Decimal("0.00"),
2025-06-07T23:23:56.9677215Z          }
2025-06-07T23:23:56.9677288Z -    
2025-06-07T23:23:56.9677358Z +
2025-06-07T23:23:56.9677440Z      # Payment summary lines
2025-06-07T23:23:56.9677541Z      m = RE_PAYMENT_SUMMARY.match(line_no_card)
2025-06-07T23:23:56.9677608Z      if m:
2025-06-07T23:23:56.9677716Z          desc = f"{m.group('type')} {m.group('desc')}"
2025-06-07T23:23:56.9677820Z          amount = parse_amount(m.group("amount"))
2025-06-07T23:23:56.9677884Z -        
2025-06-07T23:23:56.9677947Z +
2025-06-07T23:23:56.9678010Z          return {
2025-06-07T23:23:56.9678093Z              "card_last4": card_last4,
2025-06-07T23:23:56.9678240Z              "post_date": f"{year or date.today().year}-12-31",  # End of period
2025-06-07T23:23:56.9678549Z @@ -451,13 +451,13 @@ def parse_statement_line(line: str, year: int | None = None) -> dict | None:
2025-06-07T23:23:56.9678635Z              "currency_orig": "",
2025-06-07T23:23:56.9678722Z              "amount_usd": Decimal("0.00"),
2025-06-07T23:23:56.9678788Z          }
2025-06-07T23:23:56.9678849Z -    
2025-06-07T23:23:56.9678913Z +
2025-06-07T23:23:56.9678991Z      # Fee information lines
2025-06-07T23:23:56.9679082Z      m = RE_FEE_INFO.match(line_no_card)
2025-06-07T23:23:56.9679145Z      if m:
2025-06-07T23:23:56.9679225Z          desc = m.group("desc")
2025-06-07T23:23:56.9679322Z          amount = parse_amount(m.group("amount"))
2025-06-07T23:23:56.9679389Z -        
2025-06-07T23:23:56.9679449Z +
2025-06-07T23:23:56.9679513Z          return {
2025-06-07T23:23:56.9679595Z              "card_last4": card_last4,
2025-06-07T23:23:56.9679737Z              "post_date": f"{year or date.today().year}-12-31",  # End of period
2025-06-07T23:23:56.9679904Z diff --git a/tests/test_pdf_to_csv.py b/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9679984Z index f863dc4..06d169d 100644
2025-06-07T23:23:56.9680188Z --- a/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9680271Z +++ b/tests/test_pdf_to_csv.py
2025-06-07T23:23:56.9680374Z @@ -7,4 +7,4 @@ def test_parse_lines_simple():
2025-06-07T23:23:56.9680462Z      lines = ["01/01 STORE final 1234 9,99"]
2025-06-07T23:23:56.9680550Z      rows = parse_lines(iter(lines))
2025-06-07T23:23:56.9680661Z      assert rows[0]["amount_brl"] == Decimal("9.99")
2025-06-07T23:23:56.9680752Z -    assert rows[0]["card_last4"] == "1234"
2025-06-07T23:23:56.9680838Z \ No newline at end of file
2025-06-07T23:23:56.9680927Z +    assert rows[0]["card_last4"] == "1234"
2025-06-07T23:23:56.9681125Z diff --git a/tests/test_pre_commit_config.py b/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681206Z index 0dcbd2d..943ba36 100644
2025-06-07T23:23:56.9681297Z --- a/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681487Z +++ b/tests/test_pre_commit_config.py
2025-06-07T23:23:56.9681582Z @@ -4,10 +4,12 @@ from pathlib import Path
2025-06-07T23:23:56.9681646Z  
2025-06-07T23:23:56.9681772Z  CONFIG_PATH = Path(".pre-commit-config.yaml")
2025-06-07T23:23:56.9681833Z  
2025-06-07T23:23:56.9681899Z +
2025-06-07T23:23:56.9681970Z  def load_config():
2025-06-07T23:23:56.9682092Z      with CONFIG_PATH.open("r", encoding="utf-8") as f:
2025-06-07T23:23:56.9682178Z          return yaml.safe_load(f)
2025-06-07T23:23:56.9682242Z  
2025-06-07T23:23:56.9682304Z +
2025-06-07T23:23:56.9682389Z  def test_pre_commit_config_valid():
2025-06-07T23:23:56.9682545Z      """Test that the .pre-commit-config.yaml file is valid YAML."""
2025-06-07T23:23:56.9682614Z      try:
2025-06-07T23:23:56.9682728Z @@ -16,20 +18,25 @@ def test_pre_commit_config_valid():
2025-06-07T23:23:56.9682810Z      except Exception as e:
2025-06-07T23:23:56.9682911Z          pytest.fail(f"YAML syntax error: {e}")
2025-06-07T23:23:56.9682978Z  
2025-06-07T23:23:56.9683042Z +
2025-06-07T23:23:56.9683131Z  def test_repos_key_exists():
2025-06-07T23:23:56.9683209Z      config = load_config()
2025-06-07T23:23:56.9683378Z      assert "repos" in config, "Missing 'repos' key in pre-commit config"
2025-06-07T23:23:56.9683547Z      assert isinstance(config["repos"], list), "'repos' should be a list"
2025-06-07T23:23:56.9683613Z  
2025-06-07T23:23:56.9683674Z +
2025-06-07T23:23:56.9683774Z  def test_each_repo_has_required_fields():
2025-06-07T23:23:56.9683849Z      config = load_config()
2025-06-07T23:23:56.9683946Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9684162Z -        assert "repo" in repo or repo.get("repo", None) == "local", f"Repo #{i} missing 'repo' key"
2025-06-07T23:23:56.9684309Z +        assert "repo" in repo or repo.get("repo", None) == "local", (
2025-06-07T23:23:56.9684403Z +            f"Repo #{i} missing 'repo' key"
2025-06-07T23:23:56.9684468Z +        )
2025-06-07T23:23:56.9684563Z          if repo.get("repo", None) != "local":
2025-06-07T23:23:56.9684693Z              assert "rev" in repo, f"Repo #{i} missing 'rev' key"
2025-06-07T23:23:56.9684831Z          assert "hooks" in repo, f"Repo #{i} missing 'hooks' key"
2025-06-07T23:23:56.9685025Z          assert isinstance(repo["hooks"], list), f"Repo #{i} 'hooks' should be a list"
2025-06-07T23:23:56.9685090Z  
2025-06-07T23:23:56.9685152Z +
2025-06-07T23:23:56.9685253Z  def test_each_hook_has_required_fields():
2025-06-07T23:23:56.9685329Z      config = load_config()
2025-06-07T23:23:56.9685432Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9685554Z @@ -38,15 +45,17 @@ def test_each_hook_has_required_fields():
2025-06-07T23:23:56.9685691Z              assert "name" in hook, f"Repo #{i} Hook #{j} missing 'name'"
2025-06-07T23:23:56.9685879Z              assert "description" in hook, f"Repo #{i} Hook #{j} missing 'description'"
2025-06-07T23:23:56.9685944Z  
2025-06-07T23:23:56.9686010Z +
2025-06-07T23:23:56.9686116Z  def test_no_duplicate_hook_ids_within_repo():
2025-06-07T23:23:56.9686198Z      config = load_config()
2025-06-07T23:23:56.9686296Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9686429Z          ids = [hook["id"] for hook in repo["hooks"] if "id" in hook]
2025-06-07T23:23:56.9686685Z          assert len(ids) == len(set(ids)), f"Duplicate hook ids in repo #{i}: {ids}"
2025-06-07T23:23:56.9686752Z  
2025-06-07T23:23:56.9686812Z +
2025-06-07T23:23:56.9686908Z  def test_local_repo_hooks_have_entry():
2025-06-07T23:23:56.9686985Z      config = load_config()
2025-06-07T23:23:56.9687080Z      for i, repo in enumerate(config["repos"]):
2025-06-07T23:23:56.9687173Z          if repo.get("repo", None) == "local":
2025-06-07T23:23:56.9687275Z              for j, hook in enumerate(repo["hooks"]):
2025-06-07T23:23:56.9687433Z -                assert "entry" in hook, f"Local repo hook #{j} missing 'entry'"
2025-06-07T23:23:56.9687513Z \ No newline at end of file
2025-06-07T23:23:56.9687659Z +                assert "entry" in hook, f"Local repo hook #{j} missing 'entry'"
2025-06-07T23:23:56.9704945Z ##[warning]lint failed (ignored)

### 7_Run linters

ï»¿2025-06-07T23:23:56.9742712Z ##[group]Run ruff check --fix . | tee diagnostics/lint.txt
2025-06-07T23:23:56.9742901Z [36;1mruff check --fix . | tee diagnostics/lint.txt[0m
2025-06-07T23:23:56.9743030Z [36;1mblack --check . | tee -a diagnostics/lint.txt[0m
2025-06-07T23:23:56.9793811Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:56.9793888Z env:
2025-06-07T23:23:56.9793971Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:56.9794047Z   MAX_TOKENS: 5000000
2025-06-07T23:23:56.9794116Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:56.9794190Z   FORCE_EVOLVE: 0
2025-06-07T23:23:56.9794343Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794531Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:56.9794681Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794819Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9794952Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:56.9795090Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:56.9795194Z ##[endgroup]
2025-06-07T23:23:56.9974647Z scripts/comprehensive_analysis.py:21:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9974858Z    |
2025-06-07T23:23:56.9975035Z 19 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9975153Z 20 |
2025-06-07T23:23:56.9975342Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9975495Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9975798Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9975914Z    |
2025-06-07T23:23:56.9975922Z 
2025-06-07T23:23:56.9976306Z scripts/comprehensive_analysis.py:22:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9976423Z    |
2025-06-07T23:23:56.9976600Z 21 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9976901Z 22 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9977061Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9977212Z 23 |
2025-06-07T23:23:56.9977399Z 24 | logging.basicConfig(level=logging.INFO)
2025-06-07T23:23:56.9977511Z    |
2025-06-07T23:23:56.9977519Z 
2025-06-07T23:23:56.9977884Z scripts/generate_golden_csvs.py:15:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9977997Z    |
2025-06-07T23:23:56.9978165Z 13 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9978462Z 14 |
2025-06-07T23:23:56.9978664Z 15 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9978808Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9978922Z    |
2025-06-07T23:23:56.9978929Z 
2025-06-07T23:23:56.9979341Z scripts/pattern_enhancer.py:35:13: F841 Local variable `count` is assigned to but never used
2025-06-07T23:23:56.9979455Z    |
2025-06-07T23:23:56.9979616Z 33 |         for pattern in discovered:
2025-06-07T23:23:56.9979790Z 34 |             structure = pattern["structure"]
2025-06-07T23:23:56.9979950Z 35 |             count = pattern["count"]
2025-06-07T23:23:56.9980295Z    |             ^^^^^ F841
2025-06-07T23:23:56.9980459Z 36 |             examples = pattern["examples"]
2025-06-07T23:23:56.9980558Z    |
2025-06-07T23:23:56.9980768Z    = help: Remove assignment to unused variable `count`
2025-06-07T23:23:56.9980777Z 
2025-06-07T23:23:56.9981138Z scripts/semantic_validator.py:19:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9981258Z    |
2025-06-07T23:23:56.9981425Z 17 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9981538Z 18 |
2025-06-07T23:23:56.9981728Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9981878Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9982173Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9982290Z    |
2025-06-07T23:23:56.9982298Z 
2025-06-07T23:23:56.9982635Z scripts/semantic_validator.py:20:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9982964Z    |
2025-06-07T23:23:56.9983150Z 19 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9983448Z 20 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9983620Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9983731Z    |
2025-06-07T23:23:56.9983738Z 
2025-06-07T23:23:56.9984032Z scripts/semantic_validator.py:76:9: E722 Do not use bare `except`
2025-06-07T23:23:56.9984140Z    |
2025-06-07T23:23:56.9984258Z 74 |         try:
2025-06-07T23:23:56.9984445Z 75 |             pdf_total = extract_total_from_pdf(pdf_path)
2025-06-07T23:23:56.9984563Z 76 |         except:
2025-06-07T23:23:56.9984675Z    |         ^^^^^^ E722
2025-06-07T23:23:56.9984792Z 77 |             pass
2025-06-07T23:23:56.9984889Z    |
2025-06-07T23:23:56.9984896Z 
2025-06-07T23:23:56.9985217Z scripts/validate_real_accuracy.py:17:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9985321Z    |
2025-06-07T23:23:56.9985475Z 15 | sys.path.insert(0, str(ROOT / "src"))
2025-06-07T23:23:56.9985586Z 16 |
2025-06-07T23:23:56.9985748Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9985883Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9986144Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9986251Z    |
2025-06-07T23:23:56.9986259Z 
2025-06-07T23:23:56.9986612Z scripts/validate_real_accuracy.py:18:1: E402 Module level import not at top of file
2025-06-07T23:23:56.9986727Z    |
2025-06-07T23:23:56.9986900Z 17 | from statement_refinery import pdf_to_csv
2025-06-07T23:23:56.9987187Z 18 | from statement_refinery.validation import extract_total_from_pdf
2025-06-07T23:23:56.9987343Z    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ E402
2025-06-07T23:23:56.9987456Z    |
2025-06-07T23:23:56.9987463Z 
2025-06-07T23:23:56.9987580Z Found 9 errors.
2025-06-07T23:23:56.9987915Z No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
2025-06-07T23:23:57.5017975Z would reformat /home/runner/work/Evolve/Evolve/scripts/pattern_enhancer.py
2025-06-07T23:23:57.5433463Z would reformat /home/runner/work/Evolve/Evolve/scripts/validate_real_accuracy.py
2025-06-07T23:23:57.6335884Z would reformat /home/runner/work/Evolve/Evolve/scripts/incremental_learner.py
2025-06-07T23:23:57.7045088Z would reformat /home/runner/work/Evolve/Evolve/tests/test_pre_commit_config.py
2025-06-07T23:23:57.7620865Z would reformat /home/runner/work/Evolve/Evolve/scripts/semantic_validator.py
2025-06-07T23:23:57.7690427Z 
2025-06-07T23:23:57.7690939Z Oh no! ðŸ’¥ ðŸ’” ðŸ’¥
2025-06-07T23:23:57.7691429Z 5 files would be reformatted, 19 files would be left unchanged.

### 8_Run mypy

ï»¿2025-06-07T23:23:57.7944609Z ##[group]Run PYTHONPATH=src mypy --explicit-package-bases src/statement_refinery | tee diagnostics/mypy.txt
2025-06-07T23:23:57.7945353Z [36;1mPYTHONPATH=src mypy --explicit-package-bases src/statement_refinery | tee diagnostics/mypy.txt[0m
2025-06-07T23:23:57.7997210Z shell: /usr/bin/bash -e {0}
2025-06-07T23:23:57.7997889Z env:
2025-06-07T23:23:57.7998182Z   OPENAI_MODEL: gpt-4
2025-06-07T23:23:57.7998718Z   MAX_TOKENS: 5000000
2025-06-07T23:23:57.7999019Z   MAX_ATTEMPTS: 5
2025-06-07T23:23:57.7999304Z   FORCE_EVOLVE: 0
2025-06-07T23:23:57.7999753Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8000390Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:23:57.8000991Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8001523Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8002078Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:23:57.8002665Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:23:57.8003130Z ##[endgroup]
2025-06-07T23:24:03.4679694Z src/statement_refinery/pdf_to_csv.py:440: error: Unsupported operand type for unary - ("Decimal | None")  [operator]
2025-06-07T23:24:03.4711747Z Found 1 error in 1 file (checked 3 source files)

### 9_Run tests

ï»¿2025-06-07T23:24:03.4847616Z ##[group]Run pytest -v --cov=statement_refinery \
2025-06-07T23:24:03.4848250Z [36;1mpytest -v --cov=statement_refinery \[0m
2025-06-07T23:24:03.4848923Z [36;1m       --cov-report=xml \[0m
2025-06-07T23:24:03.4849374Z [36;1m       --cov-report=term-missing \[0m
2025-06-07T23:24:03.4849912Z [36;1m       --cov-fail-under=90 | tee diagnostics/test.txt[0m
2025-06-07T23:24:03.4913954Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:03.4914202Z env:
2025-06-07T23:24:03.4914377Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:03.4914592Z   MAX_TOKENS: 5000000
2025-06-07T23:24:03.4914791Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:03.4914978Z   FORCE_EVOLVE: 0
2025-06-07T23:24:03.4915238Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4915651Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:03.4916054Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4916416Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4916814Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:03.4917170Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:03.4917466Z ##[endgroup]
2025-06-07T23:24:03.9910000Z ============================= test session starts ==============================
2025-06-07T23:24:03.9911042Z platform linux -- Python 3.12.10, pytest-8.4.0, pluggy-1.6.0 -- /opt/hostedtoolcache/Python/3.12.10/x64/bin/python
2025-06-07T23:24:03.9911842Z cachedir: .pytest_cache
2025-06-07T23:24:03.9912242Z rootdir: /home/runner/work/Evolve/Evolve
2025-06-07T23:24:03.9912704Z configfile: pyproject.toml
2025-06-07T23:24:03.9913123Z plugins: xdist-3.7.0, anyio-4.9.0, cov-6.1.1
2025-06-07T23:24:04.3404828Z collecting ... collected 41 items
2025-06-07T23:24:04.3405178Z 
2025-06-07T23:24:04.3453595Z tests/test_accuracy_script.py::test_check_accuracy_main_fails_on_mismatch[True] SKIPPED [  2%]
2025-06-07T23:24:04.3474711Z tests/test_accuracy_script.py::test_check_accuracy_main_fails_on_mismatch[False] SKIPPED [  4%]
2025-06-07T23:24:04.3496379Z tests/test_accuracy_script.py::test_check_accuracy_fails_on_total_delta SKIPPED [  7%]
2025-06-07T23:24:04.3509826Z tests/test_ci_summary_constants.py::test_constants_present PASSED        [  9%]
2025-06-07T23:24:04.3529123Z tests/test_parse_line.py::test_domestic_transaction PASSED               [ 12%]
2025-06-07T23:24:04.3541875Z tests/test_parse_line.py::test_fx_transaction PASSED                     [ 14%]
2025-06-07T23:24:04.3557136Z tests/test_parse_line.py::test_payment_line PASSED                       [ 17%]
2025-06-07T23:24:04.3568979Z tests/test_parse_line.py::test_adjustment_line PASSED                    [ 19%]
2025-06-07T23:24:04.3581712Z tests/test_parse_line.py::test_complex_merchant_parsed PASSED            [ 21%]
2025-06-07T23:24:04.3592786Z tests/test_parse_line.py::test_invalid_month_skipped PASSED              [ 24%]
2025-06-07T23:24:04.3604008Z tests/test_parse_line.py::test_invalid_day_skipped PASSED                [ 26%]
2025-06-07T23:24:04.3617228Z tests/test_parse_line.py::test_invalid_month_overflow_skipped PASSED     [ 29%]
2025-06-07T23:24:04.3628778Z tests/test_parse_line.py::test_invalid_day_zero_skipped PASSED           [ 31%]
2025-06-07T23:24:04.3639746Z tests/test_parse_line.py::test_header_fragment_skipped PASSED            [ 34%]
2025-06-07T23:24:04.3650918Z tests/test_parse_line.py::test_keyword_line_skipped PASSED               [ 36%]
2025-06-07T23:24:04.3662059Z tests/test_parse_line.py::test_parse_amount_brazilian_format PASSED      [ 39%]
2025-06-07T23:24:04.3673084Z tests/test_parse_line.py::test_parse_amount_negative_european PASSED     [ 41%]
2025-06-07T23:24:04.3684039Z tests/test_parse_line.py::test_parse_amount_trailing_minus PASSED        [ 43%]
2025-06-07T23:24:04.3694909Z tests/test_parse_line.py::test_parse_amount_parentheses PASSED           [ 46%]
2025-06-07T23:24:04.3705952Z tests/test_parse_line.py::test_classify_transaction_high_priority PASSED [ 48%]
2025-06-07T23:24:04.3717495Z tests/test_parse_line.py::test_classify_transaction_fx_keyword PASSED    [ 51%]
2025-06-07T23:24:04.3728962Z tests/test_parse_line.py::test_parse_fx_currency_line_with_city PASSED   [ 53%]
2025-06-07T23:24:04.3739987Z tests/test_parse_line.py::test_parse_fx_currency_line_none PASSED        [ 56%]
2025-06-07T23:24:04.3754920Z tests/test_parse_line.py::test_iso_date_invalid PASSED                   [ 58%]
2025-06-07T23:24:04.3770972Z tests/test_pdf_to_csv.py::test_parse_lines_simple PASSED                 [ 60%]
2025-06-07T23:24:04.3845703Z tests/test_pre_commit_config.py::test_pre_commit_config_valid PASSED     [ 63%]
2025-06-07T23:24:04.3915634Z tests/test_pre_commit_config.py::test_repos_key_exists PASSED            [ 65%]
2025-06-07T23:24:04.3985014Z tests/test_pre_commit_config.py::test_each_repo_has_required_fields PASSED [ 68%]
2025-06-07T23:24:04.4054643Z tests/test_pre_commit_config.py::test_each_hook_has_required_fields PASSED [ 70%]
2025-06-07T23:24:04.4129695Z tests/test_pre_commit_config.py::test_no_duplicate_hook_ids_within_repo PASSED [ 73%]
2025-06-07T23:24:04.4200640Z tests/test_pre_commit_config.py::test_local_repo_hooks_have_entry PASSED [ 75%]
2025-06-07T23:24:04.4212287Z tests/test_utils.py::test_parse_amount_various_formats PASSED            [ 78%]
2025-06-07T23:24:04.4230547Z tests/test_utils.py::test_parse_lines_deduplicates_and_updates_card PASSED [ 80%]
2025-06-07T23:24:04.4262621Z tests/test_validation_helpers.py::test_extract_total_from_pdf PASSED     [ 82%]
2025-06-07T23:24:04.4273708Z tests/test_validation_helpers.py::test_calculate_csv_total PASSED        [ 85%]
2025-06-07T23:24:04.4284831Z tests/test_validation_helpers.py::test_find_duplicates PASSED            [ 87%]
2025-06-07T23:24:04.4296021Z tests/test_validation_helpers.py::test_validate_categories PASSED        [ 90%]
2025-06-07T23:24:04.4309087Z tests/test_validation_helpers.py::test_analyze_rows PASSED               [ 92%]
2025-06-07T23:24:05.8900001Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_pdfplumber PASSED [ 95%]
2025-06-07T23:24:05.8985523Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_no_total PASSED [ 97%]
2025-06-07T23:24:06.0075599Z tests/test_validation_pdfplumber.py::test_extract_total_from_pdf_pdfplumber_missing PASSED [100%]
2025-06-07T23:24:06.0076592Z ERROR: Coverage failure: total of 66 is less than fail-under=90
2025-06-07T23:24:06.0077032Z 
2025-06-07T23:24:06.0077045Z 
2025-06-07T23:24:06.0077259Z ================================ tests coverage ================================
2025-06-07T23:24:06.0077931Z _______________ coverage: platform linux, python 3.12.10-final-0 _______________
2025-06-07T23:24:06.0078696Z 
2025-06-07T23:24:06.0078914Z Name                                   Stmts   Miss  Cover   Missing
2025-06-07T23:24:06.0079537Z --------------------------------------------------------------------
2025-06-07T23:24:06.0080167Z src/statement_refinery/__init__.py         3      0   100%
2025-06-07T23:24:06.0081174Z src/statement_refinery/pdf_to_csv.py     306    123    60%   142-143, 178-180, 251-252, 300, 325, 333, 336-337, 359, 372-373, 396-495, 580-596, 622-623, 632-637, 649, 667-702, 706-721, 726-771
2025-06-07T23:24:06.0082445Z src/statement_refinery/validation.py      54      0   100%
2025-06-07T23:24:06.0082981Z --------------------------------------------------------------------
2025-06-07T23:24:06.0083480Z TOTAL                                    363    123    66%
2025-06-07T23:24:06.0083943Z Coverage XML written to file coverage.xml
2025-06-07T23:24:06.0084492Z FAIL Required test coverage of 90% not reached. Total coverage: 66.12%
2025-06-07T23:24:06.0085106Z ======================== 38 passed, 3 skipped in 1.99s =========================

### 10_Check accuracy

ï»¿2025-06-07T23:24:06.0571078Z ##[group]Run python scripts/check_accuracy.py --threshold 99 \
2025-06-07T23:24:06.0571903Z [36;1mpython scripts/check_accuracy.py --threshold 99 \[0m
2025-06-07T23:24:06.0572541Z [36;1m       --summary-file diagnostics/accuracy.json \[0m
2025-06-07T23:24:06.0573167Z [36;1m       --csv-dir csv_output | tee diagnostics/accuracy.txt[0m
2025-06-07T23:24:06.0631647Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:06.0631893Z env:
2025-06-07T23:24:06.0632065Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:06.0632280Z   MAX_TOKENS: 5000000
2025-06-07T23:24:06.0632475Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:06.0632659Z   FORCE_EVOLVE: 0
2025-06-07T23:24:06.0632924Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0633341Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:06.0633759Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634117Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634473Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:06.0634860Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:06.0635158Z ##[endgroup]
2025-06-07T23:24:06.1259585Z INFO: CSV written â†’ csv_output/Itau_2024-05.csv
2025-06-07T23:24:06.1914582Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1930973Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1947474Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.1957121Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5516920Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5517817Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5518808Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5519581Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5537495Z INFO: CSV written â†’ csv_output/Itau_2024-06.csv
2025-06-07T23:24:06.5555788Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5571409Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5583673Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5592515Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5601901Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.5611847Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9961580Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9962386Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9963004Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9963613Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9964149Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9964627Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:06.9974965Z INFO: CSV written â†’ csv_output/Itau_2024-07.csv
2025-06-07T23:24:06.9994308Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0008736Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0021233Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0032324Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0042020Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.0051280Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4567185Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4567968Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4569062Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4569733Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4570878Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4571517Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4580591Z INFO: CSV written â†’ csv_output/Itau_2024-08.csv
2025-06-07T23:24:07.4600363Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4615302Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4633178Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4651483Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4664138Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4673414Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4682990Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:07.4692172Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2071230Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2072065Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2072766Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2073447Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2074144Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2074783Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2075355Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2075947Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2086324Z INFO: CSV written â†’ csv_output/Itau_2024-09.csv
2025-06-07T23:24:08.2103296Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2117469Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2128137Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2137424Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2147188Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.2160596Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6276622Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6277401Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6278101Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6279010Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6279635Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6280228Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6290320Z INFO: CSV written â†’ csv_output/Itau_2024-10.csv
2025-06-07T23:24:08.6307163Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6321452Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6333236Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6342650Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6352313Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:08.6363491Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1272239Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1273040Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1273731Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1274403Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1276810Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1277627Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1288489Z INFO: CSV written â†’ csv_output/Itau_2024-11.csv
2025-06-07T23:24:09.1306472Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1320039Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1340677Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1352349Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1361399Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.1370187Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7760689Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7761593Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7762375Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7763142Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7763917Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7764688Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7774311Z INFO: CSV written â†’ csv_output/Itau_2024-12.csv
2025-06-07T23:24:09.7792672Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7806573Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7825459Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7835737Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7845137Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:09.7853923Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4376792Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4377686Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4378730Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4379492Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4380247Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4381035Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4390412Z INFO: CSV written â†’ csv_output/Itau_2025-01.csv
2025-06-07T23:24:10.4408243Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4423181Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4442016Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4454783Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4464192Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:10.4473409Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1151052Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1151959Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1152735Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1153544Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1154308Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1155066Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1164367Z INFO: CSV written â†’ csv_output/Itau_2025-02.csv
2025-06-07T23:24:11.1182589Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1196724Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1216110Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1229110Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1238255Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.1247246Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8466060Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8466855Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8468102Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8468981Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8469567Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8470230Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8480160Z INFO: CSV written â†’ csv_output/Itau_2025-03.csv
2025-06-07T23:24:11.8498439Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8512901Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8531474Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8542468Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8552293Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:11.8561794Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5245574Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5246296Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5246802Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5247251Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5247795Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5248210Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5259186Z INFO: CSV written â†’ csv_output/Itau_2025-04.csv
2025-06-07T23:24:12.5277995Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5292173Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5311663Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5325247Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5334918Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:12.5344299Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2513974Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2514785Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2515517Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2516195Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2516802Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2517364Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2528972Z INFO: CSV written â†’ csv_output/Itau_2025-05.csv
2025-06-07T23:24:13.2564073Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2566167Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2568668Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2570811Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2572985Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2575143Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2577151Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:13.2579465Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1934302Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1935108Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1935801Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1936482Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1937149Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1937829Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1938628Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1939667Z WARNING: CropBox missing from /Page, defaulting to MediaBox
2025-06-07T23:24:14.1962367Z INFO: CSV written â†’ csv_output/itau_2025-06.csv
2025-06-07T23:24:15.6573728Z mismatched parser output or low accuracy
2025-06-07T23:24:15.6574295Z 
2025-06-07T23:24:15.6574548Z Processing 1/14: Itau_2024-05.pdf
2025-06-07T23:24:15.6574925Z 
2025-06-07T23:24:15.6575086Z === Itau_2024-05.pdf ===
2025-06-07T23:24:15.6575549Z Output matches golden file exactly.
2025-06-07T23:24:15.6576058Z Match percentage: 100.00%
2025-06-07T23:24:15.6576653Z Could not verify total: Could not find total in Itau_2024-05.pdf
2025-06-07T23:24:15.6577157Z 
2025-06-07T23:24:15.6577344Z Processing 2/14: Itau_2024-06.pdf
2025-06-07T23:24:15.6577664Z 
2025-06-07T23:24:15.6577819Z === Itau_2024-06.pdf ===
2025-06-07T23:24:15.6578247Z Output matches golden file exactly.
2025-06-07T23:24:15.6578877Z Match percentage: 100.00%
2025-06-07T23:24:15.6579175Z Total mismatch: CSV 0 vs PDF 5731.86
2025-06-07T23:24:15.6579398Z 
2025-06-07T23:24:15.6579533Z Processing 3/14: Itau_2024-07.pdf
2025-06-07T23:24:15.6579768Z 
2025-06-07T23:24:15.6579869Z === Itau_2024-07.pdf ===
2025-06-07T23:24:15.6580159Z Output matches golden file exactly.
2025-06-07T23:24:15.6580421Z Match percentage: 100.00%
2025-06-07T23:24:15.6580651Z Total mismatch: CSV 0 vs PDF 22524.22
2025-06-07T23:24:15.6580828Z 
2025-06-07T23:24:15.6580920Z Processing 4/14: Itau_2024-08.pdf
2025-06-07T23:24:15.6581085Z 
2025-06-07T23:24:15.6581166Z === Itau_2024-08.pdf ===
2025-06-07T23:24:15.6581399Z Output matches golden file exactly.
2025-06-07T23:24:15.6581654Z Match percentage: 100.00%
2025-06-07T23:24:15.6581887Z Total mismatch: CSV 0 vs PDF 59574.97
2025-06-07T23:24:15.6582062Z 
2025-06-07T23:24:15.6582150Z Processing 5/14: Itau_2024-09.pdf
2025-06-07T23:24:15.6582310Z 
2025-06-07T23:24:15.6582394Z === Itau_2024-09.pdf ===
2025-06-07T23:24:15.6582619Z Output matches golden file exactly.
2025-06-07T23:24:15.6582871Z Match percentage: 100.00%
2025-06-07T23:24:15.6583101Z Total mismatch: CSV 0 vs PDF 71543.24
2025-06-07T23:24:15.6583280Z 
2025-06-07T23:24:15.6583371Z Processing 6/14: Itau_2024-10.pdf
2025-06-07T23:24:15.6583535Z 
2025-06-07T23:24:15.6583612Z === Itau_2024-10.pdf ===
2025-06-07T23:24:15.6583832Z Output matches golden file exactly.
2025-06-07T23:24:15.6584086Z Match percentage: 100.00%
2025-06-07T23:24:15.6584322Z Total mismatch: CSV 4772.90 vs PDF 8595.02
2025-06-07T23:24:15.6584514Z 
2025-06-07T23:24:15.6584599Z Processing 7/14: Itau_2024-11.pdf
2025-06-07T23:24:15.6584756Z 
2025-06-07T23:24:15.6584838Z === Itau_2024-11.pdf ===
2025-06-07T23:24:15.6585057Z Output matches golden file exactly.
2025-06-07T23:24:15.6585308Z Match percentage: 100.00%
2025-06-07T23:24:15.6585530Z Total mismatch: CSV 0 vs PDF 13787.89
2025-06-07T23:24:15.6585703Z 
2025-06-07T23:24:15.6585792Z Processing 8/14: Itau_2024-12.pdf
2025-06-07T23:24:15.6585953Z 
2025-06-07T23:24:15.6586030Z === Itau_2024-12.pdf ===
2025-06-07T23:24:15.6586250Z Output matches golden file exactly.
2025-06-07T23:24:15.6586499Z Match percentage: 100.00%
2025-06-07T23:24:15.6586731Z Total mismatch: CSV 0 vs PDF 14121.52
2025-06-07T23:24:15.6586899Z 
2025-06-07T23:24:15.6586992Z Processing 9/14: Itau_2025-01.pdf
2025-06-07T23:24:15.6587150Z 
2025-06-07T23:24:15.6587232Z === Itau_2025-01.pdf ===
2025-06-07T23:24:15.6587666Z Output matches golden file exactly.
2025-06-07T23:24:15.6587914Z Match percentage: 100.00%
2025-06-07T23:24:15.6588136Z Total mismatch: CSV 0 vs PDF 9695.65
2025-06-07T23:24:15.6588423Z 
2025-06-07T23:24:15.6588544Z Processing 10/14: Itau_2025-02.pdf
2025-06-07T23:24:15.6588803Z 
2025-06-07T23:24:15.6588881Z === Itau_2025-02.pdf ===
2025-06-07T23:24:15.6589106Z Output matches golden file exactly.
2025-06-07T23:24:15.6589360Z Match percentage: 100.00%
2025-06-07T23:24:15.6589586Z Total mismatch: CSV 0 vs PDF 11368.22
2025-06-07T23:24:15.6589753Z 
2025-06-07T23:24:15.6589848Z Processing 11/14: Itau_2025-03.pdf
2025-06-07T23:24:15.6590017Z 
2025-06-07T23:24:15.6590100Z === Itau_2025-03.pdf ===
2025-06-07T23:24:15.6590510Z Output matches golden file exactly.
2025-06-07T23:24:15.6590762Z Match percentage: 100.00%
2025-06-07T23:24:15.6590984Z Total mismatch: CSV 0 vs PDF 7704.47
2025-06-07T23:24:15.6591158Z 
2025-06-07T23:24:15.6591246Z Processing 12/14: Itau_2025-04.pdf
2025-06-07T23:24:15.6591413Z 
2025-06-07T23:24:15.6591493Z === Itau_2025-04.pdf ===
2025-06-07T23:24:15.6591707Z Output matches golden file exactly.
2025-06-07T23:24:15.6591941Z Match percentage: 100.00%
2025-06-07T23:24:15.6592153Z Total mismatch: CSV 0 vs PDF 9232.62
2025-06-07T23:24:15.6592309Z 
2025-06-07T23:24:15.6592400Z Processing 13/14: Itau_2025-05.pdf
2025-06-07T23:24:15.6592547Z 
2025-06-07T23:24:15.6592625Z === Itau_2025-05.pdf ===
2025-06-07T23:24:15.6592835Z Output matches golden file exactly.
2025-06-07T23:24:15.6593064Z Match percentage: 100.00%
2025-06-07T23:24:15.6593199Z 
2025-06-07T23:24:15.6593278Z Processing 14/14: itau_2025-06.pdf
2025-06-07T23:24:15.6593430Z 
2025-06-07T23:24:15.6593504Z === itau_2025-06.pdf ===
2025-06-07T23:24:15.6593709Z Output matches golden file exactly.
2025-06-07T23:24:15.6593938Z Match percentage: 100.00%
2025-06-07T23:24:15.6594213Z Could not verify total: Could not find total in itau_2025-06.pdf
2025-06-07T23:24:15.6594534Z Average match across PDFs: 100.00%
2025-06-07T23:24:15.6594820Z TOTAL mismatch across PDFs: CSV 25633.50 vs PDF 254740.28

### 13_Upload coverage

ï»¿2025-06-07T23:24:15.7319165Z ##[group]Run codecov/codecov-action@v4
2025-06-07T23:24:15.7319471Z with:
2025-06-07T23:24:15.7319652Z   file: coverage.xml
2025-06-07T23:24:15.7319857Z   fail_ci_if_error: true
2025-06-07T23:24:15.7320062Z env:
2025-06-07T23:24:15.7320227Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:15.7320426Z   MAX_TOKENS: 5000000
2025-06-07T23:24:15.7320610Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:15.7320785Z   FORCE_EVOLVE: 0
2025-06-07T23:24:15.7321036Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7321460Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:15.7321855Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322226Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322584Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:15.7322946Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:15.7323582Z   CODECOV_TOKEN: ***
2025-06-07T23:24:15.7323941Z ##[endgroup]
2025-06-07T23:24:15.8139468Z eventName: push
2025-06-07T23:24:15.8147955Z ==> linux OS detected
2025-06-07T23:24:16.0047118Z https://cli.codecov.io/latest/linux/codecov.SHA256SUM
2025-06-07T23:24:16.0953816Z gpg: directory '/home/runner/.gnupg' created
2025-06-07T23:24:16.0957739Z gpg: keybox '/home/runner/.gnupg/pubring.kbx' created
2025-06-07T23:24:16.0989890Z gpg: /home/runner/.gnupg/trustdb.gpg: trustdb created
2025-06-07T23:24:16.0991116Z gpg: key 806BB28AED779869: public key "Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>" imported
2025-06-07T23:24:16.1121608Z gpg: Total number processed: 1
2025-06-07T23:24:16.1129337Z gpg:               imported: 1
2025-06-07T23:24:16.1192497Z gpg: Signature made Thu May 29 21:23:31 2025 UTC
2025-06-07T23:24:16.1200373Z gpg:                using RSA key 27034E7FDB850E0BBC2C62FF806BB28AED779869
2025-06-07T23:24:16.1201491Z gpg: Good signature from "Codecov Uploader (Codecov Uploader Verification Key) <security@codecov.io>" [unknown]
2025-06-07T23:24:16.1202799Z gpg: WARNING: This key is not certified with a trusted signature!
2025-06-07T23:24:16.1203538Z gpg:          There is no indication that the signature belongs to the owner.
2025-06-07T23:24:16.1204336Z Primary key fingerprint: 2703 4E7F DB85 0E0B BC2C  62FF 806B B28A ED77 9869
2025-06-07T23:24:16.1439681Z ==> Uploader SHASUM verified (8e0a7ea74f31ee893d11051143fa223cc30f110287ad275e275ca493ddd78eaa  codecov)
2025-06-07T23:24:16.1441020Z ==> Running version latest
2025-06-07T23:24:16.2234311Z Could not pull latest version information: SyntaxError: Unexpected token '<', "<!DOCTYPE "... is not valid JSON
2025-06-07T23:24:16.2236414Z ==> Running git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:16.2325097Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:16.2374081Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit'
2025-06-07T23:24:16.2376413Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-commit --git-service github -Z
2025-06-07T23:24:16.6100800Z info - 2025-06-07 23:24:16,609 -- ci service found: github-actions
2025-06-07T23:24:16.6194581Z warning - 2025-06-07 23:24:16,619 -- No config file could be found. Ignoring config.
2025-06-07T23:24:16.6486161Z info - 2025-06-07 23:24:16,648 -- Using token to create a commit for protected branch `main`
2025-06-07T23:24:17.1871604Z info - 2025-06-07 23:24:17,186 -- Process Commit creating complete
2025-06-07T23:24:17.2886265Z Sentry is attempting to send 2 pending events
2025-06-07T23:24:17.2886585Z Waiting up to 2 seconds
2025-06-07T23:24:17.2886799Z Press Ctrl-C to quit
2025-06-07T23:24:17.3298740Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report'
2025-06-07T23:24:17.3300803Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov create-report --git-service github -Z
2025-06-07T23:24:17.6727320Z info - 2025-06-07 23:24:17,672 -- ci service found: github-actions
2025-06-07T23:24:17.6822527Z warning - 2025-06-07 23:24:17,681 -- No config file could be found. Ignoring config.
2025-06-07T23:24:18.0659550Z info - 2025-06-07 23:24:18,065 -- Process Report creating complete
2025-06-07T23:24:18.0664825Z info - 2025-06-07 23:24:18,066 -- Finished creating report successfully --- {"response": "{\"status\":\"queued\"}\n"}
2025-06-07T23:24:18.1284727Z ==> Running command '/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload'
2025-06-07T23:24:18.1287041Z [command]/home/runner/work/_actions/codecov/codecov-action/v4/dist/codecov do-upload -Z -f coverage.xml --git-service github
2025-06-07T23:24:18.4689622Z info - 2025-06-07 23:24:18,468 -- ci service found: github-actions
2025-06-07T23:24:18.4783650Z warning - 2025-06-07 23:24:18,478 -- No config file could be found. Ignoring config.
2025-06-07T23:24:18.5093133Z warning - 2025-06-07 23:24:18,509 -- xcrun is not installed or can't be found.
2025-06-07T23:24:18.5223128Z warning - 2025-06-07 23:24:18,522 -- No gcov data found.
2025-06-07T23:24:18.5229204Z info - 2025-06-07 23:24:18,522 -- Generating coverage.xml report in /home/runner/work/Evolve/Evolve
2025-06-07T23:24:18.6547911Z info - 2025-06-07 23:24:18,654 -- Wrote XML report to coverage.xml
2025-06-07T23:24:18.6958820Z info - 2025-06-07 23:24:18,695 -- Found 1 coverage files to report
2025-06-07T23:24:18.6959583Z info - 2025-06-07 23:24:18,695 -- > /home/runner/work/Evolve/Evolve/coverage.xml
2025-06-07T23:24:19.0561895Z info - 2025-06-07 23:24:19,055 -- Your upload is now processing. When finished, results will be available at: https://app.codecov.io/github/leolech14/Evolve/commit/63224c07a7ba4fd3150d60b6f60c79fd94cff7a2
2025-06-07T23:24:19.1438825Z info - 2025-06-07 23:24:19,143 -- Process Upload complete

### 14_Upload diagnostics

ï»¿2025-06-07T23:24:19.2400125Z ##[group]Run actions/upload-artifact@v4
2025-06-07T23:24:19.2400554Z with:
2025-06-07T23:24:19.2400730Z   name: diagnostics
2025-06-07T23:24:19.2400921Z   path: diagnostics/
2025-06-07T23:24:19.2401129Z   if-no-files-found: warn
2025-06-07T23:24:19.2401341Z   compression-level: 6
2025-06-07T23:24:19.2401531Z   overwrite: false
2025-06-07T23:24:19.2401723Z   include-hidden-files: false
2025-06-07T23:24:19.2401931Z env:
2025-06-07T23:24:19.2402099Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:19.2402290Z   MAX_TOKENS: 5000000
2025-06-07T23:24:19.2402476Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:19.2402652Z   FORCE_EVOLVE: 0
2025-06-07T23:24:19.2402893Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2403286Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:19.2403672Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404019Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404371Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.2404768Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:19.2405064Z ##[endgroup]
2025-06-07T23:24:19.4584453Z With the provided path, there will be 6 files uploaded
2025-06-07T23:24:19.4590578Z Artifact name is valid!
2025-06-07T23:24:19.4591325Z Root directory input is valid!
2025-06-07T23:24:19.5630250Z Beginning upload of artifact content to blob storage
2025-06-07T23:24:19.6246362Z Uploaded bytes 3477
2025-06-07T23:24:19.6414820Z Finished uploading artifact content to blob storage!
2025-06-07T23:24:19.6418587Z SHA256 digest of uploaded artifact zip is 08f202ae29fd53e7091f1c0fc113a475599e76d435eaea5cfd5927b15ec70681
2025-06-07T23:24:19.6420338Z Finalizing artifact upload
2025-06-07T23:24:19.7074400Z Artifact diagnostics.zip successfully finalized. Artifact ID 3282257397
2025-06-07T23:24:19.7075461Z Artifact diagnostics has been successfully uploaded! Final size is 3477 bytes. Artifact ID is 3282257397
2025-06-07T23:24:19.7082931Z Artifact download URL: https://github.com/leolech14/Evolve/actions/runs/15512627444/artifacts/3282257397

### 15_Upload CSVs

ï»¿2025-06-07T23:24:19.7190287Z ##[group]Run actions/upload-artifact@v4
2025-06-07T23:24:19.7190582Z with:
2025-06-07T23:24:19.7190757Z   name: csvs
2025-06-07T23:24:19.7190943Z   path: csv_output/
2025-06-07T23:24:19.7191147Z   if-no-files-found: warn
2025-06-07T23:24:19.7191377Z   compression-level: 6
2025-06-07T23:24:19.7191582Z   overwrite: false
2025-06-07T23:24:19.7191785Z   include-hidden-files: false
2025-06-07T23:24:19.7192002Z env:
2025-06-07T23:24:19.7192173Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:19.7192373Z   MAX_TOKENS: 5000000
2025-06-07T23:24:19.7192562Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:19.7192745Z   FORCE_EVOLVE: 0
2025-06-07T23:24:19.7193005Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7193418Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:19.7193823Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194186Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194565Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:19.7194966Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:19.7195272Z ##[endgroup]
2025-06-07T23:24:19.9308666Z With the provided path, there will be 14 files uploaded
2025-06-07T23:24:19.9313180Z Artifact name is valid!
2025-06-07T23:24:19.9314237Z Root directory input is valid!
2025-06-07T23:24:20.0001359Z Beginning upload of artifact content to blob storage
2025-06-07T23:24:20.0745192Z Uploaded bytes 14022
2025-06-07T23:24:20.0927431Z Finished uploading artifact content to blob storage!
2025-06-07T23:24:20.0930762Z SHA256 digest of uploaded artifact zip is f0cb7aa5f71fcd01aa66bb33627487b1e693182b4d539f04b0b57428d6992aac
2025-06-07T23:24:20.0932734Z Finalizing artifact upload
2025-06-07T23:24:20.1563808Z Artifact csvs.zip successfully finalized. Artifact ID 3282257402
2025-06-07T23:24:20.1564887Z Artifact csvs has been successfully uploaded! Final size is 14022 bytes. Artifact ID is 3282257402
2025-06-07T23:24:20.1571959Z Artifact download URL: https://github.com/leolech14/Evolve/actions/runs/15512627444/artifacts/3282257402

### 16_Generate summary

ï»¿2025-06-07T23:24:20.1671995Z ##[group]Run python scripts/ci_summary.py
2025-06-07T23:24:20.1672333Z [36;1mpython scripts/ci_summary.py[0m
2025-06-07T23:24:20.1723670Z shell: /usr/bin/bash -e {0}
2025-06-07T23:24:20.1723916Z env:
2025-06-07T23:24:20.1724095Z   OPENAI_MODEL: gpt-4
2025-06-07T23:24:20.1724315Z   MAX_TOKENS: 5000000
2025-06-07T23:24:20.1724516Z   MAX_ATTEMPTS: 5
2025-06-07T23:24:20.1724711Z   FORCE_EVOLVE: 0
2025-06-07T23:24:20.1724973Z   pythonLocation: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1725416Z   PKG_CONFIG_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib/pkgconfig
2025-06-07T23:24:20.1725833Z   Python_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726205Z   Python2_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726589Z   Python3_ROOT_DIR: /opt/hostedtoolcache/Python/3.12.10/x64
2025-06-07T23:24:20.1726951Z   LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.12.10/x64/lib
2025-06-07T23:24:20.1727263Z ##[endgroup]
2025-06-07T23:24:20.2036242Z ## CI Run Summary
2025-06-07T23:24:20.2036626Z 
2025-06-07T23:24:20.2036749Z ### Test Results
2025-06-07T23:24:20.2037001Z - Total Tests: 38
2025-06-07T23:24:20.2037247Z - Passed: 0
2025-06-07T23:24:20.2037471Z - Failed: 0
2025-06-07T23:24:20.2037691Z - Skipped: 0
2025-06-07T23:24:20.2037916Z - Coverage: 66.0%
2025-06-07T23:24:20.2038065Z 
2025-06-07T23:24:20.2038162Z ### Lint Issues
2025-06-07T23:24:20.2038770Z ```
2025-06-07T23:24:20.2038996Z Found 9 errors.
2025-06-07T23:24:20.2039222Z ```
2025-06-07T23:24:20.2039336Z 
2025-06-07T23:24:20.2039436Z ### Parser Accuracy
2025-06-07T23:24:20.2039734Z - Average Match: Data not available
2025-06-07T23:24:20.2039959Z 
2025-06-07T23:24:20.2040071Z #### Per-File Results
2025-06-07T23:24:20.2040317Z ```
2025-06-07T23:24:20.2040512Z ```
2025-06-07T23:24:20.2040640Z 

### 31_Post Run actions_setup-python@v5

ï»¿2025-06-07T23:24:20.2111542Z Post job cleanup.
2025-06-07T23:24:20.3573904Z Cache hit occurred on the primary key setup-python-Linux-x64-24.04-Ubuntu-python-3.12.10-pip-16e89f17d8a7ffc7da5ff034a3d02d9aac7c9a988a734c71f332e0e45a4cb0d9, not saving cache.

### 32_Post Run actions_checkout@v4

ï»¿2025-06-07T23:24:20.3690259Z Post job cleanup.
2025-06-07T23:24:20.4638946Z [command]/usr/bin/git version
2025-06-07T23:24:20.4675362Z git version 2.49.0
2025-06-07T23:24:20.4715401Z Copying '/home/runner/.gitconfig' to '/home/runner/work/_temp/4aa82ed3-47bc-40a6-a3e6-39b2ffb98e51/.gitconfig'
2025-06-07T23:24:20.4732261Z Temporarily overriding HOME='/home/runner/work/_temp/4aa82ed3-47bc-40a6-a3e6-39b2ffb98e51' before making global git config changes
2025-06-07T23:24:20.4733273Z Adding repository directory to the temporary git global config as a safe directory
2025-06-07T23:24:20.4737757Z [command]/usr/bin/git config --global --add safe.directory /home/runner/work/Evolve/Evolve
2025-06-07T23:24:20.4775487Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2025-06-07T23:24:20.4808684Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :"
2025-06-07T23:24:20.5041886Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2025-06-07T23:24:20.5062894Z http.https://github.com/.extraheader
2025-06-07T23:24:20.5076113Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2025-06-07T23:24:20.5107643Z [command]/usr/bin/git submodule foreach --recursive sh -c "git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :"

### 33_Complete job

ï»¿2025-06-07T23:24:20.5446617Z Cleaning up orphan processes
